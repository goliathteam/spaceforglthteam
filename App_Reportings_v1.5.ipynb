{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import bql\n",
    "import numpy as np\n",
    "from IPython.display import display, clear_output\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import bqport\n",
    "from datetime import date, datetime, timedelta\n",
    "import datetime\n",
    "from ipywidgets import *\n",
    "from  bqwidgets import AutoComplete, DatePicker\n",
    "import ipywidgets\n",
    "from openpyxl import load_workbook\n",
    "import shutil\n",
    "\n",
    "bq = bql.Service()\n",
    "d = bq.data\n",
    "f = bq.func\n",
    "u = bq.univ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bq_res_array_to_pd(res_array):\n",
    "    a = res_array[0].df().reset_index()\n",
    "    r_all = pd.DataFrame({'ID':a['ID']})\n",
    "    for res in res_array:\n",
    "        r_n = res.df().reset_index()\n",
    "        r_all = r_all.merge(r_n, on = 'ID')\n",
    "    return r_all\n",
    "\n",
    "def download_port (tgt = None):\n",
    "    global global_mat #Matriz de datos sin agrupar\n",
    "    global port_dates_list #Vector de fechas de carteras cargadas en PRTU \n",
    "    \n",
    "    #Se inicializa la matriz global que contendrá todos los datos\n",
    "    global_mat = pd.DataFrame(data = {})\n",
    "    \n",
    "    list_port_names = port.value\n",
    "    for i in range(len(list_port_names)):\n",
    "        \n",
    "        if i==0:\n",
    "            obj = bqport.load_portfolio(list_port_names[i])\n",
    "            global_mat = obj.to_dataframe().reset_index()\n",
    "#             global_mat['Banco'] = list_port_names[i]\n",
    "            aux_bank_name = list_port_names[i].split('-')\n",
    "            aux_bank_name = aux_bank_name[-1]\n",
    "            global_mat['Banco'] = aux_bank_name \n",
    "            \n",
    "        else:\n",
    "            obj = bqport.load_portfolio(list_port_names[i])\n",
    "            aux_global_mat = obj.to_dataframe().reset_index()\n",
    "#             aux_global_mat['Banco'] = list_port_names[i]            \n",
    "            aux_bank_name = list_port_names[i].split('-')\n",
    "            aux_bank_name = aux_bank_name[-1]\n",
    "            aux_global_mat['Banco'] = aux_bank_name             \n",
    "            \n",
    "            global_mat = pd.concat([global_mat, aux_global_mat])\n",
    "\n",
    "        i += 1\n",
    "    \n",
    "    port_dates_list = sorted(list(global_mat['date'].unique()), reverse = True) #Ordenado de fecha más reciente a la más antigua\n",
    "    \n",
    "    #Cargar carteras en el Autocomplete de las Carteras Manejadas\n",
    "    port_patri.data = global_mat['Banco'].unique().tolist()\n",
    "    \n",
    "    #Cargar carteras en el Dropdown de los Depósitos y Retiros\n",
    "    port_depo_ret.options = global_mat['Banco'].unique().tolist()\n",
    "    \n",
    "def download_main_data (tgt = None):\n",
    "    global global_mat #Matriz de datos sin agrupar\n",
    "    global agg_global_data_mat\n",
    "    global list_unique_clasi\n",
    "    global port_dates_list #Vector de fechas de carteras cargadas en PRTU \n",
    "    global def_mat_div\n",
    "    global def_mat_cup\n",
    "    \n",
    "    #Cargar valores en las siguientes variables donde hay widgets\n",
    "    global assets_class\n",
    "    \n",
    "    request_button2.disabled = True #Durante el proceso de esta descarga de datos, se desabilita el botón para evitar errores de doble click    \n",
    "    wait_msg.layout.visibility = 'visible'\n",
    "    \n",
    "    print_message_box.value = 'Descargando cartera(s) ...'\n",
    "    \n",
    "    #Descargar cartera(s)\n",
    "    download_port()\n",
    "    \n",
    "    print_message_box.value = 'Descargando caracteriticas ...'\n",
    "    \n",
    "    #Filtrar la global_mat por las fechas indicadas en los DatePickers\n",
    "    list_first_dates = global_mat['date'].loc[global_mat['date'].apply(lambda x: False if x > datetime.datetime.strptime(date_st.value, '%d-%m-%Y') else True)].unique()\n",
    "    \n",
    "    try:\n",
    "        first_date_n_prev = list_first_dates[-1]\n",
    "    except:\n",
    "        first_date_n_prev = port_dates_list[-1]        \n",
    "    \n",
    "    #Se filtra por el límite inferior de la fecha inicial introducida\n",
    "    global_mat = global_mat.loc[global_mat['date'] >= first_date_n_prev]\n",
    "    \n",
    "    #Se filtra por el límite superior de la fecha final introducida\n",
    "    global_mat = global_mat.loc[global_mat['date'] <= datetime.datetime.strptime(date_end.value, '%d-%m-%Y')]\n",
    "    \n",
    "    \n",
    "    #Obtener el listado de los activos\n",
    "    sec_list = list(global_mat['security'].unique())\n",
    "    \n",
    "    #La descarga va a haber que hacerla por partes, ya que para los bonos y las divisas los campos FUND_ASSET_CLASS_FOCUS y COUNTRY_FULL_NAME dan problemas\n",
    "\n",
    "    #Parche para corregir los espacios que se introducen en los tickers de bonos\n",
    "    sec_list_fi = [] \n",
    "    sec_list_eq = []\n",
    "    for i in range(len(sec_list)):\n",
    "        if (('Corp' in sec_list[i])==True) or (('Govt' in sec_list[i])==True) or (('Mtge' in sec_list[i])==True) or (('Pfd' in sec_list[i])==True):\n",
    "            sec_list_fi += [sec_list[i]]\n",
    "\n",
    "        elif (('Curncy' in sec_list[i])==True):\n",
    "            sec_list_fi += [sec_list[i]]\n",
    "\n",
    "        else:\n",
    "            sec_list_eq += [sec_list[i]]\n",
    "            \n",
    "    try:\n",
    "        aux_mat = download_equity_features(sec_list_eq)        \n",
    "    \n",
    "    except:\n",
    "        aux_mat = pd.DataFrame(columns = ['security', 'País_Assets', 'Sector', 'Tipo_sec', 'Industry_group', 'País_Fondo', 'Name', 'ID_BBG', 'Tipo_fondo', 'ISIN','Maturity_Band_Focus'])\n",
    "        \n",
    "    try:\n",
    "        aux_mat2 = download_fi_or_cur_features(sec_list_fi)\n",
    "    \n",
    "    except:\n",
    "        aux_mat2 = pd.DataFrame(columns = ['País_Assets', 'Sector', 'Matur_type', 'Tipo_sec', 'Cupón', 'Coupon_freq', 'Name', 'Vencimiento', 'Coupon_nxt_date', 'Rating', 'Interests', 'security', 'ISIN'])\n",
    "    \n",
    "    #Agrupación de ambas matrices\n",
    "    aux_mat = pd.concat([aux_mat, aux_mat2]).reset_index().drop(['index'], axis=1)\n",
    "    \n",
    "    #Se adjunta esta matriz de datos a la matriz descargada con la serie temporal de las carteras \n",
    "    global_mat = pd.merge(global_mat, aux_mat, how='left', on=['security', 'security'])\n",
    "    global_mat = global_mat.rename(columns = {'currency': 'Divisa', 'quantity': 'Nominal', 'Name': 'Título'})\n",
    "    \n",
    "    #Descargar los precios necesarios para la generación del reporting de los activos del portfolio\n",
    "    download_price_global_mat()\n",
    "    \n",
    "    #Parametrización de tipologías de activos\n",
    "    data_clasification()\n",
    "    \n",
    "    #Parametrización del sector s/ la tipología del activo\n",
    "    adaptacion_sectorial()\n",
    "    \n",
    "    #Generar la matriz global del apartado del reporting \"Desglose\" \n",
    "    agg_global_data_mat = pd.DataFrame(data = {})\n",
    "    for bank in list(global_mat['Banco'].unique()):\n",
    "        first_date = sorted(list(global_mat.loc[global_mat['Banco'].isin([bank])]['date'].unique()), reverse = True)[0] #Coger la fecha de la cartera más reciente\n",
    "        agg_global_data_mat = agg_global_data_mat.append(global_mat.loc[global_mat['Banco'].isin([bank]) & global_mat['date'].isin([first_date])], ignore_index=True)\n",
    "     \n",
    "    #Agregar a la matriz agg_global_data_mat los campos de país, precio de compra inicial y precio de compra medio ponderado\n",
    "    compute_country_date_buy_and_buyprice()\n",
    "    \n",
    "    #Calcular cuales son las posiciones (Tactical/Candidate) / Core\n",
    "#     try:\n",
    "#         TacticalOrCore()\n",
    "#     except:\n",
    "#         agg_global_data_mat['Core/Tactical'] = np.nan\n",
    "        \n",
    "    print_message_box.value = 'Generando matrices de dividendos y cupones ...'      \n",
    "    \n",
    "    #Calcular dividendos\n",
    "    try:\n",
    "        dividend_matrix()\n",
    "        \n",
    "    except:\n",
    "        agg_global_data_mat['Dividendos recibidos'] = np.nan\n",
    "        def_mat_div = pd.DataFrame(columns = ['security'] + [str(i) for i in range(1,13)])\n",
    "        \n",
    "    #Calcular cupones\n",
    "    try:\n",
    "        coupon_matrix()\n",
    "        \n",
    "    except:\n",
    "        agg_global_data_mat['Intereses recibidos'] = np.nan\n",
    "        def_mat_cup = pd.DataFrame(columns = ['security'] + [str(i) for i in range(1,13)])\n",
    "    \n",
    "    try:\n",
    "        forward_coupon_matrix()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    #Ordenar matriz\n",
    "    agg_global_data_mat = agg_global_data_mat[['Clasificación', 'Banco', 'security', 'ID_BBG', 'Título', 'Divisa', 'Rating', 'País', 'Sector', 'Nominal', 'Cupón', 'Vencimiento', 'Fecha Compra',\n",
    "                                               'Precio compra', 'Precio compra Report', 'P0_Report', 'Precio Actual', 'P1_Report', 'Dividendos recibidos', 'Intereses recibidos', 'Dividend yield fecha compra',\n",
    "                                               'Interests', 'ISIN','Maturity_Band_Focus']]\n",
    "    \n",
    "    agg_global_data_mat = agg_global_data_mat.drop_duplicates().reset_index()\n",
    "    agg_global_data_mat = agg_global_data_mat.drop(['index'], axis=1)\n",
    "    \n",
    "    #Generar el Excel de Precios\n",
    "    Load_Prices_in_Excel()\n",
    "    \n",
    "    #Cargar valores en widgets\n",
    "    port_patri.data = global_mat['Banco'].unique().tolist()\n",
    "    port_depo_ret.options = global_mat['Banco'].unique().tolist()    \n",
    "    \n",
    "    list_unique_clasi = list(agg_global_data_mat['Clasificación'].unique())\n",
    "    assets_class.options = list_unique_clasi\n",
    "    assets_class.value = list_unique_clasi[0]\n",
    "    \n",
    "    ################################################\n",
    "    #Se sobreescriben los tickers de los bonos en el Excel CHECK_RF, donde se pueden ver los datos de los precios calculados según CBBT y BVAL  \n",
    "    try:\n",
    "        list_sec_fi_agg_mat = agg_global_data_mat.loc[agg_global_data_mat['Clasificación'].isin(['Bonos'])]['security'].to_frame()\n",
    "\n",
    "        book = load_workbook('CHECK_RF.xlsx')\n",
    "        writer = pd.ExcelWriter('CHECK_RF.xlsx', engine='openpyxl') \n",
    "        writer.book = book\n",
    "        writer.sheets = dict((ws.title, ws) for ws in book.worksheets)\n",
    "\n",
    "        #Limpiar valores en CHECK_RF.xlsx\n",
    "        clear_df = pd.DataFrame([[None]]*50)\n",
    "        clear_df.to_excel(writer, 'Soporte')\n",
    "        writer.save()\n",
    "\n",
    "        #Guardar nuevos valores en el Excel\n",
    "        list_sec_fi_agg_mat.to_excel(writer, 'Soporte')\n",
    "        writer.save()\n",
    "    \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    ################################################\n",
    "    \n",
    "    print_message_box.value = ''\n",
    "    request_button2.disabled = False #Una vez realizados los cálculos, se vuelve a habilitar el botón\n",
    "    \n",
    "    wait_msg.layout.visibility = 'hidden'\n",
    "    hidden_widgets2.layout.visibility = 'visible'  \n",
    "    \n",
    "    \n",
    "def download_equity_features(equity_asset_list):\n",
    "    #Petición datos para todos aquellos valores que NO sean ni bonos ni divisas\n",
    "\n",
    "    #Solicitud de datos\n",
    "    request =  bql.Request(u.list(equity_asset_list), {'Name': d.name(), 'Tipo_sec': d.SECURITY_TYP()['value'], 'Tipo_fondo': d.FUND_ASSET_CLASS_FOCUS()['value'],\n",
    "                                                       'País_Assets': f.if_(d.COUNTRY_FULL_NAME()['value'] == 'U.S.', 'UNITED STATES', d.COUNTRY_FULL_NAME()['value']),\n",
    "                                                       'País_Fondo': f.if_(d.FUND_GEO_FOCUS()['value'] == 'U.S.', 'UNITED STATES', d.FUND_GEO_FOCUS()['value']),\n",
    "                                                       'Sector': f.if_(d.GICS_SECTOR_NAME()['value'] == 'Financial', 'Financials', d.GICS_SECTOR_NAME()['value']),\n",
    "                                                       'Industry_group': d.INDUSTRY_GROUP()['value'],\n",
    "                                                       'ID_BBG': d.ID_BB_COMPANY()['value'], 'ISIN': d.ID_ISIN()['value'],\n",
    "                                                       'Maturity_Band_Focus':d.FUND_MATURITY_BAND_FOCUS()})\n",
    "    res = bq.execute(request)\n",
    "    aux_mat = bq_res_array_to_pd(res)\n",
    "    aux_mat = aux_mat.rename(columns = {'ID': 'security'})\n",
    "    \n",
    "    return aux_mat\n",
    "\n",
    "def download_fi_or_cur_features(ficur_asset_list):\n",
    "    #Petición datos para todos aquellos valores que sean bonos o divisas\n",
    "    \n",
    "    #Parche para corregir los espacios que se introducen en los tickers de bonos\n",
    "    aux_ficur_asset_list = []\n",
    "    for i in range(len(ficur_asset_list)):\n",
    "        \n",
    "        if (('Corp' in ficur_asset_list[i])==True) or (('Govt' in ficur_asset_list[i])==True) or (('Mtge' in ficur_asset_list[i])==True) or (('Pfd' in ficur_asset_list[i])==True):\n",
    "            aux_sec_list = ficur_asset_list[i].split()\n",
    "            aux_ficur_asset_list += [aux_sec_list[0] + ' ' + aux_sec_list[1]]\n",
    "            \n",
    "        else:\n",
    "            aux_ficur_asset_list += [ficur_asset_list[i]]\n",
    "    \n",
    "\n",
    "    #Solicitud de datos\n",
    "    #Asimismo, para bonos es mejor aplicar el campo BICS_LEVEL_1_SECTOR_NAME en vez del GICS_SECTOR_NAME\n",
    "    request =  bql.Request(u.list(aux_ficur_asset_list), {'Name': d.LONG_COMP_NAME(), 'Tipo_sec': d.SECURITY_TYP()['value'],\n",
    "                                                          'País_Assets': f.if_(d.COUNTRY_FULL_NAME()['value'] == 'U.S.', 'UNITED STATES', d.COUNTRY_FULL_NAME()['value']),\n",
    "                                                          'Sector': f.if_(d.BICS_LEVEL_1_SECTOR_NAME()['value'] == 'Financial', 'Financials', d.BICS_LEVEL_1_SECTOR_NAME()['value']),\n",
    "                                                          'Interests': d.INT_ACC()['value']/100,\n",
    "                                                          'Cupón': d.CPN()['value']/100, 'Coupon_nxt_date': d.NXT_CPN_DT()['value'], 'Coupon_freq': d.CPN_FREQ()['value'],\n",
    "                                                          'Vencimiento': d.MATURITY()['value'], 'Matur_type': d.MTY_TYP()['value'],\n",
    "                                                          'Rating': f.if_(f.or_(d.RTG_SP()['value'] == np.nan, d.RTG_SP()['value'] == 'N.A.'), d.BB_COMPOSITE()['value'], d.RTG_SP()['value']), 'ISIN': d.ID_ISIN()['value']})\n",
    "    \n",
    "    res = bq.execute(request)\n",
    "    aux_mat2 = bq_res_array_to_pd(res)\n",
    "    aux_mat2 = aux_mat2.drop(['ID'], axis = 1)\n",
    "    aux_mat2['security'] = ficur_asset_list\n",
    "    \n",
    "    return aux_mat2\n",
    "\n",
    "def download_price_global_mat (tgt = None):\n",
    "    global global_mat\n",
    "    \n",
    "    #Se descargan los precios necesarios para los cálculos\n",
    "    list_P1_Base = []\n",
    "    list_P1_Report = []\n",
    "    list_P0_Report = []\n",
    "    for i in range(len(global_mat)):\n",
    "                \n",
    "        #Si es un activo de Renta Fija, se descarga el px_bid\n",
    "        if (('Corp' in global_mat.loc[i]['security'])==True) or (('Govt' in global_mat.loc[i]['security'])==True) or (('Mtge' in global_mat.loc[i]['security'])==True) or (('Pfd' in global_mat.loc[i]['security'])==True) or (global_mat.loc[i]['Sector'] == 'Government'):\n",
    "        \n",
    "            request =  bql.Request(u.list(global_mat.loc[i]['security']), {'Precio Actual': d.px_bid(end = datetime.datetime.strptime(date_end.value, '%d-%m-%Y'), fill = 'prev')['value'], \n",
    "                                                                           'P1_Report': d.px_bid(end = datetime.datetime.strptime(date_end.value, '%d-%m-%Y'), fill = 'prev', currency = ac_curncy.value)['value'],\n",
    "                                                                           'P0_Report': d.px_bid(start = global_mat.loc[i]['date'], fill = 'prev', currency = ac_curncy.value)['value']})\n",
    "            \n",
    "        elif ('Curncy' in global_mat.loc[i]['security'])==True:\n",
    "            request =  bql.Request(u.list(global_mat.loc[i]['security']), {'Precio Actual': d.px_last(end = datetime.datetime.strptime(date_end.value, '%d-%m-%Y'), fill = 'prev')['value'], \n",
    "                                                                           'P1_Report': f.div(1, d.px_last(end = datetime.datetime.strptime(date_end.value, '%d-%m-%Y'), fill = 'prev', currency = ac_curncy.value))['value'],\n",
    "                                                                           'P0_Report': f.div(1, d.px_last(start = global_mat.loc[i]['date'], fill = 'prev', currency = ac_curncy.value))['value']})\n",
    "            \n",
    "        else:\n",
    "            request =  bql.Request(u.list(global_mat.loc[i]['security']), {'Precio Actual': d.px_last(end = datetime.datetime.strptime(date_end.value, '%d-%m-%Y'), fill = 'prev')['value'], \n",
    "                                                                           'P1_Report': d.px_last(end = datetime.datetime.strptime(date_end.value, '%d-%m-%Y'), fill = 'prev', currency = ac_curncy.value)['value'],\n",
    "                                                                           'P0_Report': d.px_last(start = global_mat.loc[i]['date'], fill = 'prev', currency = ac_curncy.value)['value']})            \n",
    "            \n",
    "        res = bq.execute(request)\n",
    "        \n",
    "        aux_p1_base = bq_res_array_to_pd(res)['Precio Actual'][0]\n",
    "        aux_p1_report = bq_res_array_to_pd(res)['P1_Report'][0]\n",
    "        aux_p0_report = bq_res_array_to_pd(res)['P0_Report'][0]\n",
    "\n",
    "        if global_mat.loc[i]['Divisa'] != ac_curncy.value and aux_p1_base == aux_p1_report:\n",
    "            request =  bql.Request(ac_curncy.value + global_mat.loc[i]['Divisa'] + ' Curncy', {'FX': d.px_last(end = datetime.datetime.strptime(date_end.value, '%d-%m-%Y'), fill = 'prev')['value']})\n",
    "            res = bq.execute(request)\n",
    "            fx_df = res[0].df()\n",
    "\n",
    "            aux_p1_report = aux_p1_report / fx_df['FX'][0]\n",
    "            \n",
    "            request =  bql.Request(ac_curncy.value + global_mat.loc[i]['Divisa'] + ' Curncy', {'FX': d.px_last(start = global_mat.loc[i]['date'], fill = 'prev')['value']})\n",
    "            res = bq.execute(request)\n",
    "            fx_df = res[0].df()\n",
    "\n",
    "            aux_p0_report = aux_p0_report / fx_df['FX'][0]            \n",
    "        \n",
    "        list_P1_Base += [aux_p1_base]\n",
    "        list_P1_Report += [aux_p1_report]\n",
    "        list_P0_Report += [aux_p0_report]\n",
    "\n",
    "    global_mat['Precio Actual'] = list_P1_Base\n",
    "    global_mat['P1_Report'] = list_P1_Report\n",
    "    \n",
    "    #Si la divisa de un activo está en la que se reporta, entonces el precio 'P0_Report' tiene que ser el mismo del campo 'price' \n",
    "    for i in range(len(global_mat)):\n",
    "        if global_mat.loc[i]['Divisa'] == ac_curncy.value:\n",
    "            list_P0_Report[i] = global_mat.loc[i]['price']\n",
    "    \n",
    "    global_mat['P0_Report'] = list_P0_Report\n",
    "\n",
    "def data_clasification (tgt = None):\n",
    "    global global_mat\n",
    "\n",
    "    global_mat.loc[global_mat['security'].str.contains('Curncy'), 'Clasificación'] = 'CASH'\n",
    "    global_mat.loc[(global_mat['Tipo_sec'].str.contains('Common Stock')) & (global_mat['security'].str.contains('Equity')), 'Clasificación'] = 'Acciones'\n",
    "    global_mat.loc[(global_mat['Tipo_sec'].str.contains('ADR')) & (global_mat['security'].str.contains('Equity')), 'Clasificación'] = 'Acciones'\n",
    "    global_mat.loc[global_mat['security'].str.contains('Corp'), 'Clasificación'] = 'Bonos'\n",
    "    global_mat.loc[global_mat['security'].str.contains('Mtge'), 'Clasificación'] = 'Bonos'\n",
    "    global_mat.loc[global_mat['security'].str.contains('Govt'), 'Clasificación'] = 'Tesoros'\n",
    "    global_mat.loc[global_mat['security'].str.contains(' Pfd'), 'Clasificación'] = 'Preferentes' \n",
    "    global_mat.loc[global_mat['Sector'] == 'Government', 'Clasificación'] = 'Tesoros'  \n",
    "    global_mat.loc[(global_mat['Tipo_sec'].str.contains('ETP')) & (global_mat['Tipo_fondo'].str.contains('Equity')) & (global_mat['security'].str.contains('Equity')), 'Clasificación'] = 'ETFs RV'\n",
    "    global_mat.loc[(global_mat['Tipo_sec'].str.contains('ETP')) & (global_mat['Industry_group'].str.contains('Equity Fund')) & (global_mat['security'].str.contains('Equity')), 'Clasificación'] = 'ETFs RV'\n",
    "    global_mat.loc[(global_mat['Tipo_sec'].str.contains('ETP')) & (global_mat['Tipo_fondo'].str.contains('Fixed Income')) & (global_mat['security'].str.contains('Equity')), 'Clasificación'] = 'ETFs RF'\n",
    "    global_mat.loc[(global_mat['Tipo_sec'].str.contains('ETP')) & (global_mat['Industry_group'].str.contains('Debt Fund')) & (global_mat['security'].str.contains('Equity')), 'Clasificación'] = 'ETFs RF'\n",
    "    global_mat.loc[(global_mat['Tipo_sec'].str.contains('Open-End Fund')) & (global_mat['Tipo_fondo'].str.contains('Equity')) & (global_mat['security'].str.contains('Equity')), 'Clasificación'] = 'Fondos RV'\n",
    "    global_mat.loc[(global_mat['Tipo_sec'].str.contains('Fund of Funds')) & (global_mat['Tipo_fondo'].str.contains('Equity')) & (global_mat['security'].str.contains('Equity')), 'Clasificación'] = 'Fondos RV'\n",
    "    global_mat.loc[(global_mat['Tipo_sec'].str.contains('Open-End Fund')) & (global_mat['Industry_group'].str.contains('Equity Fund')) & (global_mat['security'].str.contains('Equity')), 'Clasificación'] = 'Fondos RV'\n",
    "    global_mat.loc[(global_mat['Tipo_sec'].str.contains('Fund of Funds')) & (global_mat['Industry_group'].str.contains('Equity Fund')) & (global_mat['security'].str.contains('Equity')), 'Clasificación'] = 'Fondos RV'\n",
    "    global_mat.loc[(global_mat['Tipo_sec'].str.contains('Open-End Fund')) & (global_mat['Tipo_fondo'].str.contains('Fixed Income')) & (global_mat['security'].str.contains('Equity')), 'Clasificación'] = 'Fondos RF'\n",
    "    global_mat.loc[(global_mat['Tipo_sec'].str.contains('Fund of Funds')) & (global_mat['Tipo_fondo'].str.contains('Fixed Income')) & (global_mat['security'].str.contains('Equity')), 'Clasificación'] = 'Fondos RF'\n",
    "    global_mat.loc[(global_mat['Tipo_sec'].str.contains('Open-End Fund')) & (global_mat['Industry_group'].str.contains('Debt Fund')) & (global_mat['security'].str.contains('Equity')), 'Clasificación'] = 'Fondos RF'\n",
    "    global_mat.loc[(global_mat['Tipo_sec'].str.contains('Fund of Funds')) & (global_mat['Industry_group'].str.contains('Debt Fund')) & (global_mat['security'].str.contains('Equity')), 'Clasificación'] = 'Fondos RF'\n",
    "    global_mat['Clasificación'] = global_mat['Clasificación'].fillna('Sin Clasificar')    \n",
    "\n",
    "def compute_country_date_buy_and_buyprice (tgt = None):\n",
    "    global agg_global_data_mat\n",
    "    \n",
    "    # Asignar a cada título su país\n",
    "    # Se juntan los valores de las columnas País_Assets y País_Fondo en una sola columna llamda País en función de la tipología del activo\n",
    "    for clasi in list(global_mat['Clasificación'].unique()):\n",
    "        if clasi == 'Acciones' or clasi == 'Bonos' or clasi == 'CASH' or clasi == 'Preferentes' or clasi == 'Tesoros':       \n",
    "            filtered_mat = global_mat.loc[global_mat['Clasificación'].isin([clasi])][['security', 'País_Assets']].drop_duplicates()\n",
    "            filtered_mat = filtered_mat.rename(index=str, columns={'País_Assets': 'País'})\n",
    "        else:\n",
    "            filtered_mat = global_mat.loc[global_mat['Clasificación'].isin([clasi])][['security', 'País_Fondo']].drop_duplicates()\n",
    "            filtered_mat = filtered_mat.rename(index=str, columns={'País_Fondo': 'País'})\n",
    "\n",
    "        if clasi == list(global_mat['Clasificación'].unique())[0]:\n",
    "            agg_global_data_mat = pd.merge(agg_global_data_mat, filtered_mat,  how='left', on=['security', 'security'])\n",
    "        else:\n",
    "            aux_agg_global_data_mat = pd.merge(agg_global_data_mat.loc[:, agg_global_data_mat.columns != 'País'], filtered_mat,  how='left', on=['security', 'security'])\n",
    "            agg_global_data_mat['País'] = agg_global_data_mat['País'].fillna(value = aux_agg_global_data_mat['País'])\n",
    "\n",
    "    #Buscar Fecha de compra inicial        \n",
    "    list_dates = []\n",
    "    for found_bank, found_asset in zip(agg_global_data_mat['Banco'].tolist(), agg_global_data_mat['security'].tolist()):\n",
    "        aux_list_dates = global_mat.loc[global_mat['Banco'].isin([found_bank]) & global_mat['security'].isin([found_asset])].sort_values(by=['date'], ascending = True)['date'].tolist()\n",
    "        list_dates += [aux_list_dates[0]]\n",
    "\n",
    "    agg_global_data_mat['Fecha Compra'] = list_dates\n",
    "    \n",
    "    #calculo el div_per_share de los equities ya que no era un campo dado de alto en global_mat\n",
    "    list_dvd_yield = []\n",
    "    global_mat_div_share_aux = global_mat\n",
    "    for idx in range(len(global_mat_div_share_aux)):\n",
    "        if 'Equity' in global_mat_div_share_aux.loc[idx]['security']:\n",
    "            try:\n",
    "                request = bql.Request(global_mat_div_share_aux.loc[idx]['security'], {'dvd_yld': d.IS_DIV_PER_SHR(as_of_date = global_mat_div_share_aux.loc[idx]['date'].to_pydatetime(),\n",
    "                                                                                                             fill = 'prev',\n",
    "                                                                                                             currency = ac_curncy.value)})\n",
    "                res = bq.execute(request)\n",
    "                aux_res = res[0].df().reset_index()\n",
    "                list_dvd_yield += [aux_res['dvd_yld'].values[0]]\n",
    "\n",
    "            except:\n",
    "                list_dvd_yield += [np.nan]\n",
    "\n",
    "        else:\n",
    "            list_dvd_yield += [np.nan]    \n",
    "\n",
    "    global_mat_div_share_aux['Dividend yield fecha compra'] = list_dvd_yield\n",
    "    global_mat_div_share_aux = global_mat_div_share_aux[['date','security','Nominal','Banco','Dividend yield fecha compra']]\n",
    "\n",
    "\n",
    "    #Div_per_share ponderado por compra\n",
    "    list_weighted_div_per = []\n",
    "    for found_bank, found_asset in zip(agg_global_data_mat['Banco'].tolist(), agg_global_data_mat['security'].tolist()):\n",
    "        #Se genera una matriz de compra de cada activo\n",
    "        aux_mat = global_mat_div_share_aux.loc[global_mat_div_share_aux[['Banco', 'security']].isin([found_bank, found_asset]).all(axis='columns')][['date', 'Nominal', 'Dividend yield fecha compra']].reset_index()\n",
    "        aux_mat['Compra_Venta'] = aux_mat['Nominal'].diff()\n",
    "        aux_mat['Compra_Venta'] = aux_mat['Compra_Venta'].fillna(aux_mat['Nominal'][0])\n",
    "        aux_mat = aux_mat.loc[aux_mat['Compra_Venta']>0] #Filtras las Compras\n",
    "\n",
    "        list_weighted_div_per += [sum(aux_mat['Nominal']*aux_mat['Dividend yield fecha compra'])/sum(aux_mat['Nominal'])]\n",
    "\n",
    "    agg_global_data_mat['Dividend yield fecha compra'] = list_weighted_div_per\n",
    "\n",
    "    #Precio medio ponderado de compra\n",
    "    list_weighted_prices = []\n",
    "    list_weighted_prices_reporting_fx = []\n",
    "    for found_bank, found_asset in zip(agg_global_data_mat['Banco'].tolist(), agg_global_data_mat['security'].tolist()):\n",
    "        #Se genera una matriz de compra de cada activo\n",
    "        aux_mat = global_mat.loc[global_mat[['Banco', 'security']].isin([found_bank, found_asset]).all(axis='columns')][['date', 'Nominal', 'price', 'P0_Report']].reset_index()\n",
    "        aux_mat['Compra_Venta'] = aux_mat['Nominal'].diff()\n",
    "        aux_mat['Compra_Venta'] = aux_mat['Compra_Venta'].fillna(aux_mat['Nominal'][0])\n",
    "        aux_mat = aux_mat.loc[aux_mat['Compra_Venta']>0] #Filtras las Compras\n",
    "\n",
    "        list_weighted_prices += [sum(aux_mat['Nominal']*aux_mat['price'])/sum(aux_mat['Nominal'])]\n",
    "        list_weighted_prices_reporting_fx += [sum(aux_mat['Nominal']*aux_mat['P0_Report'])/sum(aux_mat['Nominal'])]\n",
    "    \n",
    "    agg_global_data_mat['Precio compra'] = list_weighted_prices\n",
    "    agg_global_data_mat['Precio compra Report'] = list_weighted_prices_reporting_fx\n",
    "    \n",
    "# def TacticalOrCore (tgt = None):\n",
    "#     global agg_global_data_mat\n",
    "\n",
    "#     list_eq = agg_global_data_mat.loc[agg_global_data_mat['Clasificación'].isin(['Acciones']), 'security'].tolist()\n",
    "#     list_id_bbg = agg_global_data_mat.loc[agg_global_data_mat['Clasificación'].isin(['Acciones']), 'ID_BBG'].tolist()\n",
    "\n",
    "#     df = pd.DataFrame(data= {'ID': list_eq, 'ID_BBG': list_id_bbg})\n",
    "#     res_df = pd.DataFrame(data={'Core/Tactical': [], 'ID_BBG': []})\n",
    "\n",
    "#     for eq in list_eq:\n",
    "#         try:\n",
    "\n",
    "#             univ1 = u.list(eq)\n",
    "#             univ1 = u.translatesymbols(univ1, TARGETIDTYPE=\"FUNDAMENTALTICKER\")\n",
    "\n",
    "#             univ2 = u.members(['SPDAUDT Index', 'SPDAEEP Index', 'SPGDAUP Index', 'SREITTGL Index'])\n",
    "#             univ2 = u.translatesymbols(univ2, TARGETIDTYPE=\"FUNDAMENTALTICKER\")\n",
    "\n",
    "#             ids_in_idx = u.intersect(univ1, univ2)\n",
    "#             req = bql.Request(ids_in_idx, {'Core/Tactical': d.id()['value'], 'ID_BBG': d.ID_BB_COMPANY()['value']})\n",
    "#             res = bq.execute(req)\n",
    "#             aux_res_df = bq_res_array_to_pd(res)\n",
    "#             aux_res_df = aux_res_df.drop(['ID'], axis = 1)\n",
    "#             res_df = res_df.append(aux_res_df, ignore_index = True) \n",
    "\n",
    "#         except:\n",
    "#             pass\n",
    "\n",
    "#     df = pd.merge(df, res_df, how='left', on=['ID_BBG'])\n",
    "#     df = df.rename(columns = {'ID': 'security'})\n",
    "#     df = df.drop(['ID_BBG'], axis = 1)\n",
    "#     df['Core/Tactical'] = df['Core/Tactical'].fillna('Candidate/Tactical')\n",
    "\n",
    "#     for i_idx in range(len(df)):\n",
    "#         if df.loc[i_idx, 'Core/Tactical'] != 'Candidate/Tactical':\n",
    "#             df.loc[i_idx, 'Core/Tactical'] = 'Core' \n",
    "\n",
    "#     agg_global_data_mat = pd.merge(agg_global_data_mat, df, how='left', on=['security'])     \n",
    "    \n",
    "def adaptacion_sectorial (tgt = None):\n",
    "    global global_mat\n",
    "    \n",
    "    list_def_sec = []\n",
    "    for idx in range(len(global_mat)):\n",
    "        if global_mat.loc[idx, 'Clasificación'] == 'ETFs RV' or global_mat.loc[idx, 'Clasificación'] == 'ETFs RF' or global_mat.loc[idx, 'Clasificación'] == 'Fondos RV' or global_mat.loc[idx, 'Clasificación'] == 'Fondos RF':\n",
    "            list_def_sec += [global_mat.loc[idx, 'Industry_group']]\n",
    "        else:\n",
    "            list_def_sec += [global_mat.loc[idx, 'Sector']]\n",
    "    list_def_sec\n",
    "\n",
    "    global_mat['aux_Sector'] = list_def_sec\n",
    "    global_mat = global_mat.drop(['Sector'], axis=1)    \n",
    "    global_mat = global_mat.rename(columns = {'aux_Sector': 'Sector'})\n",
    "    \n",
    "def gen_carteras_manejadas(tgt = None):\n",
    "    global df_bancos_manejada\n",
    "    \n",
    "    #Ver si existe df_bancos_manejada, si no existe crearla, si existe añadir el valor\n",
    "    try:\n",
    "        df_bancos_manejada.columns\n",
    "        df_bancos_manejada = df_bancos_manejada.append(pd.DataFrame(data = {'Banco': port_patri.value, 'Fecha Inicial': float(patri_st_date.value), 'Fecha Final': float(patri_end_date.value), 'Tipo': 'Manejada'}, index = [0]), ignore_index=True)\n",
    "        \n",
    "    except:\n",
    "        df_bancos_manejada = pd.DataFrame(data = {'Banco': port_patri.value, 'Fecha Inicial': float(patri_st_date.value), 'Fecha Final': float(patri_end_date.value), 'Tipo': 'Manejada'}, index = [0])\n",
    "        \n",
    "    print_message_box.value = 'Añadida cartera manejada'\n",
    "    \n",
    "def generate_dep_ret(tgt = None):\n",
    "    global dep_ret_mat\n",
    "    \n",
    "    #Ver si existe dep_ret_mat, si no existe crearla, si existe añadir el valor\n",
    "    try:\n",
    "        dep_ret_mat.columns\n",
    "        dep_ret_mat = dep_ret_mat.append(pd.DataFrame(data={'Banco': port_depo_ret.value, 'Valor': float(depo_ret.value)}, index = [0]), ignore_index=True)\n",
    "        \n",
    "    except:\n",
    "        dep_ret_mat = pd.DataFrame(data = {'Banco': port_depo_ret.value, 'Valor': float(depo_ret.value)}, index = [0])\n",
    "        \n",
    "    print_message_box.value = 'Añadido depósito/retiro'\n",
    "    \n",
    "def dividend_matrix(tgt = None): \n",
    "    global global_mat\n",
    "    global agg_global_data_mat\n",
    "    \n",
    "    global def_mat_div #Aquí se genera la matriz de dividendos para el reporting\n",
    "    global tot_div    \n",
    "    \n",
    "    dividends_df = pd.DataFrame(data={})\n",
    "\n",
    "    #Aplicar los cálculos unicamente sobre los tickers que contengan la palabra Equity\n",
    "    list_eq_tickers = []\n",
    "    for eq in global_mat['security'].unique():\n",
    "        if 'Equity' in eq:\n",
    "            list_eq_tickers += [eq]\n",
    "\n",
    "    for eq in list_eq_tickers:\n",
    "        i_start_date = datetime.datetime.strptime(date_st.value, '%d-%m-%Y')\n",
    "        i_end_date = datetime.datetime.strptime(date_end.value, '%d-%m-%Y')\n",
    "\n",
    "        try:\n",
    "            request = bql.Request(eq, {'Dividendos': f.dropna(d.cash_divs(dates = f.range(i_start_date, i_end_date), ca_date_type = 'PAY_DATE', currency = ac_curncy.value))})\n",
    "            res = bq.execute(request)\n",
    "            aux_res = res[0].df().reset_index()\n",
    "            aux_res['aux'] = range(len(aux_res)) #Se Asigna una variable auxiliar para identificar dónde se tienen que colocar las fechas ex-dividend\n",
    "\n",
    "            #Para buscar las fechas Ex-Dividend, se va a coger el último valor del dividendo pagado y al primero se le resta 1 año.\n",
    "            #No obstante, en vez de sacar el histórico, sacamos el número mínimo necesario de las fechas ex-dividends que necesitamos con la función last\n",
    "            #Se alinean los valores con la variable auxiliar creada al hacer un merge\n",
    "\n",
    "            if len(aux_res) > 1:\n",
    "                aux_st_dt = aux_res['DATE'].values[0]\n",
    "                aux_end_dt = aux_res['DATE'].values[-1]\n",
    "\n",
    "            else:\n",
    "                aux_st_dt = aux_res['DATE'].values[0]\n",
    "                aux_end_dt = aux_res['DATE'].values[0]\n",
    "\n",
    "            pay_st_dt = pd.to_datetime(str(aux_st_dt - np.timedelta64(8760, 'h'))).strftime('%Y-%m-%d') \n",
    "            pay_end_dt = pd.to_datetime(str(aux_end_dt)).strftime('%Y-%m-%d')\n",
    "\n",
    "            request = bql.Request(eq, {'Dividendos': f.last(f.dropna(d.cash_divs(dates = f.range(pay_st_dt, pay_end_dt), ca_date_type = 'EFFECTIVE_DATE', currency = ac_curncy.value)), n = len(aux_res))})\n",
    "            res = bq.execute(request)\n",
    "            aux_res2 = res[0].df().reset_index().rename(index=str, columns={'DATE': 'Ex-div_date'})\n",
    "            aux_res2['aux'] = range(len(aux_res2))\n",
    "\n",
    "            aux_res = pd.merge(aux_res, aux_res2[['aux', 'Ex-div_date']], how = 'left', on = ['aux'])\n",
    "\n",
    "            dividends_df = dividends_df.append(aux_res, ignore_index = True)\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    dividends_df = dividends_df.dropna(subset=['Dividendos'])     \n",
    "    \n",
    "    df_tick_banks = global_mat[['Banco', 'security']].drop_duplicates()\n",
    "    df_tick_banks = df_tick_banks.rename(index=str, columns={'security': 'ID'}) \n",
    "\n",
    "    dividends_df = pd.merge(dividends_df, df_tick_banks, how='left', on=['ID'])    \n",
    "\n",
    "    #Se genera una pivot table donde las filas son los activos y las cantidas y las columnas son los periodos temporales que se han cargado\n",
    "    n_assets = pd.DataFrame(data={})\n",
    "\n",
    "    for i_bank in global_mat['Banco'].unique():\n",
    "        aux_i_global_mat = global_mat.loc[global_mat['Banco'].isin([i_bank])]\n",
    "        n_assets = pd.concat([n_assets, aux_i_global_mat[['date', 'Banco', 'security', 'Nominal']].pivot_table(index = ['Banco', 'security'], columns = 'date', values = 'Nominal').fillna(0).reset_index()], ignore_index=True)\n",
    "\n",
    "    list_dates_concat = []\n",
    "    for i_dates_concat in n_assets.columns:\n",
    "        if i_dates_concat != 'Banco' and i_dates_concat != 'security':\n",
    "            list_dates_concat += [i_dates_concat]\n",
    "\n",
    "    n_assets = n_assets[['Banco', 'security'] + sorted(list_dates_concat)]\n",
    "    n_assets = n_assets.fillna(method='ffill', axis = 1)\n",
    "\n",
    "    list_amount_div = []\n",
    "    for i in range(len(dividends_df)):\n",
    "        aux_mat = n_assets.loc[n_assets['security'].isin([dividends_df['ID'].iloc[i]]) & n_assets['Banco'].isin([dividends_df['Banco'].iloc[i]])].drop(['Banco', 'security'], axis=1) \n",
    "\n",
    "        try:\n",
    "            if aux_mat.loc[:,aux_mat.columns <= dividends_df['Ex-div_date'].iloc[i]].iloc[:,-1].values[0] != 0: #Si no se ha comprado el valor antes de la fecha ex-dividend, entonces no se podrá computar el dividendo recibido en la fecha de su pago            \n",
    "                date_quantity = aux_mat.loc[:,aux_mat.columns <= dividends_df['Ex-div_date'].iloc[i]].iloc[:,-1].values[0]\n",
    "                list_amount_div += [date_quantity * dividends_df['Dividendos'].iloc[i]]\n",
    "\n",
    "            else:\n",
    "                list_amount_div += [0]\n",
    "\n",
    "        except: #Si no hay nada comprado para el activo en el que en esa fecha se paga un dividendo\n",
    "            list_amount_div += [0]\n",
    "\n",
    "    dividends_df['Total_Div'] = pd.Series(list_amount_div).apply(pd.to_numeric, errors='coerce').fillna(0)         \n",
    "    dividends_df['mes'] = dividends_df['DATE'].map(lambda x: x.month)\n",
    "    dividends_df['año'] = dividends_df['DATE'].map(lambda x: x.year)\n",
    "\n",
    "    #Generar la matriz de dividendos del último año\n",
    "    last_year = np.sort(dividends_df['año'].unique())[-1]\n",
    "    fil_dividends_df = dividends_df.loc[dividends_df['año'].isin([last_year])]\n",
    "\n",
    "    cum_dividends_df = pd.pivot_table(fil_dividends_df, values='Total_Div', index=['ID'],columns=['mes'], aggfunc=np.sum)\n",
    "    tot_div = cum_dividends_df.sum(axis=1,skipna=True).sum(axis=0,skipna=True)\n",
    "\n",
    "    def_mat_div = pd.DataFrame(data={})\n",
    "    for col in cum_dividends_df.columns.tolist():\n",
    "        def_mat_div[str(col)] = cum_dividends_df[col].tolist()\n",
    "\n",
    "    if cum_dividends_df.columns.tolist() != list(range(1,13)): #Ver si faltan meses por incluir en el año\n",
    "        for left_month in list(set(list(range(1,13))) - set(cum_dividends_df.columns.tolist())):\n",
    "            def_mat_div[str(left_month)] = np.nan\n",
    "\n",
    "    def_mat_div['security'] = cum_dividends_df.index.tolist() \n",
    "    \n",
    "#     def_mat_div = def_mat_div[['Ticker'] + [str(i) for i in range(1,13)]] #Ordenar la matriz\n",
    "#     def_mat_div['Total'] = def_mat_div.sum(axis=1,skipna=True)\n",
    "#     def_mat_div = def_mat_div.append(def_mat_div.sum(numeric_only=True), ignore_index=True)\n",
    "#     def_mat_div.loc[len(def_mat_div)-1, 'Ticker'] = 'Total'\n",
    "#     def_mat_div = def_mat_div.loc[def_mat_div['Total'] != 0]\n",
    "\n",
    "    #Una vez calucalda la matriz de dividendos que servirá para el Global Reporting, generar el df para concatenar la cantidad de dividendos recibidos por ticker y banco\n",
    "    new_mat_div = pd.pivot_table(dividends_df, values='Total_Div', index=['ID', 'Banco'],columns=['mes'], aggfunc=np.sum)\n",
    "\n",
    "    new_mat_div['Dividendos recibidos'] = new_mat_div.sum(axis=1,skipna=True)\n",
    "    new_mat_div = new_mat_div.reset_index()\n",
    "    new_mat_div = new_mat_div.rename(index=str, columns={'ID': 'security'})\n",
    "    new_mat_div = new_mat_div[['security', 'Banco', 'Dividendos recibidos']]\n",
    "\n",
    "    agg_global_data_mat = pd.merge(agg_global_data_mat, new_mat_div, how='left', on=['security', 'Banco'])  \n",
    "    \n",
    "    #Calcular el dividend yield\n",
    "\n",
    "def coupon_matrix(tgt = None):\n",
    "    global global_mat\n",
    "    global agg_global_data_mat\n",
    "    \n",
    "    global def_mat_cup #Aquí se genera la matriz de cupones para el reporting\n",
    "    global tot_cup\n",
    "    \n",
    "    # Cálculo matriz cupones recibidos\n",
    "\n",
    "   #Se intenta generar un DataFrame como el que devolvía la query de los dividendos recibidos por activo\n",
    "    coupons_df = pd.DataFrame(data={})\n",
    "\n",
    "    aux_coupons_df = global_mat.loc[global_mat['Clasificación'].isin(['Bonos','Tesoros'])][['Banco', 'security', 'Coupon_freq', 'Coupon_nxt_date', 'Cupón', 'Divisa']].drop_duplicates()\n",
    "\n",
    "    start_dt = datetime.datetime.strptime(date_st.value, '%d-%m-%Y')\n",
    "    end_dt = datetime.datetime.strptime(date_end.value, '%d-%m-%Y')\n",
    "\n",
    "    for i_idx in aux_coupons_df.index:\n",
    "        try:\n",
    "            i_sec_nxt_cup = aux_coupons_df.loc[i_idx, 'Coupon_nxt_date'].to_pydatetime()\n",
    "            i_sec_cup = aux_coupons_df.loc[i_idx, 'Cupón']\n",
    "            i_sec_cup_feq = aux_coupons_df.loc[i_idx, 'Coupon_freq']\n",
    "            i_sec_cup = i_sec_cup/i_sec_cup_feq\n",
    "            i_sec_cup_feq = 12/i_sec_cup_feq\n",
    "\n",
    "            list_cup_dates = []\n",
    "            time_count = i_sec_nxt_cup\n",
    "            while start_dt <= time_count:\n",
    "                if time_count <= end_dt:\n",
    "                    list_cup_dates += [time_count]\n",
    "\n",
    "                time_count -= datetime.timedelta(i_sec_cup_feq*365/12)\n",
    "\n",
    "            if len(list_cup_dates) > 0:\n",
    "                i_sec_coupons_df = pd.DataFrame(data={'security': aux_coupons_df.loc[i_idx, 'security'],\n",
    "                                                      'Coupon_Payment_Dt': list_cup_dates, 'Cupón': i_sec_cup,\n",
    "                                                      'Divisa': aux_coupons_df.loc[i_idx, 'Divisa'],\n",
    "                                                      'Banco': aux_coupons_df.loc[i_idx, 'Banco']})\n",
    "                coupons_df = coupons_df.append(i_sec_coupons_df, ignore_index=True)\n",
    "\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    coupons_df = coupons_df.drop_duplicates() \n",
    "\n",
    "     #Una vez generado el DataFrame de forma similar al los dividendos recibidos, el resto de los cálculos se realizan de forma análoga\n",
    "\n",
    "    #Se genera una pivot table donde las filas son los activos y las cantidas y las columnas son los periodos temporales que se han cargado\n",
    "    n_assets = pd.DataFrame(data={})\n",
    "\n",
    "    for i_bank in global_mat['Banco'].unique():\n",
    "        aux_i_global_mat = global_mat.loc[global_mat['Banco'].isin([i_bank])]\n",
    "        n_assets = pd.concat([n_assets, aux_i_global_mat[['date', 'Banco', 'security', 'Nominal']].pivot_table(index = ['Banco', 'security'], columns = 'date', values = 'Nominal').fillna(0).reset_index()], ignore_index=True)\n",
    "\n",
    "    list_dates_concat = []\n",
    "    for i_dates_concat in n_assets.columns:\n",
    "        if i_dates_concat != 'Banco' and i_dates_concat != 'security':\n",
    "            list_dates_concat += [i_dates_concat]\n",
    "\n",
    "    n_assets = n_assets[['Banco', 'security'] + sorted(list_dates_concat)]\n",
    "    n_assets = n_assets.fillna(method='ffill', axis = 1)\n",
    "\n",
    "    list_amount_cup = []\n",
    "    for i in range(len(coupons_df)):\n",
    "        aux_mat = n_assets.loc[n_assets['security'].isin([coupons_df['security'].iloc[i]]) & n_assets['Banco'].isin([coupons_df['Banco'].iloc[i]])].drop(['Banco', 'security'], axis=1) \n",
    "\n",
    "        try:\n",
    "            date_quantity = aux_mat.loc[:,aux_mat.columns <= coupons_df['Coupon_Payment_Dt'].iloc[i]].iloc[:,-1].values[0]\n",
    "            list_amount_cup += [date_quantity * coupons_df['Cupón'].iloc[i]]        \n",
    "\n",
    "        except: #Si no hay nada comprado para el activo en el que en esa fecha se paga un dividendo ***\n",
    "            list_amount_cup += [0]   \n",
    "\n",
    "\n",
    "    #Incluir preferentes\n",
    "    if len(global_mat.loc[global_mat['Clasificación'].isin(['Preferentes'])])>0:\n",
    "\n",
    "        pref_carry_df = pd.DataFrame(data={})\n",
    "\n",
    "        pref_list = list(global_mat.loc[global_mat['Clasificación'].isin(['Preferentes'])]['security'].unique())\n",
    "\n",
    "        for eq in pref_list:\n",
    "            i_start_date = datetime.datetime.strptime(date_st.value, '%d-%m-%Y')\n",
    "            i_end_date = datetime.datetime.strptime(date_end.value, '%d-%m-%Y')\n",
    "\n",
    "            try:\n",
    "                request = bql.Request(eq, {'Cupón': f.dropna(d.cash_divs(CA_ADJ='RAW', dates = f.range(i_start_date, i_end_date), ca_date_type = 'PAY_DATE', currency = ac_curncy.value))})\n",
    "                res = bq.execute(request)\n",
    "                aux_res = res[0].df().reset_index()\n",
    "                aux_res['aux'] = range(len(aux_res)) #Se Asigna una variable auxiliar para identificar dónde se tienen que colocar las fechas ex-dividend\n",
    "\n",
    "                #Para buscar las fechas Ex-Dividend, se va a coger el último valor del dividendo pagado y al primero se le resta 1 año.\n",
    "                #No obstante, en vez de sacar el histórico, sacamos el número mínimo necesario de las fechas ex-dividends que necesitamos con la función last\n",
    "                #Se alinean los valores con la variable auxiliar creada al hacer un merge\n",
    "\n",
    "                if len(aux_res) > 1:\n",
    "                    aux_st_dt = aux_res['DATE'].values[0]\n",
    "                    aux_end_dt = aux_res['DATE'].values[-1]\n",
    "\n",
    "                else:\n",
    "                    aux_st_dt = aux_res['DATE'].values[0]\n",
    "                    aux_end_dt = aux_res['DATE'].values[0]\n",
    "\n",
    "                pay_st_dt = pd.to_datetime(str(aux_st_dt - np.timedelta64(8760, 'h'))).strftime('%Y-%m-%d') \n",
    "                pay_end_dt = pd.to_datetime(str(aux_end_dt)).strftime('%Y-%m-%d')\n",
    "\n",
    "                request = bql.Request(eq, {'Cupón': f.last(f.dropna(d.cash_divs(CA_ADJ='RAW', dates = f.range(pay_st_dt, pay_end_dt), ca_date_type = 'EFFECTIVE_DATE', currency = ac_curncy.value)), n = len(aux_res))})\n",
    "                res = bq.execute(request)\n",
    "                aux_res2 = res[0].df().reset_index().rename(index=str, columns={'DATE': 'Ex-div_date'})\n",
    "                aux_res2['aux'] = range(len(aux_res2))\n",
    "\n",
    "                aux_res = pd.merge(aux_res, aux_res2[['aux', 'Ex-div_date']], how = 'left', on = ['aux'])\n",
    "\n",
    "                pref_carry_df = pref_carry_df.append(aux_res, ignore_index = True)\n",
    "\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        pref_carry_df = pref_carry_df.dropna(subset=['Cupón'])\n",
    "        pref_carry_df = pref_carry_df.drop(['aux'], axis=1)\n",
    "\n",
    "        df_tick_banks = global_mat[['Banco', 'security']].drop_duplicates()\n",
    "        df_tick_banks = df_tick_banks.rename(index=str, columns={'security': 'ID'}) \n",
    "\n",
    "        pref_carry_df = pd.merge(pref_carry_df, df_tick_banks, how='left', on=['ID'])    \n",
    "\n",
    "        list_amount_pref = []\n",
    "        for i in range(len(pref_carry_df)):\n",
    "            aux_mat = n_assets.loc[n_assets['security'].isin([pref_carry_df['ID'].iloc[i]]) & n_assets['Banco'].isin([pref_carry_df['Banco'].iloc[i]])].drop(['Banco', 'security'], axis=1) \n",
    "\n",
    "            try:\n",
    "                if aux_mat.loc[:,aux_mat.columns <= pref_carry_df['Ex-div_date'].iloc[i]].iloc[:,-1].values[0] != 0: #Si no se ha comprado el valor antes de la fecha ex-dividend, entonces no se podrá computar el dividendo recibido en la fecha de su pago            \n",
    "                    date_quantity = aux_mat.loc[:,aux_mat.columns <= pref_carry_df['DATE'].iloc[i]].iloc[:,-1].values[0]\n",
    "                    list_amount_pref += [date_quantity * pref_carry_df['Cupón'].iloc[i]]\n",
    "\n",
    "                else:\n",
    "                    list_amount_pref += [0]\n",
    "\n",
    "            except: #Si no hay nada comprado para el activo en el que en esa fecha se paga el carry del preferente\n",
    "                list_amount_pref += [0]\n",
    "\n",
    "        #Adaptar el formato de los pagos de las preferentes (similar al de dividendos) al de los cupones\n",
    "        pref_carry_df = pref_carry_df.rename(index=str, columns={'ID': 'security', 'DATE': 'Coupon_Payment_Dt', 'CURRENCY': 'Divisa'})\n",
    "\n",
    "        #Agrupar las preferentes a los cupones        \n",
    "        coupons_df = coupons_df.append(pref_carry_df[['security', 'Coupon_Payment_Dt', 'Cupón', 'Divisa', 'Banco']], ignore_index=True)    \n",
    "\n",
    "        list_amount_cup = list_amount_cup + list_amount_pref\n",
    "\n",
    "    coupons_df['Total_Coupon'] = pd.Series(list_amount_cup).apply(pd.to_numeric, errors='coerce').fillna(0)  \n",
    "    coupons_df['mes'] = coupons_df['Coupon_Payment_Dt'].map(lambda x: x.month)\n",
    "\n",
    "    #En caso de que algún bono esté en otra divisa, calcular el cambio de divisa\n",
    "    list_real_amount_cup = []\n",
    "    for i_idx in coupons_df.index:\n",
    "        divisa_activo = coupons_df.loc[i_idx, 'Divisa']\n",
    "        if divisa_activo != ac_curncy.value:\n",
    "            request =  bql.Request(ac_curncy.value + divisa_activo + ' Curncy', {'FX': d.px_last(start = coupons_df.loc[i_idx, 'Coupon_Payment_Dt'].to_pydatetime(), fill = 'prev')['value']})\n",
    "            res = bq.execute(request)\n",
    "            fx_df = res[0].df()\n",
    "\n",
    "            list_real_amount_cup += [coupons_df.loc[i_idx, 'Total_Coupon'] / fx_df['FX'][0]]\n",
    "        else:\n",
    "            list_real_amount_cup += [coupons_df.loc[i_idx, 'Total_Coupon']]\n",
    "\n",
    "    coupons_df['Real_Total_Coupon'] = list_real_amount_cup \n",
    "    coupons_df['año'] = coupons_df['Coupon_Payment_Dt'].map(lambda x: x.year)\n",
    "\n",
    "    #Generar la matriz de cupones del último año\n",
    "    last_year = np.sort(coupons_df['año'].unique())[-1]\n",
    "    fil_coupons_df = coupons_df.loc[coupons_df['año'].isin([last_year])]\n",
    "\n",
    "    cum_coupons_df = pd.pivot_table(fil_coupons_df, values='Real_Total_Coupon', index=['security'],columns=['mes'], aggfunc=np.sum)\n",
    "    tot_cup = cum_coupons_df.apply(pd.to_numeric, errors='coerce').sum().sum()\n",
    "\n",
    "    def_mat_cup = pd.DataFrame(data={})\n",
    "    for col in cum_coupons_df.columns.tolist():\n",
    "        def_mat_cup[str(col)] = cum_coupons_df[col].tolist()\n",
    "\n",
    "    if cum_coupons_df.columns.tolist() != list(range(1,13)): #Ver si faltan meses por incluir en el año\n",
    "        for left_month in list(set(list(range(1,13))) - set(cum_coupons_df.columns.tolist())):\n",
    "            def_mat_cup[str(left_month)] = np.nan\n",
    "\n",
    "    def_mat_cup['security'] = cum_coupons_df.index.tolist()\n",
    "    #     def_mat_cup = def_mat_cup[['Ticker'] + [str(i) for i in range(1,13)]] #Ordenar la matriz\n",
    "    #     def_mat_cup['Total'] = def_mat_cup.sum(axis=1,skipna=True)\n",
    "    #     def_mat_cup = def_mat_cup.append(def_mat_cup.sum(numeric_only=True), ignore_index=True)\n",
    "    #     def_mat_cup.loc[len(def_mat_cup)-1, 'Ticker'] = 'Total'\n",
    "\n",
    "    new_mat_cup = pd.pivot_table(coupons_df, values='Real_Total_Coupon', index=['security', 'Banco'],columns=['mes'], aggfunc=np.sum)\n",
    "\n",
    "    new_mat_cup['Intereses recibidos'] = new_mat_cup.apply(pd.to_numeric, errors='coerce').sum(axis=1)\n",
    "    new_mat_cup = new_mat_cup.reset_index()\n",
    "    new_mat_cup = new_mat_cup[['security', 'Banco', 'Intereses recibidos']]\n",
    "\n",
    "    agg_global_data_mat = pd.merge(agg_global_data_mat, new_mat_cup, how='left', on=['security', 'Banco'])\n",
    "        \n",
    "def forward_coupon_matrix(tgt = None):\n",
    "    global global_mat\n",
    "    global agg_global_data_mat\n",
    "    global aux_coupons_df\n",
    "    global def_forward_mat_cup #Aquí se genera la matriz de cupones que se recibirán para el reporting    \n",
    "    \n",
    "    # Generar la matriz de dividendos futuros será similar a lo anterior, solo que se coge como end_date 12-31-2XXX\n",
    "    coupons_df = pd.DataFrame(data={})\n",
    "\n",
    "    aux_coupons_df = pd.merge(agg_global_data_mat.loc[agg_global_data_mat['Clasificación'].isin(['Bonos','Tesoros'])]['security'].to_frame(), global_mat.loc[global_mat['Clasificación'].isin(['Bonos','Preferentes','Tesoros'])][['Banco', 'security', 'Coupon_freq', 'Coupon_nxt_date', 'Cupón', 'Divisa']].drop_duplicates(), how='left', on=['security', 'security'])\n",
    "\n",
    "    start_dt = datetime.datetime.strptime(date_st.value, '%d-%m-%Y')\n",
    "    end_dt = datetime.datetime.strptime(date_end.value, '%d-%m-%Y')\n",
    "\n",
    "    fut_cup_st_date = datetime.datetime(end_dt.year, 1, 1)\n",
    "    fut_cup_end_date = datetime.datetime(end_dt.year, 12, 31)\n",
    "\n",
    "    for i_idx in aux_coupons_df.index:\n",
    "        try:\n",
    "            i_sec_nxt_cup = aux_coupons_df.loc[i_idx, 'Coupon_nxt_date'].to_pydatetime()\n",
    "            i_sec_cup = aux_coupons_df.loc[i_idx, 'Cupón']\n",
    "            i_sec_cup_feq = aux_coupons_df.loc[i_idx, 'Coupon_freq']\n",
    "            i_sec_cup = i_sec_cup/i_sec_cup_feq\n",
    "            i_sec_cup_feq = 12/i_sec_cup_feq\n",
    "\n",
    "            list_cup_dates = []\n",
    "            time_count = i_sec_nxt_cup\n",
    "            while fut_cup_st_date <= time_count:\n",
    "                if time_count <= fut_cup_end_date:\n",
    "                    list_cup_dates += [time_count]\n",
    "\n",
    "                time_count -= datetime.timedelta(i_sec_cup_feq*365/12)\n",
    "\n",
    "            try:\n",
    "                #El primer elemento generado en list_cup_dates será la fecha del último cupón recibido del enfoque backward\n",
    "                #Ahora lo tenemos que ensamblar con el enfoque forward\n",
    "                time_count = list_cup_dates[0]\n",
    "                time_count += datetime.timedelta(i_sec_cup_feq*365/12)\n",
    "                while fut_cup_end_date >= time_count:\n",
    "                    list_cup_dates += [time_count]\n",
    "                    time_count += datetime.timedelta(i_sec_cup_feq*365/12)\n",
    "\n",
    "            except:\n",
    "                #Si no se ha generado list_cup_dates, se toma la siguiente alternativa\n",
    "                time_count = i_sec_nxt_cup\n",
    "                while fut_cup_end_date >= time_count:\n",
    "                    list_cup_dates += [time_count]\n",
    "                    time_count += datetime.timedelta(i_sec_cup_feq*365/12)\n",
    "\n",
    "            if len(list_cup_dates) > 0:            \n",
    "                i_sec_coupons_df = pd.DataFrame(data={'security': aux_coupons_df.loc[i_idx, 'security'],\n",
    "                                                      'Coupon_Payment_Dt': list_cup_dates, 'Cupón': i_sec_cup,\n",
    "                                                      'Divisa': aux_coupons_df.loc[i_idx, 'Divisa'],\n",
    "                                                      'Banco': aux_coupons_df.loc[i_idx, 'Banco']})\n",
    "                coupons_df = coupons_df.append(i_sec_coupons_df, ignore_index=True)\n",
    "\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    coupons_df = coupons_df.drop_duplicates()    \n",
    "\n",
    "    #Una vez generado el DataFrame de forma similar al los dividendos recibidos, el resto de los cálculos se realizan de forma análoga\n",
    "    list_amount_cup = []\n",
    "    for i in range(len(coupons_df)):\n",
    "        aux_mat = global_mat.loc[global_mat['security'].isin([coupons_df['security'].iloc[i]]) & global_mat['Banco'].isin([coupons_df['Banco'].iloc[i]])][['date', 'Nominal']]\n",
    "        try:\n",
    "            date_quantity = aux_mat[aux_mat['date'] <= coupons_df['Coupon_Payment_Dt'].iloc[i]]['Nominal'].tail(1).values[0]\n",
    "            list_amount_cup += [date_quantity * coupons_df['Cupón'].iloc[i]]        \n",
    "        except: #Si no hay nada comprado para el activo en el que en esa fecha se paga un dividendo\n",
    "            list_amount_cup += [0]\n",
    "\n",
    "    ############################# INCLUIR ALGO SIMILAR A LO DE LAS PREFERENTES EN LOS CUPONES --------------------------------- \n",
    "\n",
    "    #Incluir preferentes\n",
    "    if len(global_mat.loc[global_mat['Clasificación'].isin(['Preferentes'])])>0:\n",
    "\n",
    "        pref_carry_df = pd.DataFrame(data={})\n",
    "\n",
    "        pref_list = list(global_mat.loc[global_mat['Clasificación'].isin(['Preferentes'])]['security'].unique())\n",
    "\n",
    "        for eq in pref_list:\n",
    "            i_start_date = datetime.datetime.strptime(date_st.value, '%d-%m-%Y')\n",
    "            i_end_date = datetime.datetime.strptime(date_end.value, '%d-%m-%Y')\n",
    "\n",
    "            try:\n",
    "                request = bql.Request(eq, {'Cupón': f.dropna(d.cash_divs(CA_ADJ='RAW', dates = f.range(i_start_date, i_end_date), ca_date_type = 'PAY_DATE', currency = ac_curncy.value))})\n",
    "                res = bq.execute(request)\n",
    "                aux_res = res[0].df().reset_index()\n",
    "                aux_res['aux'] = range(len(aux_res)) #Se Asigna una variable auxiliar para identificar dónde se tienen que colocar las fechas ex-dividend\n",
    "\n",
    "                #Para buscar las fechas Ex-Dividend, se va a coger el último valor del dividendo pagado y al primero se le resta 1 año.\n",
    "                #No obstante, en vez de sacar el histórico, sacamos el número mínimo necesario de las fechas ex-dividends que necesitamos con la función last\n",
    "                #Se alinean los valores con la variable auxiliar creada al hacer un merge\n",
    "\n",
    "                if len(aux_res) > 1:\n",
    "                    aux_st_dt = aux_res['DATE'].values[0]\n",
    "                    aux_end_dt = aux_res['DATE'].values[-1]\n",
    "\n",
    "                else:\n",
    "                    aux_st_dt = aux_res['DATE'].values[0]\n",
    "                    aux_end_dt = aux_res['DATE'].values[0]\n",
    "\n",
    "                pay_st_dt = pd.to_datetime(str(aux_st_dt - np.timedelta64(8760, 'h'))).strftime('%Y-%m-%d') \n",
    "                pay_end_dt = pd.to_datetime(str(aux_end_dt)).strftime('%Y-%m-%d')\n",
    "\n",
    "                request = bql.Request(eq, {'Cupón': f.last(f.dropna(d.cash_divs(CA_ADJ='RAW', dates = f.range(pay_st_dt, pay_end_dt), ca_date_type = 'EFFECTIVE_DATE', currency = ac_curncy.value)), n = len(aux_res))})\n",
    "                res = bq.execute(request)\n",
    "                aux_res2 = res[0].df().reset_index().rename(index=str, columns={'DATE': 'Ex-div_date'})\n",
    "                aux_res2['aux'] = range(len(aux_res2))\n",
    "\n",
    "                aux_res = pd.merge(aux_res, aux_res2[['aux', 'Ex-div_date']], how = 'left', on = ['aux'])\n",
    "\n",
    "                #Aquí se aproximan los pagos de las preferentes estimando la frecuencia de pago -------------------\n",
    "\n",
    "                request = bql.Request(eq, {'Cupón': f.last(f.dropna(d.cash_divs(dividend_type = 'REGULAR', CA_ADJ='RAW',dates=f.range('-2Y', end_dt), currency = ac_curncy.value)), n=2)})\n",
    "                res = bq.execute(request)\n",
    "                aux_pref_fut = res[0].df().reset_index()\n",
    "\n",
    "                #Se obtiene el valor del último pago, que se supondrá que es el que se obtendrá a futuro\n",
    "                est_cup_pref = aux_pref_fut['Cupón'][0]    \n",
    "\n",
    "                #Se aproxima la frecuencia de los pagos\n",
    "                est_freq_pref = round(((aux_pref_fut['DATE'][1] - aux_pref_fut['DATE'][0]).days)/31)\n",
    "\n",
    "                #Se calculan las fechas estimadas de los pagos de las preferentes\n",
    "                list_cup_dates_fut = []\n",
    "                time_count_pref = aux_res['DATE'].iloc[-1].to_pydatetime() #Se coge la última fecha obtenida según la fecha especificada en date_end.value\n",
    "                time_count_pref += datetime.timedelta(est_freq_pref*365/12)\n",
    "                while fut_cup_end_date >= time_count:\n",
    "                    list_cup_dates_fut += [time_count]\n",
    "                    time_count_pref += datetime.timedelta(est_freq_pref*365/12)\n",
    "\n",
    "                #Se une con el df auxiliar generado anterior\n",
    "                aux_res2 = pd.DataFrame(data={'ID': np.nan, 'DATE': list_cup_dates_fut, 'CURRENCY': np.nan, 'Cupón': est_cup_pref, 'aux': np.nan, 'Ex-div_date': np.nan})\n",
    "                aux_res = aux_res.append(aux_res2, ignore_index = True).fillna(method='ffill', axis = 0)\n",
    "\n",
    "                #-----------------------------------------------------------------------------------------------------------\n",
    "\n",
    "                pref_carry_df = pref_carry_df.append(aux_res, ignore_index = True)\n",
    "\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        pref_carry_df = pref_carry_df.dropna(subset=['Cupón'])\n",
    "        pref_carry_df = pref_carry_df.drop(['aux'], axis=1)\n",
    "        \n",
    "        df_tick_banks = global_mat[['Banco', 'security']].drop_duplicates()\n",
    "        df_tick_banks = df_tick_banks.rename(index=str, columns={'security': 'ID'}) \n",
    "\n",
    "        pref_carry_df = pd.merge(pref_carry_df, df_tick_banks, how='left', on=['ID']) \n",
    "        \n",
    "        #Se genera una pivot table donde las filas son los activos y las cantidas y las columnas son los periodos temporales que se han cargado\n",
    "        n_assets = pd.DataFrame(data={})\n",
    "        for i_bank in global_mat['Banco'].unique():\n",
    "            aux_i_global_mat = global_mat.loc[global_mat['Banco'].isin([i_bank])]\n",
    "            n_assets = pd.concat([n_assets, aux_i_global_mat[['date', 'Banco', 'security', 'Nominal']].pivot_table(index = ['Banco', 'security'], columns = 'date', values = 'Nominal').fillna(0).reset_index()], ignore_index=True)\n",
    "        list_dates_concat = []\n",
    "        for i_dates_concat in n_assets.columns:\n",
    "            if i_dates_concat != 'Banco' and i_dates_concat != 'security':\n",
    "                list_dates_concat += [i_dates_concat]\n",
    "        n_assets = n_assets[['Banco', 'security'] + sorted(list_dates_concat)]\n",
    "        n_assets = n_assets.fillna(method='ffill', axis = 1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        list_amount_pref = []\n",
    "        for i in range(len(pref_carry_df)):\n",
    "            aux_mat = n_assets.loc[n_assets['security'].isin([pref_carry_df['ID'].iloc[i]]) & n_assets['Banco'].isin([pref_carry_df['Banco'].iloc[i]])].drop(['Banco', 'security'], axis=1) \n",
    "\n",
    "            try:\n",
    "                if aux_mat.loc[:,aux_mat.columns <= pref_carry_df['Ex-div_date'].iloc[i]].iloc[:,-1].values[0] != 0: #Si no se ha comprado el valor antes de la fecha ex-dividend, entonces no se podrá computar el dividendo recibido en la fecha de su pago            \n",
    "                    date_quantity = aux_mat.loc[:,aux_mat.columns <= pref_carry_df['DATE'].iloc[i]].iloc[:,-1].values[0]\n",
    "                    list_amount_pref += [date_quantity * pref_carry_df['Cupón'].iloc[i]]\n",
    "\n",
    "                else:\n",
    "                    list_amount_pref += [0]\n",
    "\n",
    "            except: #Si no hay nada comprado para el activo en el que en esa fecha se paga el carry del preferente\n",
    "                list_amount_pref += [0]\n",
    "        \n",
    "        #Adaptar el formato de los pagos de las preferentes (similar al de dividendos) al de los cupones\n",
    "        pref_carry_df = pref_carry_df.rename(index=str, columns={'ID': 'security', 'DATE': 'Coupon_Payment_Dt', 'CURRENCY': 'Divisa'})\n",
    "        \n",
    "        #Agrupar las preferentes a los cupones        \n",
    "        coupons_df = coupons_df.append(pref_carry_df[['security', 'Coupon_Payment_Dt', 'Cupón', 'Divisa', 'Banco']], ignore_index=True)    \n",
    "        \n",
    "        list_amount_cup = list_amount_cup + list_amount_pref    \n",
    "    \n",
    "    ##################################### --------------------------------------------------------------------------\n",
    "    \n",
    "    coupons_df['Total_Coupon'] = list_amount_cup        \n",
    "    coupons_df['mes'] = coupons_df['Coupon_Payment_Dt'].map(lambda x: x.month)\n",
    "\n",
    "    #En caso de que algún bono esté en otra divisa, calcular el cambio de divisa\n",
    "    list_real_amount_cup = []\n",
    "    for i_idx in coupons_df.index:\n",
    "        divisa_activo = coupons_df.loc[i_idx, 'Divisa']\n",
    "        if divisa_activo != ac_curncy.value:\n",
    "            \n",
    "            #Al calcular las fechas futuras en las que se recibirían los cupones, en aquellos casos en los que se necesita extraer el valor de la \n",
    "            #divisa para una fecha futura, se aplicará el valor de la divisa en la fecha fin parametrizada del informe\n",
    "            if coupons_df.loc[i_idx, 'Coupon_Payment_Dt'].to_pydatetime() < datetime.datetime.strptime(date_end.value, '%d-%m-%Y'):\n",
    "                fecha_forward = coupons_df.loc[i_idx, 'Coupon_Payment_Dt'].to_pydatetime()\n",
    "                \n",
    "            else:\n",
    "                fecha_forward = datetime.datetime.strptime(date_end.value, '%d-%m-%Y')\n",
    "            \n",
    "            request =  bql.Request(ac_curncy.value + divisa_activo + ' Curncy', {'FX': d.px_last(start = fecha_forward, fill = 'prev')['value']})\n",
    "            res = bq.execute(request)\n",
    "            fx_df = res[0].df()\n",
    "\n",
    "            list_real_amount_cup += [coupons_df.loc[i_idx, 'Total_Coupon'] / fx_df['FX'][0]]\n",
    "        else:\n",
    "            list_real_amount_cup += [coupons_df.loc[i_idx, 'Total_Coupon']]\n",
    "\n",
    "    coupons_df['Real_Total_Coupon'] = list_real_amount_cup       \n",
    "\n",
    "    cum_coupons_df = pd.pivot_table(coupons_df, values='Real_Total_Coupon', index=['security'],columns=['mes'], aggfunc=np.sum)\n",
    "\n",
    "    def_forward_mat_cup = pd.DataFrame(data={})\n",
    "    for col in cum_coupons_df.columns.tolist():\n",
    "        def_forward_mat_cup[str(col)] = cum_coupons_df[col].tolist()\n",
    "\n",
    "    if cum_coupons_df.columns.tolist() != list(range(1,13)): #Ver si faltan meses por incluir en el año\n",
    "        for left_month in list(set(list(range(1,13))) - set(cum_coupons_df.columns.tolist())):\n",
    "            def_forward_mat_cup[str(left_month)] = np.nan\n",
    "\n",
    "    def_forward_mat_cup['Ticker'] = cum_coupons_df.index.tolist() \n",
    "    def_forward_mat_cup = def_forward_mat_cup[['Ticker'] + [str(i) for i in range(1,13)]] #Ordenar la matriz\n",
    "    def_forward_mat_cup['Total'] = def_forward_mat_cup.sum(axis=1,skipna=True)\n",
    "    def_forward_mat_cup = def_forward_mat_cup.append(def_forward_mat_cup.sum(numeric_only=True), ignore_index=True)\n",
    "    def_forward_mat_cup.loc[len(def_forward_mat_cup)-1, 'Ticker'] = 'Total'\n",
    "    \n",
    "def gen_excel_type_table (tgt = None):\n",
    "    global agg_global_data_mat\n",
    "    global matriz_filtrada1 #Matriz filtrada por casificación sin cambios\n",
    "    \n",
    "    output_number_assets_class.value = str(agg_global_data_mat['Clasificación'].isin([assets_class.value]).sum())\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        if assets_class.value == 'Acciones' or assets_class.value == 'ETFs RV' or assets_class.value == 'Fondos RV':\n",
    "            matriz_filtrada1 = agg_global_data_mat.loc[agg_global_data_mat['Clasificación'].isin([assets_class.value])]\n",
    "            #Se seleccionan los campos necesarios para esta tipología, excluyendo aquellos que no pertenecen a la misma\n",
    "            matriz_filtrada1 = matriz_filtrada1[matriz_filtrada1.columns[~matriz_filtrada1.columns.isin(['ID_BBG', 'ISIN', 'Rating', 'Cupón', 'Vencimiento', 'Fecha Compra', 'P0_Report', 'Dividendos recibidos', 'Intereses recibidos', 'Dividend yield fecha compra', 'Interests'])]]           \n",
    "            print_excel_type_table_Equity (matriz_filtrada1)\n",
    "            \n",
    "        elif assets_class.value == 'Bonos' or assets_class.value == 'ETFs RF' or assets_class.value == 'Fondos RF' or assets_class.value == 'Otros' or assets_class.value == 'Sin Clasificar' or assets_class.value == 'Preferentes' or assets_class.value == 'Tesoros':\n",
    "            matriz_filtrada1 = agg_global_data_mat.loc[agg_global_data_mat['Clasificación'].isin([assets_class.value])]\n",
    "            #Se seleccionan los campos necesarios para esta tipología, excluyendo aquellos que no pertenecen a la misma\n",
    "            matriz_filtrada1 = matriz_filtrada1[matriz_filtrada1.columns[~matriz_filtrada1.columns.isin(['ID_BBG', 'ISIN', 'Vencimiento', 'Fecha Compra', 'P0_Report', 'Dividendos recibidos', 'Intereses recibidos', 'Dividend yield fecha compra', 'Interests'])]]\n",
    "            print_excel_type_table_FI (matriz_filtrada1)\n",
    "        \n",
    "        elif assets_class.value == 'CASH':\n",
    "            matriz_filtrada1 = agg_global_data_mat.loc[agg_global_data_mat['Clasificación'].isin([assets_class.value])]\n",
    "            #Se seleccionan los campos necesarios para esta tipología, excluyendo aquellos que no pertenecen a la misma\n",
    "            matriz_filtrada1 = matriz_filtrada1[['Banco', 'security', 'Título', 'Divisa', 'País']] \n",
    "            print_excel_type_table_CASH (matriz_filtrada1)            \n",
    "\n",
    "    except: #No se parametrizan los Estrucutrados u otras tipologías\n",
    "        pass       \n",
    "\n",
    "def print_excel_type_table_Equity (gen_table):\n",
    "    #Cargar valores en las siguientes variables donde hay widgets\n",
    "    global tabla_excel    \n",
    "    \n",
    "    #Generar tabla con inputs modificables tipo Excel\n",
    "    tabla_excel.children = () #En caso de que se vuelva a llamar al Dropdown, borrar la anterior cargada\n",
    "    \n",
    "    #Generar los valores del Dataframe\n",
    "    aux_v = []\n",
    "    for vals_df in gen_table.values:\n",
    "        aux_h = []\n",
    "        i = 0\n",
    "        #Hay que poner la expresión try-except para los NAs que haya\n",
    "        for val_df in vals_df:\n",
    "            if i == 0: #Clasificación\n",
    "                aux_h += [Dropdown(value = val_df, options = ['Acciones', 'Fondos RV', 'ETFs RV', 'Bonos', 'Fondos RF', 'ETFs RF', 'Otros', 'CASH', 'Preferentes', 'Tesoros' ,'Sin Clasificar'], layout=Layout(width='140px'))]\n",
    "            elif i == 1: #Banco\n",
    "                try:\n",
    "                    aux_h += [Text(value = val_df, layout=Layout(width='120px'))]\n",
    "                except:\n",
    "                    aux_h += [Text(value = str(val_df), layout=Layout(width='120px'))]\n",
    "            elif i == 2: #security\n",
    "                try:\n",
    "                    aux_h += [Text(value = val_df, disabled = True, layout=Layout(width='135px'))]\n",
    "                except:\n",
    "                    aux_h += [Text(value = str(val_df), disabled = True, layout=Layout(width='135px'))]\n",
    "            elif i == 3: #Título\n",
    "                try:\n",
    "                    aux_h += [Text(value = val_df, layout=Layout(width='145px'))]\n",
    "                except:\n",
    "                    aux_h += [Text(value = str(val_df), layout=Layout(width='145px'))]\n",
    "            elif i == 4: #Divisa\n",
    "                try:\n",
    "                    aux_h += [Text(value = val_df, layout=Layout(width='65px'))]\n",
    "                except:\n",
    "                    aux_h += [Text(value = str(val_df), layout=Layout(width='65px'))]                \n",
    "            elif i == 5: #País\n",
    "                try:\n",
    "                    aux_h += [Text(value = val_df, layout=Layout(width='120px'))]\n",
    "                except:\n",
    "                    aux_h += [Text(value = str(val_df), layout=Layout(width='120px'))]\n",
    "            elif i == 6: #Sector\n",
    "                try:\n",
    "                    aux_h += [Text(value = val_df, layout=Layout(width='100px'))]\n",
    "                except:\n",
    "                    aux_h += [Text(value = str(val_df), layout=Layout(width='100px'))]                    \n",
    "            elif i == 7: #Nominal\n",
    "                aux_h += [Text(value = str(val_df), layout=Layout(width='80px'))]\n",
    "            elif i == 8: #Precio compra\n",
    "                aux_h += [Text(value = str(val_df), layout=Layout(width='90px'))]                \n",
    "            elif i == 9: #Precio compra en divisa reportada\n",
    "                aux_h += [Text(value = str(val_df), layout=Layout(width='90px'))]                                          \n",
    "            elif i == 10: #Precio Actual\n",
    "                aux_h += [Text(value = str(val_df), layout=Layout(width='90px'))]\n",
    "            elif i == 11: #P1_Report\n",
    "                aux_h += [Text(value = str(val_df), layout=Layout(width='90px'))]\n",
    "            i += 1\n",
    "        aux_v += [HBox(aux_h)]\n",
    "    \n",
    "    #Generar las cabeceras del Dataframe como cabeceras del Excel que no se puedan modificar    \n",
    "    i = 0\n",
    "    aux_head = []\n",
    "    for head in gen_table.columns:\n",
    "        \n",
    "        if i == 0:\n",
    "            aux_head += [Text(value = head, disabled = True, layout=Layout(width='140px'))]\n",
    "        elif i == 1:\n",
    "            aux_head += [Text(value = head, disabled = True, layout=Layout(width='120px'))]\n",
    "        elif i == 2:\n",
    "            aux_head += [Text(value = head, disabled = True, layout=Layout(width='135px'))]\n",
    "        elif i == 3:\n",
    "            aux_head += [Text(value = head, disabled = True, layout=Layout(width='145px'))]\n",
    "        elif i == 4:\n",
    "            aux_head += [Text(value = head, disabled = True, layout=Layout(width='65px'))]\n",
    "        elif i == 5:\n",
    "            aux_head += [Text(value = head, disabled = True, layout=Layout(width='120px'))]\n",
    "        elif i == 6:\n",
    "            aux_head += [Text(value = head, disabled = True, layout=Layout(width='100px'))]            \n",
    "        elif i == 7:\n",
    "            aux_head += [Text(value = head, disabled = True, layout=Layout(width='80px'))]\n",
    "        elif i == 8:\n",
    "            aux_head += [Text(value = head, disabled = True, layout=Layout(width='90px'))]            \n",
    "        elif i == 9:\n",
    "            aux_head += [Text(value = head, disabled = True, layout=Layout(width='90px'))]\n",
    "        elif i == 10:\n",
    "            aux_head += [Text(value = head, disabled = True, layout=Layout(width='90px'))]      \n",
    "        elif i == 11:\n",
    "            aux_head += [Text(value = head, disabled = True, layout=Layout(width='90px'))]                 \n",
    "        i += 1\n",
    "\n",
    "    tabla_excel.children += (VBox([HBox(aux_head)] +  aux_v),)\n",
    "\n",
    "def print_excel_type_table_FI (gen_table):\n",
    "    #Cargar valores en las siguientes variables donde hay widgets\n",
    "    global tabla_excel    \n",
    "    \n",
    "    #Generar tabla con inputs modificables tipo Excel\n",
    "    tabla_excel.children = () #En caso de que se vuelva a llamar al Dropdown, borrar la anterior cargada\n",
    "    \n",
    "    #Generar los valores del Dataframe\n",
    "    aux_v = []\n",
    "    for vals_df in gen_table.values:\n",
    "        aux_h = []\n",
    "        i = 0\n",
    "        #Hay que poner la expresión try-except para los NAs que haya\n",
    "        for val_df in vals_df:\n",
    "            if i == 0: #Clasificación\n",
    "                aux_h += [Dropdown(value = val_df, options = ['Acciones', 'Fondos RV', 'ETFs RV', 'Bonos', 'Fondos RF', 'ETFs RF', 'Otros', 'CASH', 'Preferentes', 'Tesoros', 'Sin Clasificar'], layout=Layout(width='140px'))]\n",
    "            elif i == 1: #Banco\n",
    "                try:\n",
    "                    aux_h += [Text(value = val_df, layout=Layout(width='120px'))]\n",
    "                except:\n",
    "                    aux_h += [Text(value = str(val_df), layout=Layout(width='120px'))]\n",
    "            elif i == 2: #security\n",
    "                try:\n",
    "                    aux_h += [Text(value = val_df, disabled = True, layout=Layout(width='135px'))]\n",
    "                except:\n",
    "                    aux_h += [Text(value = str(val_df), disabled = True, layout=Layout(width='135px'))]\n",
    "            elif i == 3: #Título\n",
    "                try:\n",
    "                    aux_h += [Text(value = val_df, layout=Layout(width='145px'))]\n",
    "                except:\n",
    "                    aux_h += [Text(value = str(val_df), layout=Layout(width='145px'))]\n",
    "            elif i == 4: #Divisa\n",
    "                try:\n",
    "                    aux_h += [Text(value = val_df, layout=Layout(width='65px'))]\n",
    "                except:\n",
    "                    aux_h += [Text(value = str(val_df), layout=Layout(width='65px'))]\n",
    "            elif i == 5: #Rating\n",
    "                try:\n",
    "                    aux_h += [Text(value = val_df, layout=Layout(width='65px'))]\n",
    "                except:\n",
    "                    aux_h += [Text(value = str(val_df), layout=Layout(width='65px'))]                         \n",
    "            elif i == 6: #País\n",
    "                try:\n",
    "                    aux_h += [Text(value = val_df, layout=Layout(width='120px'))]\n",
    "                except:\n",
    "                    aux_h += [Text(value = str(val_df), layout=Layout(width='120px'))]  \n",
    "            elif i == 7: #Sector\n",
    "                try:\n",
    "                    aux_h += [Text(value = val_df, layout=Layout(width='100px'))]\n",
    "                except:\n",
    "                    aux_h += [Text(value = str(val_df), layout=Layout(width='100px'))]                      \n",
    "            elif i == 8: #Nominal\n",
    "                aux_h += [Text(value = str(val_df), layout=Layout(width='80px'))]\n",
    "            elif i == 9: #Cupón\n",
    "                aux_h += [Text(value = str(val_df), layout=Layout(width='55px'))]                     \n",
    "            elif i == 10: #Precio compra\n",
    "                aux_h += [Text(value = str(val_df), layout=Layout(width='90px'))]\n",
    "            elif i == 11: #Precio compra en divisa Reportada\n",
    "                aux_h += [Text(value = str(val_df), layout=Layout(width='90px'))]                     \n",
    "            elif i == 12: #Precio Actual\n",
    "                aux_h += [Text(value = str(val_df), layout=Layout(width='90px'))]\n",
    "            elif i == 13: #P1_Report\n",
    "                aux_h += [Text(value = str(val_df), layout=Layout(width='90px'))]                     \n",
    "            i += 1\n",
    "        aux_v += [HBox(aux_h)]\n",
    "    \n",
    "    #Generar las cabeceras del Dataframe como cabeceras del Excel que no se puedan modificar    \n",
    "    i = 0\n",
    "    aux_head = []\n",
    "    for head in gen_table.columns:\n",
    "        \n",
    "        if i == 0:\n",
    "            aux_head += [Text(value = head, disabled = True, layout=Layout(width='140px'))]\n",
    "        elif i == 1:\n",
    "            aux_head += [Text(value = head, disabled = True, layout=Layout(width='120px'))]\n",
    "        elif i == 2:\n",
    "            aux_head += [Text(value = head, disabled = True, layout=Layout(width='135px'))]\n",
    "        elif i == 3:\n",
    "            aux_head += [Text(value = head, disabled = True, layout=Layout(width='145px'))]\n",
    "        elif i == 4:\n",
    "            aux_head += [Text(value = head, disabled = True, layout=Layout(width='65px'))]\n",
    "        elif i == 5:\n",
    "            aux_head += [Text(value = head, disabled = True, layout=Layout(width='65px'))]            \n",
    "        elif i == 6:\n",
    "            aux_head += [Text(value = head, disabled = True, layout=Layout(width='120px'))]\n",
    "        elif i == 7:\n",
    "            aux_head += [Text(value = head, disabled = True, layout=Layout(width='100px'))]            \n",
    "        elif i == 8:\n",
    "            aux_head += [Text(value = head, disabled = True, layout=Layout(width='80px'))]\n",
    "        elif i == 9:\n",
    "            aux_head += [Text(value = head, disabled = True, layout=Layout(width='55px'))]\n",
    "        elif i == 10:\n",
    "            aux_head += [Text(value = head, disabled = True, layout=Layout(width='90px'))]        \n",
    "        elif i == 11:\n",
    "            aux_head += [Text(value = head, disabled = True, layout=Layout(width='90px'))]      \n",
    "        elif i == 12:\n",
    "            aux_head += [Text(value = head, disabled = True, layout=Layout(width='90px'))]      \n",
    "        elif i == 13:\n",
    "            aux_head += [Text(value = head, disabled = True, layout=Layout(width='90px'))]             \n",
    "        i += 1\n",
    "\n",
    "    tabla_excel.children += (VBox([HBox(aux_head)] +  aux_v),)\n",
    "    \n",
    "def print_excel_type_table_CASH (gen_table):\n",
    "    #Cargar valores en las siguientes variables donde hay widgets\n",
    "    global tabla_excel    \n",
    "    \n",
    "    #Generar tabla con inputs modificables tipo Excel\n",
    "    tabla_excel.children = () #En caso de que se vuelva a llamar al Dropdown, borrar la anterior cargada\n",
    "    \n",
    "    #Generar los valores del Dataframe\n",
    "    aux_v = []\n",
    "    for vals_df in gen_table.values:\n",
    "        aux_h = []\n",
    "        i = 0\n",
    "        #Hay que poner la expresión try-except para los NAs que haya\n",
    "        for val_df in vals_df:\n",
    "            if i == 0: #Banco\n",
    "                try:\n",
    "                    aux_h += [Text(value = val_df, layout=Layout(width='120px'))]\n",
    "                except:\n",
    "                    aux_h += [Text(value = str(val_df), layout=Layout(width='120px'))]\n",
    "            elif i == 1: #security\n",
    "                try:\n",
    "                    aux_h += [Text(value = val_df, disabled = True, layout=Layout(width='135px'))]\n",
    "                except:\n",
    "                    aux_h += [Text(value = str(val_df), disabled = True, layout=Layout(width='135px'))]\n",
    "            elif i == 2: #Título\n",
    "                try:\n",
    "                    aux_h += [Text(value = val_df, layout=Layout(width='145px'))]\n",
    "                except:\n",
    "                    aux_h += [Text(value = str(val_df), layout=Layout(width='145px'))]\n",
    "            elif i == 3: #Divisa\n",
    "                try:\n",
    "                    aux_h += [Text(value = val_df, layout=Layout(width='65px'))]\n",
    "                except:\n",
    "                    aux_h += [Text(value = str(val_df), layout=Layout(width='65px'))]                \n",
    "            elif i == 4: #País\n",
    "                try:\n",
    "                    aux_h += [Text(value = val_df, layout=Layout(width='120px'))]\n",
    "                except:\n",
    "                    aux_h += [Text(value = str(val_df), layout=Layout(width='120px'))]\n",
    "            i += 1\n",
    "        aux_v += [HBox(aux_h)]\n",
    "    \n",
    "    #Generar las cabeceras del Dataframe como cabeceras del Excel que no se puedan modificar    \n",
    "    i = 0\n",
    "    aux_head = []\n",
    "    for head in gen_table.columns:\n",
    "        \n",
    "        if i == 0:\n",
    "            aux_head += [Text(value = head, disabled = True, layout=Layout(width='120px'))]\n",
    "        elif i == 1:\n",
    "            aux_head += [Text(value = head, disabled = True, layout=Layout(width='135px'))]\n",
    "        elif i == 2:\n",
    "            aux_head += [Text(value = head, disabled = True, layout=Layout(width='145px'))]\n",
    "        elif i == 3:\n",
    "            aux_head += [Text(value = head, disabled = True, layout=Layout(width='65px'))]\n",
    "        elif i == 4:\n",
    "            aux_head += [Text(value = head, disabled = True, layout=Layout(width='120px'))]                \n",
    "        i += 1\n",
    "\n",
    "    tabla_excel.children += (VBox([HBox(aux_head)] +  aux_v),)    \n",
    "        \n",
    "def apply_changes_excel_type_table (tgt = None):\n",
    "    global agg_global_data_mat\n",
    "    global list_unique_clasi    \n",
    "    \n",
    "    request_button6.disabled = True #Durante el proceso de esta descarga de datos, se desabilita el botón para evitar errores de doble click\n",
    "    \n",
    "    cur_val_selected = assets_class.value\n",
    "    \n",
    "    read_excel_type_table()\n",
    "    print_message_box.value = 'CAMBIOS APLICADOS EN ' + str(assets_class.value)\n",
    "    \n",
    "    #Imprimir de nuevo la tabla \n",
    "    list_unique_clasi = list(agg_global_data_mat['Clasificación'].unique())\n",
    "    assets_class.options = list_unique_clasi    \n",
    "    \n",
    "    if cur_val_selected in list_unique_clasi:\n",
    "        assets_class.value  = cur_val_selected\n",
    "    else:\n",
    "        assets_class.value = list_unique_clasi[0]    \n",
    "        \n",
    "    request_button6.disabled = False #Durante el proceso de esta descarga de datos, se desabilita el botón para evitar errores de doble click\n",
    "        \n",
    "def read_excel_type_table (tgt = None):\n",
    "    global global_mat\n",
    "    global agg_global_data_mat\n",
    "    global matriz_filtrada1 #Matriz filtrada por casificación sin cambios\n",
    "    global matriz_filtrada2 #Matriz filtrada por casificación CON CAMBIOS DEL USUARIO\n",
    "\n",
    "    #Definir el Dataframe vacío con las mismas columnas e índices\n",
    "    matriz_filtrada2 = pd.DataFrame(data={})\n",
    "    matriz_filtrada2 = matriz_filtrada2.reindex(index = matriz_filtrada1.index, columns = matriz_filtrada1.columns)\n",
    "\n",
    "    #Leer las celdas, si no son valores numéricos serán carácteres \n",
    "    for cells,idx in zip(tabla_excel.children[0].children[1:], matriz_filtrada2.index): #Saltar las cabeceras\n",
    "        for cell, col in zip(cells.children, matriz_filtrada2.columns):\n",
    "            try:\n",
    "                matriz_filtrada2.loc[idx,col] = float(cell.value)\n",
    "            except:\n",
    "                matriz_filtrada2.loc[idx,col] = cell.value\n",
    "\n",
    "    #Identificar si hay diferencias entre matriz_filtrada1 y matriz_filtrada2 \n",
    "    if matriz_filtrada1.equals(matriz_filtrada2) == False:\n",
    "        contrast_mat = matriz_filtrada1 == matriz_filtrada2\n",
    "        \n",
    "        #Se tiene que hacer una copia para que no salte un warning de que estás machacando valores\n",
    "        agg_global_data_mat2 = agg_global_data_mat.copy()\n",
    "        \n",
    "        for i_contrast in contrast_mat.index:\n",
    "            for j_contras in contrast_mat.columns:\n",
    "                if contrast_mat.loc[i_contrast, j_contras] == False:\n",
    "                    agg_global_data_mat2.loc[i_contrast, j_contras] = matriz_filtrada2.loc[i_contrast, j_contras]\n",
    "        \n",
    "        #Se aplican esos cambios en la matriz desglosada, para lo cual se eliminan las filas con los valores antiguos y se añaden los valores modificados\n",
    "#         agg_global_data_mat = agg_global_data_mat.drop(agg_global_data_mat.index[agg_global_data_mat2.index.tolist()])\n",
    "#         agg_global_data_mat = agg_global_data_mat.append(agg_global_data_mat2).sort_index()\n",
    "        agg_global_data_mat = agg_global_data_mat2\n",
    "        \n",
    "        #Si ha habido cambios en la Clasificación, se aplican sobre la matriz global\n",
    "        sample_agg_global_data_mat = agg_global_data_mat[['security', 'Clasificación']].drop_duplicates()\n",
    "\n",
    "        list_new_clasi = []\n",
    "        for idx in global_mat.index:\n",
    "            if global_mat.loc[idx, 'security'] in sample_agg_global_data_mat['security'].tolist():\n",
    "                list_new_clasi += [sample_agg_global_data_mat.loc[sample_agg_global_data_mat['security'].isin([global_mat.loc[idx, 'security']]), 'Clasificación'].values[0]]\n",
    "            else:\n",
    "                list_new_clasi += [global_mat.loc[idx, 'Clasificación']]\n",
    "\n",
    "        global_mat = global_mat.drop(['Clasificación'], axis=1)\n",
    "        global_mat['Clasificación'] = list_new_clasi        \n",
    "\n",
    "def Load_Prices_in_Excel (tgt = None):\n",
    "    global agg_global_data_mat\n",
    "\n",
    "    #Se carga el Excel que se utiliza como soporte de precios para volcar los precios reales desde otro EXcel\n",
    "    #Sobre SOPORTE_Precios_Portfolio se sobreescriben las pestañas con los valores\n",
    "\n",
    "#     book = load_workbook('SOPORTE_Precios_Portfolio.xlsx')\n",
    "#     writer = pd.ExcelWriter('SOPORTE_Precios_Portfolio.xlsx', engine='openpyxl') \n",
    "#     writer.book = book\n",
    "#     writer.sheets = dict((ws.title, ws) for ws in book.worksheets)\n",
    "\n",
    "#     # Añadir una pestaña auxiliar para que al borrarlas al menos en el Excel quede una y no salte un error\n",
    "#     pestana_blanco = pd.DataFrame(data={})\n",
    "#     pestana_blanco.to_excel(writer, 'aux_sheet')\n",
    "#     writer.save()\n",
    "\n",
    "#     #Borrar pestañas con datos\n",
    "#     book.remove_sheet(book.get_sheet_by_name('Precios'))\n",
    "#     writer.save()\n",
    "\n",
    "#     #Crearlas nuevamente para que estén vacías\n",
    "#     book.create_sheet('Precios')\n",
    "#     writer.save()\n",
    "\n",
    "#     #Borrar la pestaña auxuliar\n",
    "#     book.remove_sheet(book.get_sheet_by_name('aux_sheet'))\n",
    "#     writer.save()    \n",
    "\n",
    "#     #Vuelve a cargar el Excel\n",
    "#     book = load_workbook('SOPORTE_Precios_Portfolio.xlsx')\n",
    "#     writer = pd.ExcelWriter('SOPORTE_Precios_Portfolio.xlsx', engine='openpyxl') \n",
    "#     writer.book = book\n",
    "#     writer.sheets = dict((ws.title, ws) for ws in book.worksheets)\n",
    "\n",
    "#     #Cargar valores nuevos en las pestañas del Excel SOPORTE_Precios_Portfolio\n",
    "#     agg_global_data_mat[['Banco', 'security', 'ISIN', 'Título', 'Precio compra', 'Precio compra Report', 'Precio Actual', 'P1_Report']].to_excel(writer, 'Precios', index=False)\n",
    "\n",
    "#     writer.save()\n",
    "    \n",
    "def Read_Prices_from_Excel (tgt = None):\n",
    "    global agg_global_data_mat\n",
    "    \n",
    "    read_excel_button.disabled = True #Durante el proceso de esta descarga de datos, se desabilita el botón para evitar errores de doble click\n",
    "    \n",
    "#     new_prices_data = pd.read_excel('SOPORTE_Precios_Portfolio.xlsx')\n",
    "#     list_columns_mat = agg_global_data_mat.columns\n",
    "    \n",
    "#     agg_global_data_mat = agg_global_data_mat.drop(['Precio compra', 'Precio compra Report', 'Precio Actual', 'P1_Report'], axis=1)    \n",
    "#     agg_global_data_mat = pd.merge(agg_global_data_mat, new_prices_data[['Banco', 'security', 'ISIN', 'Precio compra', 'Precio compra Report', 'Precio Actual', 'P1_Report']], how='left', on=['Banco', 'security', 'ISIN'])\n",
    "#     agg_global_data_mat = agg_global_data_mat[list_columns_mat]    \n",
    "    \n",
    "#     print_message_box.value = 'Se han leído los precios de SOPORTE_Precios_Portfolio.xlsx'\n",
    "    \n",
    "#     #Imprimir de nuevo la tabla \n",
    "#     cur_val_selected = assets_class.value\n",
    "#     list_unique_clasi = list(agg_global_data_mat['Clasificación'].unique())\n",
    "#     assets_class.options = list_unique_clasi    \n",
    "    \n",
    "#     if cur_val_selected in list_unique_clasi:\n",
    "#         assets_class.value  = cur_val_selected\n",
    "#     else:\n",
    "#         assets_class.value = list_unique_clasi[0]    \n",
    "        \n",
    "    read_excel_button.disabled = False #Durante el proceso de esta descarga de datos, se desabilita el botón para evitar errores de doble click        \n",
    "        \n",
    "def validate_data (tgt = None):\n",
    "    global agg_global_data_mat\n",
    "    global def_mat_div\n",
    "    global def_mat_cup\n",
    "    \n",
    "    if agg_global_data_mat['Clasificación'].isin(['Sin Clasificar']).sum() == 0: \n",
    "        \n",
    "        try:\n",
    "            def_mat_div = pd.merge(def_mat_div, agg_global_data_mat[['security', 'Clasificación']].drop_duplicates(keep='first'), how='left', on=['security']) \n",
    "\n",
    "            #Hacer una reclasificación entre la matriz de dividendos y la de cupones para que los dividendos de los ETF's RF y Fondos RF salgan en la matriz de cupones\n",
    "            if len(def_mat_div.loc[def_mat_div['Clasificación'].isin(['ETFs RF', 'Fondos RF'])]) > 0:\n",
    "\n",
    "                def_mat_cup = def_mat_cup.append(def_mat_div.loc[def_mat_div['Clasificación'].isin(['ETFs RF', 'Fondos RF'])], ignore_index=True)\n",
    "                def_mat_cup = def_mat_cup.drop(['Clasificación'], axis=1)\n",
    "                def_mat_cup = def_mat_cup.rename(index=str, columns={'security': 'Ticker'})\n",
    "\n",
    "            def_mat_div = def_mat_div.loc[~def_mat_div['Clasificación'].isin(['ETFs RF', 'Fondos RF'])]\n",
    "            def_mat_div = def_mat_div.drop(['Clasificación'], axis=1)\n",
    "            def_mat_div = def_mat_div.rename(index=str, columns={'security': 'Ticker'})     \n",
    "\n",
    "            def_mat_div = def_mat_div[['Ticker'] + [str(i) for i in range(1,13)]] #Ordenar la matriz\n",
    "            def_mat_div['Total'] = def_mat_div.sum(axis=1,skipna=True)\n",
    "            def_mat_div = def_mat_div.append(def_mat_div.sum(numeric_only=True), ignore_index=True)\n",
    "            def_mat_div.loc[len(def_mat_div)-1, 'Ticker'] = 'Total'\n",
    "            def_mat_div = def_mat_div.loc[def_mat_div['Total'] != 0]\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        try:\n",
    "            #Aplicar los formatos del GR\n",
    "            if 'security' in def_mat_cup.columns:\n",
    "                def_mat_cup = def_mat_cup.rename(index=str, columns={'security': 'Ticker'})            \n",
    "            \n",
    "            def_mat_cup = def_mat_cup[['Ticker'] + [str(i) for i in range(1,13)]] #Ordenar la matriz\n",
    "            def_mat_cup['Total'] = def_mat_cup.sum(axis=1,skipna=True)\n",
    "            def_mat_cup = def_mat_cup.append(def_mat_cup.sum(numeric_only=True), ignore_index=True)\n",
    "            def_mat_cup.loc[len(def_mat_cup)-1, 'Ticker'] = 'Total'\n",
    "            def_mat_cup = def_mat_cup.loc[def_mat_cup['Total'] != 0]\n",
    "        \n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "        #Generar el resto de campos necesarios en agg_global_data_mat relativos a los cálculos de valor actual y retorno\n",
    "        agg_global_data_mat['Valor de Compra'] = agg_global_data_mat['Precio compra'] * agg_global_data_mat['Nominal']\n",
    "        \n",
    "        #Calculamos correctamente el dividend yield, ajustado por los nuevos precios de compra introducidos en Load/Read prices:\n",
    "        agg_global_data_mat['Dividend yield fecha compra'] = agg_global_data_mat['Dividend yield fecha compra']/agg_global_data_mat['Precio compra Report']\n",
    "\n",
    "        #Dividir entre 100 el precio de los bonos para obtener el valor de compra\n",
    "        aux_list_precio_compra = []\n",
    "        for i in agg_global_data_mat.index:\n",
    "            if (agg_global_data_mat.loc[i, 'Clasificación'] == 'Bonos') or (agg_global_data_mat.loc[i, 'Clasificación'] == 'Tesoros'):\n",
    "                aux_list_precio_compra += [agg_global_data_mat.loc[i, 'Precio compra']/100]\n",
    "            else:\n",
    "                aux_list_precio_compra += [agg_global_data_mat.loc[i, 'Precio compra']]\n",
    "\n",
    "        agg_global_data_mat['aux_Precio compra'] = aux_list_precio_compra\n",
    "        agg_global_data_mat['Valor de Compra'] = agg_global_data_mat['aux_Precio compra'] * agg_global_data_mat['Nominal']\n",
    "        agg_global_data_mat = agg_global_data_mat.drop(['aux_Precio compra'], axis=1)        \n",
    "\n",
    "        agg_global_data_mat['Dividendos+Intereses'] = agg_global_data_mat['Dividendos recibidos'].fillna(0) + agg_global_data_mat['Intereses recibidos'].fillna(0)\n",
    "\n",
    "        #Dividir entre 100 el precio de los bonos para obtener el valor de compra\n",
    "        aux_list_p1_report = []\n",
    "        aux_list_p0_report = []\n",
    "        for i in agg_global_data_mat.index:\n",
    "            if (agg_global_data_mat.loc[i, 'Clasificación'] == 'Bonos') or (agg_global_data_mat.loc[i, 'Clasificación'] == 'Tesoros'):\n",
    "                aux_list_p1_report += [agg_global_data_mat.loc[i, 'P1_Report']/100]\n",
    "                aux_list_p0_report += [agg_global_data_mat.loc[i, 'Precio compra Report']/100]\n",
    "\n",
    "            else:\n",
    "                aux_list_p1_report += [agg_global_data_mat.loc[i, 'P1_Report']]    \n",
    "                aux_list_p0_report += [agg_global_data_mat.loc[i, 'Precio compra Report']]\n",
    "\n",
    "        agg_global_data_mat['aux_P1_Report'] = aux_list_p1_report\n",
    "        agg_global_data_mat['aux_Precio compra Report'] = aux_list_p0_report\n",
    "\n",
    "        agg_global_data_mat['Valor Actual'] = agg_global_data_mat['aux_P1_Report'] * agg_global_data_mat['Nominal'] + (agg_global_data_mat['Interests'].fillna(0) * (agg_global_data_mat['P1_Report']/agg_global_data_mat['Precio Actual']).fillna(1)) * agg_global_data_mat['Nominal'] #Se aplica el cambio de divisa al cupón corrido\n",
    "        agg_global_data_mat = agg_global_data_mat.drop(['Interests', 'ISIN'], axis=1)\n",
    "        agg_global_data_mat['Retorno Obtenido'] = ((agg_global_data_mat['Valor Actual'] + agg_global_data_mat['Dividendos+Intereses']) / (agg_global_data_mat['aux_Precio compra Report'] * agg_global_data_mat['Nominal'])) - 1\n",
    "        agg_global_data_mat = agg_global_data_mat.drop(['aux_P1_Report', 'aux_Precio compra Report'], axis=1)\n",
    "        \n",
    "        #Parche para imputar correctamente los bonos mexicanos\n",
    "        if len(agg_global_data_mat.loc[agg_global_data_mat['Divisa'].isin(['MXN']) & agg_global_data_mat['Clasificación'].isin(['Bonos','Preferentes','Tesoros'])]) > 0:\n",
    "            index_mxn = agg_global_data_mat.loc[agg_global_data_mat['Divisa'].isin(['MXN']) & agg_global_data_mat['Clasificación'].isin(['Bonos','Preferentes','Tesoros'])].index\n",
    "\n",
    "            agg_global_data_mat2 = agg_global_data_mat.copy()\n",
    "            for i_idx_mxn in index_mxn:\n",
    "                agg_global_data_mat2.loc[i_idx_mxn, 'Valor Actual'] = agg_global_data_mat.loc[i_idx_mxn, 'Valor Actual']*100\n",
    "                agg_global_data_mat2.loc[i_idx_mxn, 'Intereses recibidos'] = agg_global_data_mat.loc[i_idx_mxn, 'Intereses recibidos']*100\n",
    "                agg_global_data_mat2.loc[i_idx_mxn, 'Dividendos+Intereses'] = np.nansum([agg_global_data_mat.loc[i_idx_mxn, 'Intereses recibidos']*100,agg_global_data_mat.loc[i_idx_mxn, 'Dividendos recibidos']])\n",
    "            agg_global_data_mat = agg_global_data_mat2\n",
    "        ######################################################\n",
    "\n",
    "        agg_global_data_mat['% Total Cartera'] = agg_global_data_mat['Valor Actual'] / sum(agg_global_data_mat['Valor Actual'])\n",
    "        agg_global_data_mat['% Total RV'] = agg_global_data_mat.loc[agg_global_data_mat['Clasificación'].isin(['Acciones', 'Fondos RV', 'ETFs RV'])]['Valor Actual']/sum(agg_global_data_mat.loc[agg_global_data_mat['Clasificación'].isin(['Acciones', 'Fondos RV', 'ETFs RV'])]['Valor Actual'])\n",
    "        agg_global_data_mat['% Total RF'] = agg_global_data_mat.loc[agg_global_data_mat['Clasificación'].isin(['Bonos', 'Fondos RF', 'ETFs RF','Preferentes'])]['Valor Actual']/sum(agg_global_data_mat.loc[agg_global_data_mat['Clasificación'].isin(['Bonos', 'Fondos RF', 'ETFs RF','Preferentes'])]['Valor Actual'])                    \n",
    "        \n",
    "        agg_global_data_mat = agg_global_data_mat.drop_duplicates().reset_index()\n",
    "        agg_global_data_mat = agg_global_data_mat.drop(['index'], axis=1)\n",
    "        \n",
    "        hidden_widgets3.layout.visibility = 'visible'\n",
    "\n",
    "    else:\n",
    "        print_message_box.value = 'HAY ACTIVOS SIN CLASIFICAR CORRECTAMENTE'\n",
    "    \n",
    "def Global_Reporting_Generation (tgt = None):\n",
    "    global global_mat\n",
    "    global agg_global_data_mat\n",
    "    global def_mat_div\n",
    "    global def_mat_cup\n",
    "    global def_forward_mat_cup        \n",
    "    global df_bancos_manejada\n",
    "    global dep_ret_mat\n",
    "    global tot_div\n",
    "    global tot_cup\n",
    "    global df_rf_dist_activ\n",
    "\n",
    "    #Se declaran los dfs necesarios para generar el Global Reporting\n",
    "    df_liquidez = pd.DataFrame(data={})\n",
    "    \n",
    "    df_bonos = pd.DataFrame(data={})\n",
    "    df_preferentes = pd.DataFrame(data={})\n",
    "    df_fi_rf = pd.DataFrame(data={})\n",
    "    df_etf_rf = pd.DataFrame(data={})\n",
    "    \n",
    "    df_acciones = pd.DataFrame(data={})\n",
    "    df_fi_rv = pd.DataFrame(data={})\n",
    "    df_etf_rv = pd.DataFrame(data={})\n",
    "    \n",
    "    df_rf_dist_activ = pd.DataFrame(data={})\n",
    "    df_rf_dist_pais = pd.DataFrame(data={})\n",
    "    df_rf_dist_sector = pd.DataFrame(data={})\n",
    "    \n",
    "    df_rv_dist_activ = pd.DataFrame(data={})\n",
    "    df_rv_dist_pais = pd.DataFrame(data={})\n",
    "    df_rv_dist_sector = pd.DataFrame(data={}) \n",
    "    \n",
    "    if len(agg_global_data_mat.loc[agg_global_data_mat['Clasificación'].isin(['CASH','Tesoros'])]) > 0:\n",
    "        liquidity_per_bank = agg_global_data_mat.loc[agg_global_data_mat['Clasificación'].isin(['Tesoros','CASH'])]\n",
    "        \n",
    "        # Fill DataFrame\n",
    "        for i_bank in liquidity_per_bank['Banco'].unique():\n",
    "            # Value\n",
    "            aux_liquidity_per_bank = liquidity_per_bank.loc[liquidity_per_bank['Banco'].isin([i_bank])][['Clasificación','Valor Actual']]\n",
    "            aux_tesoros = aux_liquidity_per_bank[aux_liquidity_per_bank['Clasificación'] == 'Tesoros'][['Valor Actual']].sum()\n",
    "            aux_cash = aux_liquidity_per_bank[aux_liquidity_per_bank['Clasificación'] == 'CASH'][['Valor Actual']].sum()\n",
    "\n",
    "            # Add to the DataFrame\n",
    "            df_liquidez.loc['CASH',i_bank] = aux_cash[0]\n",
    "            df_liquidez.loc['Tesoros',i_bank] = aux_tesoros[0]\n",
    "        \n",
    "        # Adjust format to excel\n",
    "        df_liquidez = df_liquidez.reset_index().rename(columns={\"index\": \"\"})\n",
    "        \n",
    "    \n",
    "    if len(agg_global_data_mat.loc[agg_global_data_mat['Clasificación'].isin(['Bonos'])]) > 0:\n",
    "        df_bonos = agg_global_data_mat.loc[agg_global_data_mat['Clasificación'].isin(['Bonos'])][['Banco', 'Título', 'Divisa', 'País', 'Cupón', 'Vencimiento',\n",
    "                                                                                                        'Nominal', 'Fecha Compra', 'Precio compra',\n",
    "                                                                                                        'Valor de Compra', 'Precio Actual',\n",
    "                                                                                                        'Dividendos+Intereses', 'Valor Actual',\n",
    "                                                                                                        'Retorno Obtenido', '% Total RF',\n",
    "                                                                                                        '% Total Cartera']]\n",
    "        \n",
    "        df_bonos = df_bonos.rename(columns = {'Dividendos+Intereses': 'Intereses recibidos'})\n",
    "        df_bonos = df_bonos.sort_values(by=['% Total Cartera'], ascending=False)\n",
    "        \n",
    "    if len(agg_global_data_mat.loc[agg_global_data_mat['Clasificación'].isin(['Preferentes'])]) > 0:\n",
    "        df_preferentes = agg_global_data_mat.loc[agg_global_data_mat['Clasificación'].isin(['Preferentes'])][['Banco', 'Título', 'Divisa', 'País', 'Cupón', 'Vencimiento',\n",
    "                                                                                                        'Nominal', 'Fecha Compra', 'Precio compra',\n",
    "                                                                                                        'Valor de Compra', 'Precio Actual',\n",
    "                                                                                                        'Dividendos+Intereses', 'Valor Actual',\n",
    "                                                                                                        'Retorno Obtenido', '% Total RF',\n",
    "                                                                                                        '% Total Cartera']]\n",
    "        \n",
    "        df_preferentes = df_preferentes.rename(columns = {'Dividendos+Intereses': 'Intereses recibidos'})\n",
    "        df_preferentes = df_preferentes.sort_values(by=['% Total Cartera'], ascending=False)    \n",
    "    \n",
    "    if len(agg_global_data_mat.loc[agg_global_data_mat['Clasificación'].isin(['Fondos RF'])]) > 0:\n",
    "        df_fi_rf = agg_global_data_mat.loc[agg_global_data_mat['Clasificación'].isin(['Fondos RF'])][['Banco', 'Título', 'Divisa', 'País',\n",
    "                                                                                                        'Nominal', 'Fecha Compra', 'Precio compra',\n",
    "                                                                                                        'Valor de Compra', 'Precio Actual',\n",
    "                                                                                                        'Dividendos+Intereses', 'Valor Actual',\n",
    "                                                                                                        'Retorno Obtenido', '% Total RF',\n",
    "                                                                                                        '% Total Cartera']]\n",
    "        \n",
    "        df_fi_rf = df_fi_rf.rename(columns = {'Dividendos+Intereses': 'Intereses recibidos'})\n",
    "        df_fi_rf = df_fi_rf.sort_values(by=['% Total Cartera'], ascending=False)\n",
    "        \n",
    "    if len(agg_global_data_mat.loc[agg_global_data_mat['Clasificación'].isin(['ETFs RF'])]) > 0:\n",
    "        df_etf_rf = agg_global_data_mat.loc[agg_global_data_mat['Clasificación'].isin(['ETFs RF'])][['Banco', 'Título', 'Divisa', 'País',\n",
    "                                                                                                        'Nominal', 'Fecha Compra', 'Precio compra',\n",
    "                                                                                                        'Valor de Compra', 'Precio Actual',\n",
    "                                                                                                        'Dividendos+Intereses', 'Valor Actual',\n",
    "                                                                                                        'Retorno Obtenido', '% Total RF',\n",
    "                                                                                                        '% Total Cartera']]\n",
    "        \n",
    "        df_etf_rf = df_etf_rf.rename(columns = {'Dividendos+Intereses': 'Intereses recibidos'})\n",
    "        df_etf_rf = df_etf_rf.sort_values(by=['% Total Cartera'], ascending=False)\n",
    "    \n",
    "    if len(agg_global_data_mat.loc[agg_global_data_mat['Clasificación'].isin(['Acciones'])]) > 0:\n",
    "        df_acciones = agg_global_data_mat.loc[agg_global_data_mat['Clasificación'].isin(['Acciones'])][['Banco', 'Título', 'Divisa', 'País',\n",
    "                                                                                                        'Nominal', 'Fecha Compra', 'Precio compra',\n",
    "                                                                                                        'Valor de Compra', 'Precio Actual',\n",
    "                                                                                                        'Dividendos+Intereses', 'Valor Actual',\n",
    "                                                                                                        'Retorno Obtenido', '% Total RV',\n",
    "                                                                                                        '% Total Cartera']]\n",
    "        \n",
    "        df_acciones = df_acciones.rename(columns = {'Dividendos+Intereses': 'Dividendos recibidos'})\n",
    "        df_acciones = df_acciones.sort_values(by=['% Total Cartera'], ascending=False)\n",
    "    \n",
    "    if len(agg_global_data_mat.loc[agg_global_data_mat['Clasificación'].isin(['Fondos RV'])]) > 0:\n",
    "        df_fi_rv = agg_global_data_mat.loc[agg_global_data_mat['Clasificación'].isin(['Fondos RV'])][['Banco', 'Título', 'Divisa', 'País',\n",
    "                                                                                                        'Nominal', 'Fecha Compra', 'Precio compra',\n",
    "                                                                                                        'Valor de Compra', 'Precio Actual',\n",
    "                                                                                                        'Dividendos+Intereses', 'Valor Actual',\n",
    "                                                                                                        'Retorno Obtenido', '% Total RV',\n",
    "                                                                                                        '% Total Cartera']]\n",
    "        \n",
    "        df_fi_rv = df_fi_rv.rename(columns = {'Dividendos+Intereses': 'Dividendos recibidos'})\n",
    "        df_fi_rv = df_fi_rv.sort_values(by=['% Total Cartera'], ascending=False)\n",
    "\n",
    "    if len(agg_global_data_mat.loc[agg_global_data_mat['Clasificación'].isin(['ETFs RV'])]) > 0:\n",
    "        df_etf_rv = agg_global_data_mat.loc[agg_global_data_mat['Clasificación'].isin(['ETFs RV'])][['Banco', 'Título', 'Divisa', 'País',\n",
    "                                                                                                        'Nominal', 'Fecha Compra', 'Precio compra',\n",
    "                                                                                                        'Valor de Compra', 'Precio Actual',\n",
    "                                                                                                        'Dividendos+Intereses', 'Valor Actual',\n",
    "                                                                                                        'Retorno Obtenido', '% Total RV',\n",
    "                                                                                                        '% Total Cartera']]\n",
    "        \n",
    "        df_etf_rv = df_etf_rv.rename(columns = {'Dividendos+Intereses': 'Dividendos recibidos'})\n",
    "        df_etf_rv = df_etf_rv.sort_values(by=['% Total Cartera'], ascending=False)\n",
    "    \n",
    "    df_all_RF = agg_global_data_mat.loc[agg_global_data_mat['Clasificación'].isin(['Bonos', 'Fondos RF', 'ETFs RF','Preferentes'])]\n",
    "    \n",
    "    if len(df_all_RF) > 0:\n",
    "        df_rf_dist_activ = pd.DataFrame({'DISTRIBUCIÓN POR TIPO DE ACTIVO':df_all_RF.groupby(['Clasificación'])['Valor Actual'].sum()}).reset_index()\n",
    "        df_rf_dist_activ['DISTRIBUCIÓN POR TIPO DE ACTIVO'] = df_rf_dist_activ['DISTRIBUCIÓN POR TIPO DE ACTIVO']/sum(df_rf_dist_activ['DISTRIBUCIÓN POR TIPO DE ACTIVO'])\n",
    "\n",
    "        df_rf_dist_pais = pd.DataFrame({'DISTRIBUCIÓN POR PAÍS':df_all_RF.groupby(['País'])['Valor Actual'].sum()}).reset_index()\n",
    "        df_rf_dist_pais['DISTRIBUCIÓN POR PAÍS'] = df_rf_dist_pais['DISTRIBUCIÓN POR PAÍS']/sum(df_rf_dist_pais['DISTRIBUCIÓN POR PAÍS'])\n",
    "\n",
    "        df_rf_dist_sector = pd.DataFrame({'DISTRIBUCIÓN POR SECTOR':df_all_RF.groupby(['Sector'])['Valor Actual'].sum()}).reset_index()\n",
    "        df_rf_dist_sector['DISTRIBUCIÓN POR SECTOR'] = df_rf_dist_sector['DISTRIBUCIÓN POR SECTOR']/sum(df_rf_dist_sector['DISTRIBUCIÓN POR SECTOR'])\n",
    "\n",
    "    df_all_RV = agg_global_data_mat.loc[agg_global_data_mat['Clasificación'].isin(['Acciones', 'Fondos RV', 'ETFs RV'])]\n",
    "\n",
    "    if len(df_all_RV) > 0:\n",
    "        df_rv_dist_activ = pd.DataFrame({'DISTRIBUCIÓN POR TIPO DE ACTIVO':df_all_RV.groupby(['Clasificación'])['Valor Actual'].sum()}).reset_index()\n",
    "        df_rv_dist_activ['DISTRIBUCIÓN POR TIPO DE ACTIVO'] = df_rv_dist_activ['DISTRIBUCIÓN POR TIPO DE ACTIVO']/sum(df_rv_dist_activ['DISTRIBUCIÓN POR TIPO DE ACTIVO'])\n",
    "\n",
    "        df_rv_dist_pais = pd.DataFrame({'DISTRIBUCIÓN POR PAÍS':df_all_RV.groupby(['País'])['Valor Actual'].sum()}).reset_index()\n",
    "        df_rv_dist_pais['DISTRIBUCIÓN POR PAÍS'] = df_rv_dist_pais['DISTRIBUCIÓN POR PAÍS']/sum(df_rv_dist_pais['DISTRIBUCIÓN POR PAÍS'])\n",
    "\n",
    "        df_rv_dist_sector = pd.DataFrame({'DISTRIBUCIÓN POR SECTOR':df_all_RV.groupby(['Sector'])['Valor Actual'].sum()}).reset_index()\n",
    "        df_rv_dist_sector['DISTRIBUCIÓN POR SECTOR'] = df_rv_dist_sector['DISTRIBUCIÓN POR SECTOR']/sum(df_rv_dist_sector['DISTRIBUCIÓN POR SECTOR'])\n",
    "\n",
    "    dist_global_pais = pd.DataFrame({'DISTRIBUCIÓN POR PAÍS':agg_global_data_mat.groupby(['País'])['Valor Actual'].sum()}).reset_index()\n",
    "    dist_global_pais = dist_global_pais.rename(index=str, columns={'País': 'DISTRIBUCIÓN POR PAÍS', 'DISTRIBUCIÓN POR PAÍS': 'Valor'}) \n",
    "    dist_global_pais = dist_global_pais.sort_values(by=['Valor'], ascending=False)\n",
    "    dist_global_pais['%'] = dist_global_pais['Valor']/sum(dist_global_pais['Valor'])\n",
    "    dist_global_pais = dist_global_pais.head(15)\n",
    "\n",
    "    dist_global_sector = pd.DataFrame({'DISTRIBUCIÓN POR SECTOR':agg_global_data_mat.groupby(['Sector'])['Valor Actual'].sum()}).reset_index()\n",
    "    dist_global_sector = dist_global_sector.rename(index=str, columns={'Sector': 'DISTRIBUCIÓN POR SECTOR', 'DISTRIBUCIÓN POR SECTOR': 'Valor'}) \n",
    "    dist_global_sector = dist_global_sector.sort_values(by=['Valor'], ascending=False)\n",
    "    dist_global_sector['%'] = dist_global_sector['Valor']/sum(dist_global_sector['Valor'])\n",
    "    dist_global_sector = dist_global_sector.head(15)    \n",
    "    \n",
    "    df_divisas = agg_global_data_mat.copy()\n",
    "    for i in range(len(df_divisas)):\n",
    "        if df_divisas.loc[i,'Divisa'] == 'USD' or df_divisas.loc[i,'Divisa'] == 'EUR' or df_divisas.loc[i,'Divisa'] == 'MXN' or df_divisas.loc[i,'Divisa'] == 'GBP':\n",
    "            pass\n",
    "        else:\n",
    "            df_divisas.loc[i,'Divisa'] = 'OTRAS'        \n",
    "            \n",
    "    #Se obtienen los valores iniciales de la cartera\n",
    "    aux_df_divisas_0 = global_mat[global_mat['date'].isin([global_mat['date'].unique()[0]])][['Divisa', 'value']]\n",
    "    for i in aux_df_divisas_0.index:\n",
    "        if aux_df_divisas_0.loc[i,'Divisa'] == 'USD' or aux_df_divisas_0.loc[i,'Divisa'] == 'EUR' or aux_df_divisas_0.loc[i,'Divisa'] == 'MXN' or aux_df_divisas_0.loc[i,'Divisa'] == 'GBP':\n",
    "            pass\n",
    "        else:\n",
    "            aux_df_divisas_0.loc[i,'Divisa'] = 'OTRAS'           \n",
    "            \n",
    "    aux_df_divisas_0 = aux_df_divisas_0.rename(index=str, columns={'value': 'Valor de Compra Report'})\n",
    "    \n",
    "    df_divisas = df_divisas.append(aux_df_divisas_0, ignore_index=True)\n",
    "\n",
    "    df_divisas = df_divisas.groupby(['Divisa'])[['Valor de Compra Report', 'Valor Actual']].sum().reset_index()\n",
    "    df_divisas = df_divisas.rename(index=str, columns={'Divisa': 'DISTRIBUCÓN POR DIVISA', 'Valor de Compra Report': 'Fecha Inicial', 'Valor Actual': 'Fecha Final'})\n",
    "    df_divisas['Variación'] = (df_divisas['Fecha Final'] / df_divisas['Fecha Inicial']) - 1   \n",
    "    df_divisas['% del total'] = df_divisas['Fecha Final'] / sum(df_divisas['Fecha Final'].fillna(0))\n",
    "    df_divisas = df_divisas[['DISTRIBUCÓN POR DIVISA', 'Fecha Inicial', 'Variación', 'Fecha Final', '% del total']]\n",
    "    df_divisas = df_divisas.append(pd.DataFrame(data={'DISTRIBUCÓN POR DIVISA':'',\n",
    "                                                      'Fecha Inicial': df_divisas['Fecha Inicial'].sum(),\n",
    "                                                      'Variación': '',\n",
    "                                                      'Fecha Final': df_divisas['Fecha Final'].sum(),\n",
    "                                                      '% del total': ''}, index=[0]), ignore_index=True)\n",
    "\n",
    "    df_agg_asset_type = pd.DataFrame(data={'DISTRIBUCIÓN POR ACTIVO FINANCIERO': [], 'Fecha Inicial': [], 'Fecha Final': []})\n",
    "    aux_agg_asset_type_rf = pd.DataFrame(data={'DISTRIBUCIÓN POR ACTIVO FINANCIERO': [], 'Fecha Inicial': [], 'Fecha Final': []})\n",
    "    aux_agg_asset_type_rv = pd.DataFrame(data={'DISTRIBUCIÓN POR ACTIVO FINANCIERO': [], 'Fecha Inicial': [], 'Fecha Final': []})\n",
    "    \n",
    "    aux_agg_global_data_mat = agg_global_data_mat.copy()\n",
    "    \n",
    "    aux_agg_global_data_mat_0 = global_mat[global_mat['date'].isin([global_mat['date'].unique()[0]])][['Clasificación', 'Banco', 'value']]\n",
    "    aux_agg_global_data_mat_0 = aux_agg_global_data_mat_0.rename(index=str, columns={'value': 'Valor de Compra Report'})\n",
    "    \n",
    "    aux_agg_global_data_mat = aux_agg_global_data_mat.append(aux_agg_global_data_mat_0, ignore_index=True)\n",
    "\n",
    "    agg_asset_type_liq = pd.DataFrame(data={'DISTRIBUCIÓN POR ACTIVO FINANCIERO': \"1 - Liquidez\",\n",
    "                                            'Fecha Inicial': aux_agg_global_data_mat.loc[aux_agg_global_data_mat['Clasificación'].isin(['CASH','Tesoros'])]['Valor de Compra Report'].sum(),\n",
    "                                            'Fecha Final': aux_agg_global_data_mat.loc[aux_agg_global_data_mat['Clasificación'].isin(['CASH','Tesoros'])]['Valor Actual'].sum()}, index=[0])    \n",
    "\n",
    "    try:\n",
    "        aux_data = aux_agg_global_data_mat.loc[aux_agg_global_data_mat['Clasificación'].isin(['Bonos'])].groupby(['Clasificación'])[['Valor de Compra Report', 'Valor Actual']].sum().reset_index().values[0].tolist()\n",
    "        aux_agg_asset_type_rf = aux_agg_asset_type_rf.append(pd.DataFrame(data={'DISTRIBUCIÓN POR ACTIVO FINANCIERO': '2.1 - Directo: Bonos', 'Fecha Inicial': aux_data[1], 'Fecha Final': aux_data[2]}, index=[0]))\n",
    "    except:\n",
    "        aux_agg_asset_type_rf = aux_agg_asset_type_rf.append(pd.DataFrame(data={'DISTRIBUCIÓN POR ACTIVO FINANCIERO': '2.1 - Directo: Bonos', 'Fecha Inicial': 0, 'Fecha Final': 0}, index=[0]))\n",
    "\n",
    "    try:\n",
    "        aux_data = aux_agg_global_data_mat.loc[aux_agg_global_data_mat['Clasificación'].isin(['Fondos RF'])].groupby(['Clasificación'])[['Valor de Compra Report', 'Valor Actual']].sum().reset_index().values[0].tolist()\n",
    "        aux_agg_asset_type_rf = aux_agg_asset_type_rf.append(pd.DataFrame(data={'DISTRIBUCIÓN POR ACTIVO FINANCIERO': '2.2 - Fondos RF', 'Fecha Inicial': aux_data[1], 'Fecha Final': aux_data[2]}, index=[1]))\n",
    "    except:\n",
    "        aux_agg_asset_type_rf = aux_agg_asset_type_rf.append(pd.DataFrame(data={'DISTRIBUCIÓN POR ACTIVO FINANCIERO': '2.2 - Fondos RF', 'Fecha Inicial': 0, 'Fecha Final': 0}, index=[1]))\n",
    "\n",
    "    try:\n",
    "        aux_data = aux_agg_global_data_mat.loc[aux_agg_global_data_mat['Clasificación'].isin(['ETFs RF'])].groupby(['Clasificación'])[['Valor de Compra Report', 'Valor Actual']].sum().reset_index().values[0].tolist()\n",
    "        aux_agg_asset_type_rf = aux_agg_asset_type_rf.append(pd.DataFrame(data={'DISTRIBUCIÓN POR ACTIVO FINANCIERO': \"2.3 - ETF's\", 'Fecha Inicial': aux_data[1], 'Fecha Final': aux_data[2]}, index=[2]))\n",
    "    except:\n",
    "        aux_agg_asset_type_rf = aux_agg_asset_type_rf.append(pd.DataFrame(data={'DISTRIBUCIÓN POR ACTIVO FINANCIERO': \"2.3 - ETF's\", 'Fecha Inicial': 0, 'Fecha Final': 0}, index=[2]))    \n",
    "\n",
    "        \n",
    "    try:\n",
    "        aux_data = aux_agg_global_data_mat.loc[aux_agg_global_data_mat['Clasificación'].isin(['Preferentes'])].groupby(['Clasificación'])[['Valor de Compra Report', 'Valor Actual']].sum().reset_index().values[0].tolist()\n",
    "        aux_agg_asset_type_rf = aux_agg_asset_type_rf.append(pd.DataFrame(data={'DISTRIBUCIÓN POR ACTIVO FINANCIERO': \"2.4 - Preferentes\", 'Fecha Inicial': aux_data[1], 'Fecha Final': aux_data[2]}, index=[3]))\n",
    "    except:\n",
    "        aux_agg_asset_type_rf = aux_agg_asset_type_rf.append(pd.DataFrame(data={'DISTRIBUCIÓN POR ACTIVO FINANCIERO': \"2.4 - Preferentes\", 'Fecha Inicial': 0, 'Fecha Final': 0}, index=[3]))  \n",
    "        \n",
    "        \n",
    "        \n",
    "    agg_asset_type_rf = pd.DataFrame(data={'DISTRIBUCIÓN POR ACTIVO FINANCIERO': \"2 - Renta Fija\", 'Fecha Inicial': aux_agg_asset_type_rf['Fecha Inicial'].sum(), 'Fecha Final': aux_agg_asset_type_rf['Fecha Final'].sum()}, index=[0])    \n",
    "\n",
    "    try:\n",
    "        aux_data = aux_agg_global_data_mat.loc[aux_agg_global_data_mat['Clasificación'].isin(['Acciones'])].groupby(['Clasificación'])[['Valor de Compra Report', 'Valor Actual']].sum().reset_index().values[0].tolist()\n",
    "        aux_agg_asset_type_rv = aux_agg_asset_type_rv.append(pd.DataFrame(data={'DISTRIBUCIÓN POR ACTIVO FINANCIERO': '3.1 - Directo: Acciones', 'Fecha Inicial': aux_data[1], 'Fecha Final': aux_data[2]}, index=[0]))\n",
    "    except:\n",
    "        aux_agg_asset_type_rv = aux_agg_asset_type_rv.append(pd.DataFrame(data={'DISTRIBUCIÓN POR ACTIVO FINANCIERO': '3.1 - Directo: Acciones', 'Fecha Inicial': 0, 'Fecha Final': 0}, index=[0]))\n",
    "\n",
    "    try:\n",
    "        aux_data = aux_agg_global_data_mat.loc[aux_agg_global_data_mat['Clasificación'].isin(['Fondos RV'])].groupby(['Clasificación'])[['Valor de Compra Report', 'Valor Actual']].sum().reset_index().values[0].tolist()\n",
    "        aux_agg_asset_type_rv = aux_agg_asset_type_rv.append(pd.DataFrame(data={'DISTRIBUCIÓN POR ACTIVO FINANCIERO': '3.2 - Fondos RV', 'Fecha Inicial': aux_data[1], 'Fecha Final': aux_data[2]}, index=[1]))\n",
    "    except:\n",
    "        aux_agg_asset_type_rv = aux_agg_asset_type_rv.append(pd.DataFrame(data={'DISTRIBUCIÓN POR ACTIVO FINANCIERO': '3.2 - Fondos RV', 'Fecha Inicial': 0, 'Fecha Final': 0}, index=[1]))\n",
    "\n",
    "    try:\n",
    "        aux_data = aux_agg_global_data_mat.loc[aux_agg_global_data_mat['Clasificación'].isin(['ETFs RV'])].groupby(['Clasificación'])[['Valor de Compra Report', 'Valor Actual']].sum().reset_index().values[0].tolist()\n",
    "        aux_agg_asset_type_rv = aux_agg_asset_type_rv.append(pd.DataFrame(data={'DISTRIBUCIÓN POR ACTIVO FINANCIERO': \"3.3 - ETF's\", 'Fecha Inicial': aux_data[1], 'Fecha Final': aux_data[2]}, index=[2]))\n",
    "    except:\n",
    "        aux_agg_asset_type_rv = aux_agg_asset_type_rv.append(pd.DataFrame(data={'DISTRIBUCIÓN POR ACTIVO FINANCIERO': \"3.3 - ETF's\", 'Fecha Inicial': 0, 'Fecha Final': 0}, index=[2]))        \n",
    "\n",
    "    agg_asset_type_rv = pd.DataFrame(data={'DISTRIBUCIÓN POR ACTIVO FINANCIERO': \"3 - Renta Variable\", 'Fecha Inicial': aux_agg_asset_type_rv['Fecha Inicial'].sum(), 'Fecha Final': aux_agg_asset_type_rv['Fecha Final'].sum()}, index=[0])    \n",
    "\n",
    "    df_agg_asset_type = df_agg_asset_type.append([agg_asset_type_liq, agg_asset_type_rf,aux_agg_asset_type_rf,\n",
    "                                                  agg_asset_type_rv, aux_agg_asset_type_rv], ignore_index=True)\n",
    "\n",
    "    list_weights = []\n",
    "    for i in range(len(df_agg_asset_type)):\n",
    "        if i == 0 or i == 1 or i == 6:\n",
    "            list_weights += [df_agg_asset_type.loc[i, 'Fecha Final']/df_agg_asset_type.loc[[0,1,6], 'Fecha Final'].sum()]\n",
    "        elif i == 2 or i == 3 or i == 4 or i == 5:\n",
    "            list_weights += [df_agg_asset_type.loc[i, 'Fecha Final']/df_agg_asset_type.loc[[2,3,4,5], 'Fecha Final'].sum()]\n",
    "        else:\n",
    "            list_weights += [df_agg_asset_type.loc[i, 'Fecha Final']/df_agg_asset_type.loc[[7,8,9], 'Fecha Final'].sum()]\n",
    "\n",
    "    df_agg_asset_type['% del total'] = list_weights\n",
    "    df_agg_asset_type['Variación'] = ((df_agg_asset_type['Fecha Final'] / df_agg_asset_type['Fecha Inicial']) - 1).fillna(0)   \n",
    "    df_agg_asset_type = df_agg_asset_type[['DISTRIBUCIÓN POR ACTIVO FINANCIERO', 'Fecha Inicial', 'Variación', 'Fecha Final', '% del total']]\n",
    "    df_agg_asset_type = df_agg_asset_type.append(pd.DataFrame(data={'DISTRIBUCIÓN POR ACTIVO FINANCIERO':'', 'Fecha Inicial': df_agg_asset_type.loc[[0,1,6],'Fecha Inicial'].sum(),\n",
    "                                                                    'Variación': '', 'Fecha Final': df_agg_asset_type.loc[[0,1,6],'Fecha Final'].sum(), '% del total': ''}, index=[0]), ignore_index=True)\n",
    "\n",
    "    \n",
    "    df_bancos = aux_agg_global_data_mat.groupby(['Banco'])[['Valor de Compra Report', 'Valor Actual']].sum().reset_index()\n",
    "    df_bancos = df_bancos.rename(index=str, columns={'Valor de Compra Report': 'Fecha Inicial', 'Valor Actual': 'Fecha Final'})\n",
    "    df_bancos['Tipo'] = 'Custodia'\n",
    "\n",
    "    #Comprobar si se ha añadido alguna cartera manejada\n",
    "    try:\n",
    "        df_bancos_manejada.columns\n",
    "        df_bancos = df_bancos.append(df_bancos_manejada, ignore_index=True)\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    agg_bancos = df_bancos.groupby(['Banco'])[['Fecha Inicial', 'Fecha Final']].sum().reset_index()\n",
    "    agg_bancos['Variación'] = ((agg_bancos['Fecha Final'] / agg_bancos['Fecha Inicial']) - 1).fillna(0)\n",
    "    agg_bancos['%del total'] = agg_bancos['Fecha Final'] / agg_bancos['Fecha Final'].sum()\n",
    "    agg_bancos = agg_bancos.append(pd.DataFrame(data={'Banco':'', 'Fecha Inicial': agg_bancos['Fecha Inicial'].sum(), 'Fecha Final': agg_bancos['Fecha Final'].sum(), 'Variación': '', '%del total': ''}, index=[0]), ignore_index=True)\n",
    "\n",
    "    df_bancos['Variación'] = ((df_bancos['Fecha Final'] / df_bancos['Fecha Inicial']) - 1).fillna(0)\n",
    "\n",
    "    def_agg_bancos = pd.DataFrame(columns = agg_bancos.columns.tolist())\n",
    "\n",
    "    for i in range(len(agg_bancos)):\n",
    "        dict_df = dict(zip(agg_bancos.columns.tolist(), agg_bancos.loc[i].values.tolist()))\n",
    "        def_agg_bancos = def_agg_bancos.append(pd.DataFrame(data=dict_df, index=[0]), ignore_index=True)\n",
    "        if i < (len(agg_bancos)-1):\n",
    "            aux_sub_df_bancos = df_bancos.loc[df_bancos['Banco'].isin([agg_bancos.loc[i].values.tolist()[0]])].sort_values(by='Tipo', ascending=True)\n",
    "            for idx in aux_sub_df_bancos.index:\n",
    "                sub_list = aux_sub_df_bancos.loc[idx].values.tolist()\n",
    "                aux_dict_df = dict(zip(agg_bancos.columns.tolist(), [sub_list[3], sub_list[1], sub_list[2], sub_list[4], '']))\n",
    "                def_agg_bancos = def_agg_bancos.append(pd.DataFrame(data=aux_dict_df, index=[0]), ignore_index=True)\n",
    "\n",
    "    def_agg_bancos = def_agg_bancos[['Banco', 'Fecha Inicial', 'Variación', 'Fecha Final', '%del total']]\n",
    "    def_agg_bancos = def_agg_bancos.rename(index=str, columns={'Banco': 'DISTRIBUCÓN POR BANCO'})\n",
    "\n",
    "    def_mat_resumen = pd.DataFrame(columns=['Resumen', 'Valor'])\n",
    "    \n",
    "#     tot_div = agg_global_data_mat.loc[~agg_global_data_mat['Clasificación'].isin(['Bonos'])]['Dividendos+Intereses'].sum()\n",
    "#     tot_cup = agg_global_data_mat.loc[agg_global_data_mat['Clasificación'].isin(['Bonos'])]['Dividendos+Intereses'].sum()\n",
    "    \n",
    "    try:\n",
    "        var_exist_test = tot_div - 1\n",
    "    except:\n",
    "        tot_div = 0\n",
    "        \n",
    "    try:\n",
    "        var_exist_test = tot_cup - 1\n",
    "    except:\n",
    "        tot_cup = 0        \n",
    "    \n",
    "    tot_rentas = tot_div + tot_cup \n",
    "    \n",
    "    def_mat_resumen.loc[0] = ['Total activos incio periodo', sum(global_mat[global_mat['date'].isin([global_mat['date'].unique()[0]])]['value'])]\n",
    "    def_mat_resumen.loc[7] = ['Total activos al final del  periodo', agg_bancos.loc[len(agg_bancos)-1,'Fecha Final']]\n",
    "    def_mat_resumen.loc[3] = ['Rentas del periodo', tot_rentas]\n",
    "    def_mat_resumen.loc[4] = ['Dividendos', tot_div]\n",
    "    def_mat_resumen.loc[5] = ['Cupones', tot_cup]\n",
    "    def_mat_resumen.loc[2] = ['Cambio en el valor de los activos', def_mat_resumen.loc[7, 'Valor'] - def_mat_resumen.loc[0, 'Valor']]\n",
    "    def_mat_resumen.loc[6] = ['Variación con intereses y dividendos', def_mat_resumen.loc[3, 'Valor'] + def_mat_resumen.loc[2, 'Valor']]\n",
    "\n",
    "    #Comprobar si se han añadido depositos y retiros\n",
    "    try:\n",
    "        dep_ret_mat.columns\n",
    "        def_mat_resumen.loc[1] = ['Depósitos y retiros', dep_ret_mat['Valor'].sum()]\n",
    "\n",
    "    except:\n",
    "        def_mat_resumen.loc[1] = ['Depósitos y retiros', 0]\n",
    "\n",
    "    def_mat_resumen = def_mat_resumen.sort_index(axis=0)  \n",
    "    \n",
    "    #Se carga el Excel que se utiliza como soporte de datos para generar las gráficas en PowerPoint\n",
    "    #Sobre SOPORTE_GLOBAL_REPORTING se sobreescriben las pestañas con los valores que están linkados a las pestañas con los gráficos\n",
    "\n",
    "    book = load_workbook('SOPORTE_GLOBAL_REPORTING.xlsx')\n",
    "    writer = pd.ExcelWriter('SOPORTE_GLOBAL_REPORTING.xlsx', engine='openpyxl') \n",
    "    writer.book = book\n",
    "    writer.sheets = dict((ws.title, ws) for ws in book.worksheets)\n",
    "    \n",
    "    # Añadir una pestaña auxiliar para que al borrarlas al menos en el Excel quede una y no salte un error\n",
    "    pestana_blanco = pd.DataFrame(data={})\n",
    "    pestana_blanco.to_excel(writer, 'aux_sheet')\n",
    "    writer.save()\n",
    "\n",
    "    #Borrar pestañas con datos\n",
    "    book.remove_sheet(book.get_sheet_by_name('Soporte_Resumen'))\n",
    "    book.remove_sheet(book.get_sheet_by_name('Soporte_Distri_Bancos'))\n",
    "    book.remove_sheet(book.get_sheet_by_name('Soporte_Distri_ActyDiv'))\n",
    "    book.remove_sheet(book.get_sheet_by_name('Soporte_Distri_País'))\n",
    "    book.remove_sheet(book.get_sheet_by_name('Soporte_Distri_Sec'))\n",
    "    book.remove_sheet(book.get_sheet_by_name('Soporte_Liquidez'))  \n",
    "    book.remove_sheet(book.get_sheet_by_name('Soporte_Disti_RF'))   \n",
    "    book.remove_sheet(book.get_sheet_by_name('Soporte_df_bonos'))\n",
    "    book.remove_sheet(book.get_sheet_by_name('Soporte_df_preferentes'))\n",
    "    book.remove_sheet(book.get_sheet_by_name('Soporte_fi_rf'))\n",
    "    book.remove_sheet(book.get_sheet_by_name('Soporte_etf_rf'))\n",
    "    book.remove_sheet(book.get_sheet_by_name('Soporte_Disti_RV'))\n",
    "    book.remove_sheet(book.get_sheet_by_name('Soporte_df_acciones'))\n",
    "    book.remove_sheet(book.get_sheet_by_name('Soporte_fi_rv'))\n",
    "    book.remove_sheet(book.get_sheet_by_name('Soporte_etf_rv'))\n",
    "    book.remove_sheet(book.get_sheet_by_name('Soporte_mat_div'))\n",
    "    book.remove_sheet(book.get_sheet_by_name('Soporte_mat_cup'))\n",
    "    book.remove_sheet(book.get_sheet_by_name('Soporte_mat_cup_forward'))\n",
    "    book.remove_sheet(book.get_sheet_by_name('Extracción Datos'))\n",
    "    writer.save()\n",
    "\n",
    "    #Crearlas nuevamente para que estén vacías\n",
    "    book.create_sheet('Soporte_Resumen')\n",
    "    book.create_sheet('Soporte_Distri_Bancos')\n",
    "    book.create_sheet('Soporte_Distri_ActyDiv')\n",
    "    book.create_sheet('Soporte_Distri_País')\n",
    "    book.create_sheet('Soporte_Distri_Sec')\n",
    "    book.create_sheet('Soporte_Liquidez')\n",
    "    book.create_sheet('Soporte_Disti_RF')\n",
    "    book.create_sheet('Soporte_df_bonos')\n",
    "    book.create_sheet('Soporte_df_preferentes')\n",
    "    book.create_sheet('Soporte_fi_rf')\n",
    "    book.create_sheet('Soporte_etf_rf')\n",
    "    book.create_sheet('Soporte_Disti_RV')\n",
    "    book.create_sheet('Soporte_df_acciones')\n",
    "    book.create_sheet('Soporte_fi_rv')\n",
    "    book.create_sheet('Soporte_etf_rv')\n",
    "    book.create_sheet('Soporte_mat_div')\n",
    "    book.create_sheet('Soporte_mat_cup')\n",
    "    book.create_sheet('Soporte_mat_cup_forward')\n",
    "    book.create_sheet('Extracción Datos')\n",
    "    writer.save()\n",
    "\n",
    "    #Borrar la pestaña auxuliar\n",
    "    book.remove_sheet(book.get_sheet_by_name('aux_sheet'))\n",
    "    writer.save()    \n",
    "    \n",
    "    #Vuelve a cargar el Excel\n",
    "    book = load_workbook('SOPORTE_GLOBAL_REPORTING.xlsx')\n",
    "    writer = pd.ExcelWriter('SOPORTE_GLOBAL_REPORTING.xlsx', engine='openpyxl') \n",
    "    writer.book = book\n",
    "    writer.sheets = dict((ws.title, ws) for ws in book.worksheets)\n",
    "\n",
    "    #Cargar valores nuevos en las pestañas del Excel SOPORTE_GLOBAL_REPORTING\n",
    "    global_mat.to_excel(writer, 'Extracción Datos')\n",
    "    \n",
    "    df_liquidez.to_excel(writer, sheet_name='Soporte_Liquidez', startcol=0, index=False)\n",
    "    \n",
    "    df_rf_dist_activ.to_excel(writer, sheet_name='Soporte_Disti_RF', startcol=0, index=False)\n",
    "    df_rf_dist_pais.to_excel(writer, sheet_name='Soporte_Disti_RF', startcol=5, index=False)\n",
    "    df_rf_dist_sector.to_excel(writer, sheet_name='Soporte_Disti_RF', startcol=9, index=False)    \n",
    "\n",
    "    df_bonos.to_excel(writer, 'Soporte_df_bonos', index=False)\n",
    "    df_preferentes.to_excel(writer, 'Soporte_df_preferentes', index=False)\n",
    "    df_fi_rf.to_excel(writer, 'Soporte_fi_rf', index=False)\n",
    "    df_etf_rf.to_excel(writer, 'Soporte_etf_rf', index=False)\n",
    "\n",
    "    df_rv_dist_activ.to_excel(writer, sheet_name='Soporte_Disti_RV', startcol=0, index=False)\n",
    "    df_rv_dist_pais.to_excel(writer, sheet_name='Soporte_Disti_RV', startcol=5, index=False)\n",
    "    df_rv_dist_sector.to_excel(writer, sheet_name='Soporte_Disti_RV', startcol=9, index=False)    \n",
    "    df_acciones.to_excel(writer, 'Soporte_df_acciones', index=False)\n",
    "    df_fi_rv.to_excel(writer, 'Soporte_fi_rv', index=False)\n",
    "    df_etf_rv.to_excel(writer, 'Soporte_etf_rv', index=False)\n",
    "\n",
    "    try:\n",
    "        #Adaptación de la matriz al formato del GR\n",
    "        def_mat_div = pd.merge(def_mat_div, global_mat[['security', 'Título']].rename(columns = {'security': 'Ticker'}).drop_duplicates(keep='first'), how='left', on=['Ticker']).drop(['Ticker'], axis=1)\n",
    "        def_mat_div = def_mat_div[['Título'] + [str(i) for i in range(1,13)] + ['Total']] #Ordenar la matriz\n",
    "        def_mat_div = def_mat_div.rename(columns = {'1': 'Ene', '2': 'Feb', '3': 'Mar', '4': 'Abr', '5': 'May', '6': 'Jun', '7': 'Jul', '8': 'Ago', '9': 'Sept', '10': 'Oct', '11': 'Nov', '12': 'Dic'})\n",
    "        def_mat_div['Título'] = def_mat_div['Título'].fillna('Total')        \n",
    "        def_mat_div.to_excel(writer, 'Soporte_mat_div', index=False)\n",
    "    except:\n",
    "        pestana_blanco.to_excel(writer, 'Soporte_mat_div')\n",
    "\n",
    "    try:\n",
    "        #Adaptación de la matriz al formato del GR\n",
    "        def_mat_cup = pd.merge(def_mat_cup, global_mat[['security', 'Título', 'Cupón', 'Vencimiento']].rename(columns = {'security': 'Ticker'}).drop_duplicates(keep='first'), how='left', on=['Ticker']).drop(['Ticker'], axis=1)\n",
    "        def_mat_cup = def_mat_cup[['Título', 'Cupón', 'Vencimiento'] + [str(i) for i in range(1,13)] + ['Total']] #Ordenar la matriz\n",
    "        def_mat_cup = def_mat_cup.rename(columns = {'1': 'Ene', '2': 'Feb', '3': 'Mar', '4': 'Abr', '5': 'May', '6': 'Jun', '7': 'Jul', '8': 'Ago', '9': 'Sept', '10': 'Oct', '11': 'Nov', '12': 'Dic'})\n",
    "        def_mat_cup['Título'] = def_mat_cup['Título'].fillna('Total')        \n",
    "        def_mat_cup.to_excel(writer, 'Soporte_mat_cup', index=False)\n",
    "    except:\n",
    "        pestana_blanco.to_excel(writer, 'Soporte_mat_cup')\n",
    "\n",
    "    try:\n",
    "        #Adaptación de la matriz al formato del GR\n",
    "        def_forward_mat_cup = pd.merge(def_forward_mat_cup, global_mat[['security', 'Título', 'Cupón', 'Vencimiento']].rename(columns = {'security': 'Ticker'}).drop_duplicates(keep='first'),\n",
    "                                       how='left',\n",
    "                                       on=['Ticker']).drop(['Ticker'], axis=1)\n",
    "        def_forward_mat_cup = def_forward_mat_cup[['Título', 'Cupón', 'Vencimiento'] + [str(i) for i in range(1,13)] + ['Total']] #Ordenar la matriz\n",
    "        def_forward_mat_cup = def_forward_mat_cup.rename(columns = {'1': 'Ene', '2': 'Feb', '3': 'Mar', '4': 'Abr', '5': 'May', '6': 'Jun', '7': 'Jul', '8': 'Ago', '9': 'Sept', '10': 'Oct', '11': 'Nov', '12': 'Dic'})\n",
    "        def_forward_mat_cup['Título'] = def_forward_mat_cup['Título'].fillna('Total')        \n",
    "        def_forward_mat_cup.to_excel(writer, 'Soporte_mat_cup_forward', index=False)\n",
    "    except:\n",
    "        pestana_blanco.to_excel(writer, 'Soporte_mat_cup_forward')\n",
    "\n",
    "    dist_global_pais.to_excel(writer, 'Soporte_Distri_País', index=False)\n",
    "    dist_global_sector.to_excel(writer, 'Soporte_Distri_Sec', index=False)\n",
    "\n",
    "    df_agg_asset_type[['DISTRIBUCIÓN POR ACTIVO FINANCIERO', 'Fecha Inicial', 'Variación', 'Fecha Final', '% del total']].to_excel(writer, sheet_name='Soporte_Distri_ActyDiv', startcol=0, index=False)\n",
    "    df_agg_asset_type.loc[df_agg_asset_type['DISTRIBUCIÓN POR ACTIVO FINANCIERO'].isin(['1 - Liquidez',\n",
    "                                                                                        '2 - Renta Fija',\n",
    "                                                                                        '3 - Renta Variable'])][['DISTRIBUCIÓN POR ACTIVO FINANCIERO','Fecha Final']].to_excel(writer, sheet_name='Soporte_Distri_ActyDiv', startcol=9, index=False)\n",
    "    df_divisas[['DISTRIBUCÓN POR DIVISA', 'Fecha Inicial', 'Variación', 'Fecha Final', '% del total']].to_excel(writer, sheet_name='Soporte_Distri_ActyDiv', startrow=13, index=False)\n",
    "\n",
    "    def_agg_bancos.to_excel(writer, sheet_name='Soporte_Distri_Bancos', startcol=0, index=False)\n",
    "    df_bancos[['Banco', 'Fecha Final']].to_excel(writer, sheet_name='Soporte_Distri_Bancos', startcol=9, index=False)\n",
    "\n",
    "    def_mat_resumen.to_excel(writer, 'Soporte_Resumen', index=False)\n",
    "        \n",
    "    writer.save()      \n",
    "    \n",
    "    print_message_box.value = 'GLOBAL REPORTING GENERADO EN: ' + str(os.getcwd()) + '\\SOPORTE_GLOBAL_REPORTING.xlsx ' \n",
    "\n",
    "    \n",
    "def One_Pager_Generation (tgt = None):\n",
    "    global agg_global_data_mat\n",
    "    global tot_div\n",
    "    global tot_cup\n",
    "\n",
    "    for i_bank in agg_global_data_mat['Banco'].unique():\n",
    "        aux_agg_global_data_mat = agg_global_data_mat.loc[agg_global_data_mat['Banco'].isin([i_bank])]\n",
    "\n",
    "        #Se declaran los dfs necesarios para generar el One Pager\n",
    "        df_fi = pd.DataFrame(data={})\n",
    "        df_eq = pd.DataFrame(data={})\n",
    "        df_cash = pd.DataFrame(data={})\n",
    "        df_treasuries = pd.DataFrame(data={})\n",
    "        df_cash_otros = pd.DataFrame(data={})\n",
    "        df_otros = pd.DataFrame(data={})\n",
    "\n",
    "        aux_agg_global_data_mat = agg_global_data_mat.loc[agg_global_data_mat['Banco'].isin([i_bank])]\n",
    "        aux_agg_global_data_mat['Variación Precio'] = aux_agg_global_data_mat['Precio Actual'] / aux_agg_global_data_mat['Precio compra'] - 1 \n",
    "\n",
    "        if len(aux_agg_global_data_mat.loc[aux_agg_global_data_mat['Clasificación'].isin(['Bonos', 'Fondos RF', 'ETFs RF','Preferentes'])]) > 0:\n",
    "            \n",
    "            df_fi = aux_agg_global_data_mat.loc[aux_agg_global_data_mat['Clasificación'].isin(['Bonos', 'Fondos RF','ETFs RF','Preferentes'])]\n",
    "            \n",
    "            # Drop FI Short Dur --> Cash\n",
    "            df_fi = df_fi[df_fi.Maturity_Band_Focus != 'Ultra Short'][['Clasificación', 'Rating', 'País', 'security','Título','Divisa', 'Cupón', 'Vencimiento', 'Retorno Obtenido',\n",
    "                                                                       '% Total Cartera', 'Variación Precio', 'Nominal','Fecha Compra', 'Precio compra', 'Precio Actual',\n",
    "                                                                       'Dividendos+Intereses', 'Valor Actual','Valor de Compra']]\n",
    "            \n",
    "            df_fi = df_fi.rename(columns = {'Dividendos+Intereses': 'Intereses recibidos'})\n",
    "            \n",
    "            #Calcular Rating medio\n",
    "            aux_rating = aux_agg_global_data_mat.loc[aux_agg_global_data_mat['Clasificación'].isin(['Bonos','Preferentes']), ['Rating', 'Valor Actual']]\n",
    "            \n",
    "            list_rtg = aux_rating['Rating'].tolist()\n",
    "            aux_list_rtg = []\n",
    "            for i_rtg in list_rtg:\n",
    "                aix_i = i_rtg.split(' *')\n",
    "                aux_list_rtg += [aix_i[0]]\n",
    "            list_rtg = aux_list_rtg    \n",
    "            aux_list_rtg = []\n",
    "            for i_rtg in list_rtg:\n",
    "                aix_i = i_rtg.split('u')\n",
    "                aux_list_rtg += [aix_i[0]]\n",
    "\n",
    "            aux_rating['Clean_RTG'] = aux_list_rtg            \n",
    "            \n",
    "            #Generar un diccionario con el rating y su valor correspondiente y otro diccionario que sea el inverso de este\n",
    "            rating_valor = {'AAA': 21, 'AA+': 20, 'AA': 19, 'AA-': 18, 'A+': 17, 'A': 16, 'A-': 15,\n",
    "                            'BBB+': 14, 'BBB': 13, 'BBB-': 12, 'BB+': 11, 'BB': 10, 'BB-': 9, 'B+': 8, 'B': 7, 'B-': 6,\n",
    "                            'CCC+': 5, 'CCC': 4, 'CCC-': 3, 'CC': 2, 'C': 1, 'D': 0}\n",
    "            valor_rating = {'21': 'AAA', '20': 'AA+', '19': 'AA', '18': 'AA-', '17': 'A+', '16': 'A', '15': 'A-',\n",
    "                            '14': 'BBB+', '13': 'BBB', '12': 'BBB-', '11': 'BB+', '10': 'BB', '9': 'BB-', '8': 'B+', '7': 'B', '6': 'B-',\n",
    "                            '5': 'CCC+', '4': 'CCC', '3': 'CCC-', '2': 'CC', '1': 'C', '0': 'D'}    \n",
    "\n",
    "            #Asignar el número de rating a cada bono\n",
    "            aux_rating['Numero_Rating'] = aux_rating['Clean_RTG'].map(rating_valor).fillna(0)     \n",
    "            rating_medio = valor_rating[str(int(np.round(sum((aux_rating['Valor Actual']/aux_rating['Valor Actual'].sum()) * aux_rating['Numero_Rating']), 0)))]    \n",
    "\n",
    "            df_fi = df_fi.sort_values(by=['% Total Cartera'], ascending=False)\n",
    "\n",
    "            #Añadir filas en blanco para cuadrar la longitud de la matriz con el formato del Excel        \n",
    "            aux_len = 47 - len(df_fi)\n",
    "\n",
    "            if aux_len>0:\n",
    "                null_list = [np.nan]*(aux_len)      \n",
    "\n",
    "                df_fi = df_fi.append(pd.DataFrame(data = {'Clasificación': null_list, 'Rating': null_list, 'País': null_list, 'security': null_list, 'Título': null_list, 'Divisa': null_list, 'Cupón': null_list, 'Vencimiento': null_list,\n",
    "                                                          'Retorno Obtenido': null_list, '% Total Cartera': null_list, 'Variación Precio': null_list, 'Nominal': null_list, 'Fecha Compra': null_list, 'Precio compra': null_list,\n",
    "                                                          'Precio Actual': null_list, 'Intereses recibidos': null_list, 'Valor Actual': null_list}), ignore_index=True)        \n",
    "\n",
    "            #Añadir la última fila con totales        \n",
    "            df_fi = df_fi.append(pd.DataFrame(data = {'Clasificación': 'SUMA / MEDIA ', 'Rating': rating_medio,\n",
    "                                                      'País': '', 'security': '', 'Título': '', 'Divisa': '',\n",
    "                                                      'Cupón': sum((df_fi[df_fi['Clasificación'].isin(['Bonos','Preferentes'])]['Valor Actual'].fillna(0) / df_fi[df_fi['Clasificación'].isin(['Bonos','Preferentes'])]['Valor Actual'].fillna(0).sum())\n",
    "                                                                   *df_fi[df_fi['Clasificación'].isin(['Bonos','Preferentes'])]['Cupón'].fillna(0)),\n",
    "                                                      'Vencimiento': '',\n",
    "                                                      'Retorno Obtenido': sum((df_fi['Valor de Compra'].fillna(0)/df_fi['Valor de Compra'].fillna(0).sum()) * df_fi['Retorno Obtenido'].fillna(0)),\n",
    "                                                      '% Total Cartera': df_fi['% Total Cartera'].sum(),\n",
    "                                                      'Variación Precio': sum((df_fi['Valor Actual'].fillna(0)/df_fi['Valor Actual'].fillna(0).sum()) * df_fi['Variación Precio'].fillna(0)),\n",
    "                                                      'Nominal': '', 'Fecha Compra': '', 'Precio compra': '','Precio Actual': '',\n",
    "                                                      'Intereses recibidos': df_fi['Intereses recibidos'].fillna(0).sum(),\n",
    "                                                      'Valor Actual': df_fi['Valor Actual'].fillna(0).sum()}, index = [0]), ignore_index=True)\n",
    "\n",
    "            df_fi = df_fi[['Clasificación', 'Rating', 'País', 'security', 'Título', 'Divisa', 'Cupón', 'Vencimiento', 'Retorno Obtenido', '% Total Cartera', 'Variación Precio', 'Nominal',\n",
    "                           'Fecha Compra', 'Precio compra', 'Precio Actual', 'Intereses recibidos', 'Valor Actual']]    \n",
    "\n",
    "        if len(aux_agg_global_data_mat.loc[aux_agg_global_data_mat['Clasificación'].isin(['Acciones', 'Fondos RV', 'ETFs RV'])]) > 0:\n",
    "            df_eq = aux_agg_global_data_mat.loc[aux_agg_global_data_mat['Clasificación'].isin(['Acciones', 'Fondos RV', 'ETFs RV'])][['Clasificación', 'security', 'Título', 'Divisa',\n",
    "                                                                                                                                      'Retorno Obtenido', '% Total Cartera',\n",
    "                                                                                                                                      'Variación Precio', 'Nominal', 'Fecha Compra',\n",
    "                                                                                                                                      'Precio compra', 'Precio Actual',\n",
    "                                                                                                                                      'Dividendos+Intereses', 'Valor Actual', 'Valor de Compra',\n",
    "                                                                                                                                      'Dividend yield fecha compra', 'Precio compra Report']]\n",
    "            \n",
    "            df_eq = df_eq.rename(columns = {'Dividendos+Intereses': 'Dividendos recibidos'})\n",
    "\n",
    "#             df_eq['Dividend yield fecha compra'] = (df_eq['Dividendos recibidos'] / df_eq['Nominal']) / (df_eq['Precio compra Report']) \n",
    "            df_eq = df_eq.drop(['Precio compra Report'], axis=1)\n",
    "            df_eq = df_eq.sort_values(by=['% Total Cartera'], ascending=False)\n",
    "\n",
    "            #Añadir filas en blanco para cuadrar la lonitud de la matriz con el formato del Excel        \n",
    "            aux_len = 47 - len(df_eq)\n",
    "\n",
    "            if aux_len>0:\n",
    "                null_list = [np.nan]*(aux_len)                   \n",
    "                df_eq = df_eq.append(pd.DataFrame(data = {'Clasificación': null_list, 'security': null_list, 'Título': null_list, 'Divisa': null_list,\n",
    "                                                          'Retorno Obtenido': null_list, '% Total Cartera': null_list, 'Variación Precio': null_list,\n",
    "                                                          'Nominal': null_list, 'Fecha Compra': null_list, 'Precio compra': null_list, 'Precio Actual': null_list,\n",
    "                                                          'Dividendos recibidos': null_list, 'Valor Actual': null_list, 'Dividend yield fecha compra': null_list}), ignore_index=True)        \n",
    "\n",
    "            #Añadir la última fila con totales\n",
    "            df_eq = df_eq.append(pd.DataFrame(data = {'Clasificación': 'SUMA / MEDIA ', 'security': '', 'Título': '', 'Divisa': '',\n",
    "                                                      'Retorno Obtenido': sum((df_eq['Valor de Compra'].fillna(0)/df_eq['Valor de Compra'].fillna(0).sum()) * df_eq['Retorno Obtenido'].fillna(0)),\n",
    "                                                      '% Total Cartera': df_eq['% Total Cartera'].fillna(0).sum(),\n",
    "                                                      'Variación Precio': sum((df_eq['Valor Actual'].fillna(0)/df_eq['Valor Actual'].fillna(0).sum()) * df_eq['Variación Precio'].fillna(0)),\n",
    "                                                      'Nominal': '', 'Fecha Compra': '', 'Precio compra': '','Precio Actual': '',\n",
    "                                                      'Dividendos recibidos': df_eq['Dividendos recibidos'].fillna(0).sum(), 'Valor Actual': df_eq['Valor Actual'].fillna(0).sum(),\n",
    "                                                      'Dividend yield fecha compra': sum((df_eq['Valor Actual'].fillna(0)/df_eq['Valor de Compra'].fillna(0).sum()) * df_eq['Dividend yield fecha compra'].fillna(0))}, index = [0]), ignore_index=True)\n",
    "\n",
    "            df_eq = df_eq[['Clasificación', 'security', 'Título', 'Divisa', 'Retorno Obtenido', '% Total Cartera', 'Variación Precio', 'Nominal', 'Fecha Compra', 'Precio compra', 'Precio Actual', 'Dividendos recibidos',\n",
    "                           'Valor Actual', 'Dividend yield fecha compra']]\n",
    "\n",
    "        if len(aux_agg_global_data_mat.loc[aux_agg_global_data_mat['Clasificación'].isin(['CASH'])]) > 0:\n",
    "            # CASH - Currencies \n",
    "            df_cash = aux_agg_global_data_mat.loc[aux_agg_global_data_mat['Clasificación'].isin(['CASH'])]\n",
    "            df_cash = df_cash[['Clasificación', 'Título', 'Divisa','Retorno Obtenido', '% Total Cartera', 'Valor Actual','Valor de Compra']]\n",
    "            df_cash = df_cash.sort_values(by=['% Total Cartera'], ascending=False)\n",
    "\n",
    "            #Añadir filas en blanco para cuadrar la lonitud de la matriz con el formato del Excel    \n",
    "            aux_len = 7 - len(df_cash)\n",
    "\n",
    "            if aux_len>0:\n",
    "                null_list = [np.nan]*(aux_len)        \n",
    "                df_cash = df_cash.append(pd.DataFrame(data = {'Clasificación': null_list, 'Título': null_list, 'Divisa': null_list, 'Retorno Obtenido': null_list, '% Total Cartera': null_list, 'Valor Actual': null_list}), ignore_index=True)\n",
    "\n",
    "            #Añadir la última fila con totales                \n",
    "            df_cash = df_cash.append(pd.DataFrame(data = {'Clasificación': 'SUMA / MEDIA ', 'Título': '', 'Divisa': '', \n",
    "                                                          'Retorno Obtenido': sum((df_cash['Valor de Compra'].fillna(0)/df_cash['Valor de Compra'].fillna(0).sum()) * df_cash['Retorno Obtenido'].fillna(0)),\n",
    "                                                          '% Total Cartera': df_cash['% Total Cartera'].fillna(0).sum(), \n",
    "                                                          'Valor Actual': df_cash['Valor Actual'].fillna(0).sum()}, index = [0]), ignore_index=True)    \n",
    "\n",
    "            df_cash = df_cash[['Clasificación', 'Título', 'Divisa', 'Retorno Obtenido', '% Total Cartera', 'Valor Actual']]\n",
    "            \n",
    "            \n",
    "        if len(aux_agg_global_data_mat.loc[aux_agg_global_data_mat['Clasificación'].isin(['Tesoros'])]) > 0: \n",
    "            # CASH - Treasuries\n",
    "            df_treasuries = aux_agg_global_data_mat.loc[aux_agg_global_data_mat['Clasificación'].isin(['Tesoros'])]\n",
    "            df_treasuries = df_treasuries[['Clasificación', 'Rating', 'País', 'Título','Divisa', 'Cupón', 'Vencimiento', 'Retorno Obtenido','% Total Cartera', 'Variación Precio', 'Nominal','Fecha Compra',\n",
    "                                           'Precio compra', 'Precio Actual','Dividendos+Intereses', 'Valor Actual','Valor de Compra']]\n",
    "            df_treasuries = df_treasuries.rename(columns = {'Dividendos+Intereses': 'Intereses recibidos'})\n",
    "\n",
    "            #Calcular Rating medio\n",
    "            try: \n",
    "                aux_rating = aux_agg_global_data_mat.loc[aux_agg_global_data_mat['Clasificación'].isin(['Tesoros']), ['Rating', 'Valor Actual']]\n",
    "                \n",
    "                list_rtg = aux_rating['Rating'].tolist()\n",
    "                aux_list_rtg = []\n",
    "                for i_rtg in list_rtg:\n",
    "                    aix_i = i_rtg.split(' *')\n",
    "                    aux_list_rtg += [aix_i[0]]\n",
    "                list_rtg = aux_list_rtg    \n",
    "                aux_list_rtg = []\n",
    "                for i_rtg in list_rtg:\n",
    "                    aix_i = i_rtg.split('u')\n",
    "                    aux_list_rtg += [aix_i[0]]\n",
    "\n",
    "                aux_rating['Clean_RTG'] = aux_list_rtg                   \n",
    "                \n",
    "                #Generar un diccionario con el rating y su valor correspondiente y otro diccionario que sea el inverso de este\n",
    "                rating_valor = {'AAA': 21, 'AA+': 20, 'AA': 19, 'AA-': 18, 'A+': 17, 'A': 16, 'A-': 15,\n",
    "                                'BBB+': 14, 'BBB': 13, 'BBB-': 12, 'BB+': 11, 'BB': 10, 'BB-': 9, 'B+': 8, 'B': 7, 'B-': 6,\n",
    "                                'CCC+': 5, 'CCC': 4, 'CCC-': 3, 'CC': 2, 'C': 1, 'D': 0}\n",
    "                valor_rating = {'21': 'AAA', '20': 'AA+', '19': 'AA', '18': 'AA-', '17': 'A+', '16': 'A', '15': 'A-',\n",
    "                                '14': 'BBB+', '13': 'BBB', '12': 'BBB-', '11': 'BB+', '10': 'BB', '9': 'BB-', '8': 'B+', '7': 'B', '6': 'B-',\n",
    "                                '5': 'CCC+', '4': 'CCC', '3': 'CCC-', '2': 'CC', '1': 'C', '0': 'D'}    \n",
    "\n",
    "                #Asignar el número de rating a cada bono\n",
    "                aux_rating['Numero_Rating'] = aux_rating['Clean_RTG'].map(rating_valor).fillna(0)     \n",
    "                rating_medio = valor_rating[str(int(np.round(sum((aux_rating['Valor Actual']/aux_rating['Valor Actual'].sum()) * aux_rating['Numero_Rating']), 0)))]\n",
    "\n",
    "            except:\n",
    "                rating_medio = np.nan\n",
    "\n",
    "            df_treasuries = df_treasuries.sort_values(by=['% Total Cartera'], ascending=False)\n",
    "\n",
    "            #Añadir filas en blanco para cuadrar la lonitud de la matriz con el formato del Excel\n",
    "            aux_len = 7 - len(df_treasuries)\n",
    "\n",
    "            if aux_len>0:\n",
    "                null_list = [np.nan]*(aux_len)        \n",
    "                df_treasuries = df_treasuries.append(pd.DataFrame(data = {'Clasificación': null_list, 'Rating': null_list, 'País': null_list, 'Título': null_list, 'Divisa': null_list, 'Cupón': null_list, 'Vencimiento': null_list,\n",
    "                                                              'Retorno Obtenido': null_list, '% Total Cartera': null_list, 'Variación Precio': null_list, 'Nominal': null_list, 'Fecha Compra': null_list, 'Precio compra': null_list,\n",
    "                                                              'Precio Actual': null_list, 'Intereses recibidos': null_list, 'Valor Actual': null_list}), ignore_index=True)        \n",
    "\n",
    "            #Añadir la última fila con totales                \n",
    "            df_treasuries = df_treasuries.append(pd.DataFrame(data = {'Clasificación': 'SUMA / MEDIA ', 'Rating': rating_medio, 'País': '', 'Título': '', 'Divisa': '',\n",
    "                                                                      'Cupón': sum((df_treasuries['Valor Actual'].fillna(0)/df_treasuries['Valor Actual'].fillna(0).sum()) * df_treasuries['Cupón']), 'Vencimiento': '',\n",
    "                                                                      'Retorno Obtenido': sum((df_treasuries['Valor de Compra'].fillna(0)/df_treasuries['Valor de Compra'].fillna(0).sum()) * df_treasuries['Retorno Obtenido'].fillna(0)),\n",
    "                                                                      '% Total Cartera': df_treasuries['% Total Cartera'].fillna(0).sum(),\n",
    "                                                                      'Variación Precio': sum((df_treasuries['Valor Actual'].fillna(0)/df_treasuries['Valor Actual'].fillna(0).sum()) * df_treasuries['Variación Precio'].fillna(0)),\n",
    "                                                                      'Nominal': '', 'Fecha Compra': '', 'Precio compra': '','Precio Actual': '',\n",
    "                                                                      'Intereses recibidos': df_treasuries['Intereses recibidos'].fillna(0).sum(),\n",
    "                                                                      'Valor Actual': df_treasuries['Valor Actual'].fillna(0).sum()}, index = [0]), ignore_index=True)        \n",
    "\n",
    "            df_treasuries = df_treasuries[['Clasificación', 'Rating', 'País', 'Título', 'Divisa', 'Cupón', 'Vencimiento', 'Retorno Obtenido', '% Total Cartera', 'Variación Precio', 'Nominal', 'Fecha Compra',\n",
    "                                           'Precio compra', 'Precio Actual', 'Intereses recibidos', 'Valor Actual']]    \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "        if len(aux_agg_global_data_mat[aux_agg_global_data_mat.Maturity_Band_Focus == 'Ultra Short']) > 0:\n",
    "             # CASH - Otros\n",
    "            df_cash_otros = aux_agg_global_data_mat[aux_agg_global_data_mat.Maturity_Band_Focus == 'Ultra Short']\n",
    "            df_cash_otros = df_cash_otros[['Clasificación', 'Rating', 'País', 'Título','Divisa', 'Cupón', 'Vencimiento', 'Retorno Obtenido','% Total Cartera', 'Variación Precio', 'Nominal','Fecha Compra',\n",
    "                                           'Precio compra', 'Precio Actual','Dividendos+Intereses', 'Valor Actual','Valor de Compra']]\n",
    "            df_cash_otros = df_cash_otros.rename(columns = {'Dividendos+Intereses': 'Intereses recibidos'})\n",
    "            #Calcular Rating medio\n",
    "            try: \n",
    "                aux_rating = aux_agg_global_data_mat.loc[aux_agg_global_data_mat['Maturity_Band_Focus'].isin(['Ultra Short']), ['Rating', 'Valor Actual']]\n",
    "                \n",
    "                list_rtg = aux_rating['Rating'].tolist()\n",
    "                aux_list_rtg = []\n",
    "                for i_rtg in list_rtg:\n",
    "                    aix_i = i_rtg.split(' *')\n",
    "                    aux_list_rtg += [aix_i[0]]\n",
    "                list_rtg = aux_list_rtg    \n",
    "                aux_list_rtg = []\n",
    "                for i_rtg in list_rtg:\n",
    "                    aix_i = i_rtg.split('u')\n",
    "                    aux_list_rtg += [aix_i[0]]\n",
    "\n",
    "                aux_rating['Clean_RTG'] = aux_list_rtg                   \n",
    "                \n",
    "                #Generar un diccionario con el rating y su valor correspondiente y otro diccionario que sea el inverso de este\n",
    "                rating_valor = {'AAA': 21, 'AA+': 20, 'AA': 19, 'AA-': 18, 'A+': 17, 'A': 16, 'A-': 15,\n",
    "                                'BBB+': 14, 'BBB': 13, 'BBB-': 12, 'BB+': 11, 'BB': 10, 'BB-': 9, 'B+': 8, 'B': 7, 'B-': 6,\n",
    "                                'CCC+': 5, 'CCC': 4, 'CCC-': 3, 'CC': 2, 'C': 1, 'D': 0}\n",
    "                valor_rating = {'21': 'AAA', '20': 'AA+', '19': 'AA', '18': 'AA-', '17': 'A+', '16': 'A', '15': 'A-',\n",
    "                                '14': 'BBB+', '13': 'BBB', '12': 'BBB-', '11': 'BB+', '10': 'BB', '9': 'BB-', '8': 'B+', '7': 'B', '6': 'B-',\n",
    "                                '5': 'CCC+', '4': 'CCC', '3': 'CCC-', '2': 'CC', '1': 'C', '0': 'D'}    \n",
    "\n",
    "                #Asignar el número de rating a cada bono\n",
    "                aux_rating['Numero_Rating'] = aux_rating['Clean_RTG'].map(rating_valor).fillna(0)     \n",
    "                rating_medio = valor_rating[str(int(np.round(sum((aux_rating['Valor Actual']/aux_rating['Valor Actual'].sum()) * aux_rating['Numero_Rating']), 0)))]\n",
    "\n",
    "            except:\n",
    "                rating_medio = np.nan\n",
    "\n",
    "            df_cash_otros = df_cash_otros.sort_values(by=['% Total Cartera'], ascending=False)\n",
    "\n",
    "            #Añadir filas en blanco para cuadrar la lonitud de la matriz con el formato del Excel\n",
    "            aux_len = 7 - len(df_cash_otros)\n",
    "\n",
    "            if aux_len>0:\n",
    "                null_list = [np.nan]*(aux_len)        \n",
    "                df_cash_otros = df_cash_otros.append(pd.DataFrame(data = {'Clasificación': null_list, 'Rating': null_list, 'País': null_list, 'Título': null_list, 'Divisa': null_list, 'Cupón': null_list, 'Vencimiento': null_list,\n",
    "                                                              'Retorno Obtenido': null_list, '% Total Cartera': null_list, 'Variación Precio': null_list, 'Nominal': null_list, 'Fecha Compra': null_list, 'Precio compra': null_list,\n",
    "                                                              'Precio Actual': null_list, 'Intereses recibidos': null_list, 'Valor Actual': null_list}), ignore_index=True)        \n",
    "\n",
    "            #Añadir la última fila con totales                \n",
    "            df_cash_otros = df_cash_otros.append(pd.DataFrame(data = {'Clasificación': 'SUMA / MEDIA ', 'Rating': rating_medio, 'País': '', 'Título': '', 'Divisa': '',\n",
    "                                                                      'Cupón': sum((df_cash_otros['Valor Actual'].fillna(0)/df_cash_otros['Valor Actual'].fillna(0).sum()) * df_cash_otros['Cupón']), 'Vencimiento': '',\n",
    "                                                                      'Retorno Obtenido': sum((df_cash_otros['Valor de Compra'].fillna(0)/df_cash_otros['Valor de Compra'].fillna(0).sum()) * df_cash_otros['Retorno Obtenido'].fillna(0)),\n",
    "                                                                      '% Total Cartera': df_cash_otros['% Total Cartera'].fillna(0).sum(),\n",
    "                                                                      'Variación Precio': sum((df_cash_otros['Valor Actual'].fillna(0)/df_cash_otros['Valor Actual'].fillna(0).sum()) * df_cash_otros['Variación Precio'].fillna(0)),\n",
    "                                                                      'Nominal': '', 'Fecha Compra': '', 'Precio compra': '','Precio Actual': '',\n",
    "                                                                      'Intereses recibidos': df_cash_otros['Intereses recibidos'].fillna(0).sum(),\n",
    "                                                                      'Valor Actual': df_cash_otros['Valor Actual'].fillna(0).sum()}, index = [0]), ignore_index=True)        \n",
    "\n",
    "            df_cash_otros = df_cash_otros[['Clasificación', 'Rating', 'País', 'Título', 'Divisa', 'Cupón', 'Vencimiento', 'Retorno Obtenido', '% Total Cartera', 'Variación Precio', 'Nominal', 'Fecha Compra',\n",
    "                                           'Precio compra', 'Precio Actual', 'Intereses recibidos', 'Valor Actual']]                \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        if len(aux_agg_global_data_mat.loc[aux_agg_global_data_mat['Clasificación'].isin(['Otros'])]) > 0:    \n",
    "            df_otros = aux_agg_global_data_mat.loc[aux_agg_global_data_mat['Clasificación'].isin(['Otros'])][['Clasificación', 'Rating', 'País', 'Título',\n",
    "                                                                                                              'Divisa', 'Cupón', 'Vencimiento', 'Retorno Obtenido',\n",
    "                                                                                                              '% Total Cartera', 'Variación Precio', 'Nominal',\n",
    "                                                                                                              'Fecha Compra', 'Precio compra', 'Precio Actual',\n",
    "                                                                                                              'Dividendos+Intereses', 'Valor Actual','Valor de Compra']]\n",
    "            \n",
    "            df_otros = df_otros.rename(columns = {'Dividendos+Intereses': 'Intereses recibidos'})\n",
    "\n",
    "            #Calcular Rating medio\n",
    "            try: \n",
    "                aux_rating = aux_agg_global_data_mat.loc[aux_agg_global_data_mat['Clasificación'].isin(['Otros']), ['Rating', 'Valor Actual']]\n",
    "                \n",
    "                list_rtg = aux_rating['Rating'].tolist()\n",
    "                aux_list_rtg = []\n",
    "                for i_rtg in list_rtg:\n",
    "                    aix_i = i_rtg.split(' *')\n",
    "                    aux_list_rtg += [aix_i[0]]\n",
    "                list_rtg = aux_list_rtg    \n",
    "                aux_list_rtg = []\n",
    "                for i_rtg in list_rtg:\n",
    "                    aix_i = i_rtg.split('u')\n",
    "                    aux_list_rtg += [aix_i[0]]\n",
    "\n",
    "                aux_rating['Clean_RTG'] = aux_list_rtg                   \n",
    "                \n",
    "                #Generar un diccionario con el rating y su valor correspondiente y otro diccionario que sea el inverso de este\n",
    "                rating_valor = {'AAA': 21, 'AA+': 20, 'AA': 19, 'AA-': 18, 'A+': 17, 'A': 16, 'A-': 15,\n",
    "                                'BBB+': 14, 'BBB': 13, 'BBB-': 12, 'BB+': 11, 'BB': 10, 'BB-': 9, 'B+': 8, 'B': 7, 'B-': 6,\n",
    "                                'CCC+': 5, 'CCC': 4, 'CCC-': 3, 'CC': 2, 'C': 1, 'D': 0}\n",
    "                valor_rating = {'21': 'AAA', '20': 'AA+', '19': 'AA', '18': 'AA-', '17': 'A+', '16': 'A', '15': 'A-',\n",
    "                                '14': 'BBB+', '13': 'BBB', '12': 'BBB-', '11': 'BB+', '10': 'BB', '9': 'BB-', '8': 'B+', '7': 'B', '6': 'B-',\n",
    "                                '5': 'CCC+', '4': 'CCC', '3': 'CCC-', '2': 'CC', '1': 'C', '0': 'D'}    \n",
    "\n",
    "                #Asignar el número de rating a cada bono\n",
    "                aux_rating['Numero_Rating'] = aux_rating['Clean_RTG'].map(rating_valor).fillna(0)     \n",
    "                rating_medio = valor_rating[str(int(np.round(sum((aux_rating['Valor Actual']/aux_rating['Valor Actual'].sum()) * aux_rating['Numero_Rating']), 0)))]\n",
    "\n",
    "            except:\n",
    "                rating_medio = np.nan\n",
    "\n",
    "            df_otros = df_otros.sort_values(by=['% Total Cartera'], ascending=False)\n",
    "\n",
    "            #Añadir filas en blanco para cuadrar la lonitud de la matriz con el formato del Excel\n",
    "            aux_len = 7 - len(df_otros)\n",
    "\n",
    "            if aux_len>0:\n",
    "                null_list = [np.nan]*(aux_len)        \n",
    "                df_otros = df_otros.append(pd.DataFrame(data = {'Clasificación': null_list, 'Rating': null_list, 'País': null_list, 'Título': null_list, 'Divisa': null_list, 'Cupón': null_list, 'Vencimiento': null_list,\n",
    "                                                              'Retorno Obtenido': null_list, '% Total Cartera': null_list, 'Variación Precio': null_list, 'Nominal': null_list, 'Fecha Compra': null_list, 'Precio compra': null_list,\n",
    "                                                              'Precio Actual': null_list, 'Intereses recibidos': null_list, 'Valor Actual': null_list}), ignore_index=True)        \n",
    "\n",
    "            #Añadir la última fila con totales                \n",
    "            df_otros = df_otros.append(pd.DataFrame(data = {'Clasificación': 'SUMA / MEDIA ', 'Rating': rating_medio, 'País': '', 'Título': '', 'Divisa': '',\n",
    "                                                            'Cupón': sum((df_otros['Valor Actual'].fillna(0)/df_otros['Valor Actual'].fillna(0).sum()) * df_otros['Cupón']),'Vencimiento': '',\n",
    "                                                            'Retorno Obtenido': sum((df_otros['Valor de Compra'].fillna(0)/df_otros['Valor de Compra'].fillna(0).sum()) * df_otros['Retorno Obtenido'].fillna(0)),\n",
    "                                                            '% Total Cartera': df_otros['% Total Cartera'].fillna(0).sum(),\n",
    "                                                            'Variación Precio': sum((df_otros['Valor Actual'].fillna(0)/df_otros['Valor Actual'].fillna(0).sum()) * df_otros['Variación Precio'].fillna(0)),\n",
    "                                                            'Nominal': '', 'Fecha Compra': '', 'Precio compra': '','Precio Actual': '',\n",
    "                                                            'Intereses recibidos': df_otros['Intereses recibidos'].fillna(0).sum(), 'Valor Actual': df_otros['Valor Actual'].fillna(0).sum()}, index = [0]), ignore_index=True)        \n",
    "\n",
    "            df_otros = df_otros[['Clasificación', 'Rating', 'País', 'Título', 'Divisa', 'Cupón', 'Vencimiento', 'Retorno Obtenido', '% Total Cartera', 'Variación Precio', 'Nominal', 'Fecha Compra', 'Precio compra', 'Precio Actual',\n",
    "                                 'Intereses recibidos', 'Valor Actual']]       \n",
    "\n",
    "\n",
    "        #Se genera una copia del nuevo One Pager para el banco correspondiente\n",
    "        new_bank_name = shutil.copy('SOPORTE_ONE_PAGER.xlsx', 'SOP_ONE_P_' + i_bank + '.xlsx')\n",
    "\n",
    "        #Se carga el Excel nuevo\n",
    "\n",
    "        book = load_workbook(new_bank_name)\n",
    "        writer = pd.ExcelWriter(new_bank_name, engine='openpyxl') \n",
    "        writer.book = book\n",
    "        writer.sheets = dict((ws.title, ws) for ws in book.worksheets)\n",
    "\n",
    "        # Sobreescribir las pestañas soporte del Excel\n",
    "        df_fi.to_excel(writer, sheet_name='Renta Fija', index=False, header=False, startrow=3)\n",
    "        df_eq.to_excel(writer, sheet_name='Renta Variable', index=False, header=False, startrow=3)\n",
    "        df_cash.to_excel(writer, sheet_name='Liquidez', index=False, header=False, startrow=3)\n",
    "        df_treasuries.to_excel(writer, sheet_name='Liquidez', index=False, header=False, startrow=15)\n",
    "        df_cash_otros.to_excel(writer, sheet_name='Liquidez', index=False, header=False, startrow=27)\n",
    "#        df_otros.to_excel(writer, sheet_name='Liquidez', index=False, header=False, startrow=27)\n",
    "        \n",
    "        try:\n",
    "            var_exist_test = tot_div - 1\n",
    "        except:\n",
    "            tot_div = 0\n",
    "\n",
    "        try:\n",
    "            var_exist_test = tot_cup - 1\n",
    "        except:\n",
    "            tot_cup = 0        \n",
    "        \n",
    "        aux_tot_div = pd.DataFrame({'Tot_Dividendos':[tot_div]})\n",
    "        aux_tot_cup = pd.DataFrame({'Tot_Cupones':[tot_cup]})\n",
    "\n",
    "        aux_tot_div.to_excel(writer, sheet_name='Tot_DivyCup')\n",
    "        aux_tot_cup.to_excel(writer, sheet_name='Tot_DivyCup', startcol=5)\n",
    "\n",
    "        writer.save()  \n",
    "    \n",
    "    print_message_box.value = 'ONE PAGER GENERADO EN: ' + str(os.getcwd()) + '\\SOP_OP_XXX NOMBRE BANCO XXXX.xlsx '  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "812e6fe928914dbaafc475bc07f97abf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Label(value='', layout=Layout(width='200px')), VBox(children=(Label(value='$CARG…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "######## Please wait message\n",
    "\n",
    "wait_msg = HTML(\"\"\"<h2 style=\"color:white;\">Calculando .....</h>\n",
    "    <i class=\"fa fa-spinner fa-spin fa-2x fa-fw\" style=\"color:white;\"></i>\"\"\")\n",
    "wait_msg.layout.height = '1px'\n",
    "wait_msg.layout.visibility = 'hidden'\n",
    "wait_msg.layout.margin = '20px 10px 10px 10px'\n",
    "\n",
    "############################\n",
    "\n",
    "############# MAIN GUI ##############\n",
    "\n",
    "#Generar espacios entre distintos widgets\n",
    "aux_H_label = Label(value='') #Espacio horizontal\n",
    "aux_H_label.layout.width = '30px'\n",
    "\n",
    "aux_first_H_label = Label(value='') #Primer Espacio horizontal tipo sangría\n",
    "aux_first_H_label.layout.width = '200px'\n",
    "\n",
    "aux_V_label = Label(value='') #Espacio Vertical\n",
    "aux_V_label.layout.height = '30px'\n",
    "\n",
    "#FILA 1 COLUMNA 1\n",
    "\n",
    "header_row1 = Label(value='$CARGA$ $INICIAL$ $DE$ $CARTERAS$')\n",
    "header_row1.layout.width = '300px'\n",
    "\n",
    "#Carga de portfolios en PRTU <GO>\n",
    "port_list = bqport.list_portfolios()\n",
    "port_name = []\n",
    "\n",
    "for port_id in port_list:\n",
    "\n",
    "    port_name.append(port_id['name'])\n",
    "\n",
    "port = SelectMultiple(options = [])    \n",
    "port = SelectMultiple(options = sorted(port_name))\n",
    "port.layout.height = '300px'\n",
    "\n",
    "#Agrupación de widgets de la FILA 1\n",
    "row1 = HBox([aux_first_H_label, VBox([header_row1, port]), Box([wait_msg])])\n",
    "\n",
    "#FILA 2\n",
    "header_row2 = Label(value='$PARAMETRIZACIÓN$ $DEL$ $INFORME$')\n",
    "header_row2.layout.width = '320px'\n",
    "\n",
    "header_row2_1 = Label(value='DATOS DE ENTRADA')\n",
    "header_row2_1.layout.width = '300px'\n",
    "\n",
    "label_st = Label(value='Fecha Inicio')\n",
    "label_st.layout.width = '100px'\n",
    "date_st = DatePicker(date_format = '%d-%m-%Y')\n",
    "date_st.layout.width = '200px'\n",
    "\n",
    "\n",
    "label_end = Label(value='Fecha Fin')\n",
    "label_end.layout.width = '80px'\n",
    "date_end = DatePicker(date_format = '%d-%m-%Y')\n",
    "date_end.layout.width = '200px'\n",
    "\n",
    "date_end.value = datetime.datetime.today().strftime('%d-%m-%Y')\n",
    "date_st.value = datetime.datetime(datetime.datetime.today().year - 1, 12, 31).strftime('%d-%m-%Y')\n",
    "\n",
    "#Buscador de monedas\n",
    "label_ac_curncy = Label(value='Moneda')\n",
    "label_ac_curncy.layout.width = '60px'\n",
    "ac_curncy = AutoComplete(value = 'USD', data = ['AED', 'AFN', 'ALL', 'AMD', 'ANG', 'AOA', 'ARS', 'ATS', 'AUD', 'AUd', 'AWG', 'AZM', 'AZN', 'BAM', 'BBD', 'BDT', 'BEF', 'BGN',\n",
    "                                         'BHD', 'BIF', 'BMD', 'BND', 'BOB','BRL', 'BRl', 'BSD','BTN', 'BWP', 'BWp', 'BYR', 'BZD', 'CAD', 'CAd', 'CDF', 'CHF', 'CHf', 'CLF',\n",
    "                                         'CLP', 'CNH', 'CNY', 'COP', 'CRC', 'CSD', 'CUP', 'CVE', 'CYP', 'CZK', 'DEM', 'DJF', 'DKK', 'DOP', 'DZD', 'ECS', 'EEK', 'EGP',\n",
    "                                         'ERN', 'ESP', 'ETB', 'EUA', 'EUR', 'EUr', 'FIM', 'FJD', 'FKP', 'FRF', 'GBP', 'GBp', 'GEL', 'GHC', 'GHS', 'GIP', 'GMD', 'GNF',\n",
    "                                         'GRD', 'GTQ', 'GYD', 'HKD', 'HNL', 'HRK', 'HTG', 'HUF', 'IDR', 'IEP', 'IEp', 'ILS', 'ILs', 'IMP', 'INR', 'IQD', 'IRR', 'ISK',\n",
    "                                         'ITL', 'JMD', 'JOD', 'JPY', 'KES', 'KGS', 'KHR', 'KMF', 'KPW', 'KRW', 'KWD', 'KWd', 'KYD', 'KZT', 'LAK', 'LBP', 'LKR', 'LRD',\n",
    "                                         'LSL', 'LTL', 'LUF', 'LVL', 'LYD', 'MAD', 'MDL', 'MGA', 'MGF', 'MKD', 'MMK', 'MNT', 'MOP', 'MRO', 'MTL', 'MUR', 'MVR', 'MWK',\n",
    "                                         'MWk', 'MXN', 'MYR', 'MYr', 'MZM', 'MZN', 'NAD', 'NAd', 'NGN', 'NIO', 'NLG', 'NOK', 'NPR', 'NZD', 'OMR', 'PAB', 'PEN', 'PGK',\n",
    "                                         'PHP', 'PKR', 'PLN', 'PTE', 'PYG', 'QAR', 'ROL', 'RON', 'RSD', 'RUB', 'RWF', 'SAR', 'SBD', 'SCR', 'SDG', 'SEK', 'SGD', 'SGd',\n",
    "                                         'SIT', 'SKK', 'SLL', 'SOS', 'SPL', 'SRG', 'SSP', 'STD', 'SVC', 'SYP', 'SZL', 'SZl', 'THB', 'THO', 'TJS', 'TMM', 'TND', 'TOP',\n",
    "                                         'TRL', 'TRY', 'TTD', 'TWD', 'TZS', 'UAH', 'UDI', 'UGX', 'USD', 'USd', 'UYI', 'UYU', 'UZS', 'VEB', 'VEF', 'VND', 'VUV', 'WST',\n",
    "                                         'XAF', 'XAU', 'XCD', 'XDR', 'XEU', 'XOF', 'XPF', 'YER', 'ZAR', 'ZAr', 'ZMK', 'ZMW', 'ZMk', 'ZWD', 'ZWR', 'ZWd'])\n",
    "ac_curncy.layout.width = '150px'\n",
    "\n",
    "\n",
    "#Botón para aplicar parámetros introducidos\n",
    "request_button2 = Button(description = 'CARGAR', button_style = 'warning')\n",
    "request_button2.on_click(download_main_data)\n",
    "request_button2.layout.width = '150px'\n",
    "\n",
    "#Agrupación de widgets de la FILA 1\n",
    "date_st_widget = HBox([label_st, date_st])\n",
    "date_end_widget = HBox([label_end, date_end])\n",
    "curncy_widget = HBox([label_ac_curncy, ac_curncy])\n",
    "row2 = HBox([aux_first_H_label, VBox([header_row2, aux_V_label, header_row2_1, HBox([date_st_widget, date_end_widget, curncy_widget, request_button2])])])\n",
    "\n",
    "#FILA 3\n",
    "\n",
    "header_row3 = Label(value='INCLUIR PATRIMONIO CARTERAS MANEJADAS')\n",
    "header_row3.layout.width = '350px'\n",
    "\n",
    "label_port_patri = Label(value='Cartera Manejada')\n",
    "label_port_patri.layout.width = '120px'\n",
    "port_patri = AutoComplete(data=[])\n",
    "port_patri.layout.width = '200px'\n",
    "\n",
    "label_patri_st_date = Label(value='Patrimonio FI')\n",
    "label_patri_st_date.layout.width = '100px'\n",
    "patri_st_date = Text(value='')\n",
    "patri_st_date.layout.width = '150px'\n",
    "\n",
    "label_patri_end_date = Label(value='Patrimonio FF')\n",
    "label_patri_end_date.layout.width = '100px'\n",
    "patri_end_date = Text(value='')\n",
    "patri_end_date.layout.width = '150px'\n",
    "\n",
    "#Botón para añadir carteras manejadas\n",
    "request_button3 = Button(description = 'AGREGAR', button_style = 'warning')\n",
    "request_button3.on_click(gen_carteras_manejadas)\n",
    "request_button3.layout.width = '120px'\n",
    "\n",
    "#Agrupación de widgets de la FILA 3\n",
    "row3 = HBox([aux_first_H_label, VBox([header_row3, HBox([label_port_patri, port_patri, label_patri_st_date, patri_st_date, label_patri_end_date, patri_end_date, request_button3])])])\n",
    "\n",
    "#FILA 4\n",
    "\n",
    "header_row4 = Label(value='INCLUIR DEPÓSITOS Y RETIROS NETOS')\n",
    "header_row4.layout.width = '350px'\n",
    "\n",
    "label_port_patri = Label(value='Cartera')\n",
    "label_port_patri.layout.width = '120px'\n",
    "\n",
    "port_depo_ret = Dropdown(options=[])\n",
    "port_depo_ret.layout.width = '200px'\n",
    "\n",
    "depo_ret = Text(value='')\n",
    "\n",
    "#Botón para añadir info depósitos/retiros\n",
    "request_button4 = Button(description = 'AGREGAR', button_style = 'warning')\n",
    "request_button4.on_click(generate_dep_ret)\n",
    "request_button4.layout.width = '334px'\n",
    "\n",
    "#Agrupación de widgets de la FILA 4\n",
    "row4 = HBox([aux_first_H_label, VBox([header_row4, HBox([label_port_patri, port_depo_ret, depo_ret, request_button4])])])\n",
    "\n",
    "#FILA 5\n",
    "\n",
    "header_row5 = Label(value='$VALIDACION$ $DE$ $DATOS$')\n",
    "header_row5.layout.width = '300px'\n",
    "\n",
    "#Agrupación de widgets de la FILA 5\n",
    "row5 = HBox([aux_first_H_label, VBox([header_row5])])\n",
    "\n",
    "#FILA 6.0\n",
    "read_excel_button = Button(description = 'LEER EXCEL DE PRECIOS', button_style = 'warning')\n",
    "read_excel_button.on_click(Read_Prices_from_Excel)\n",
    "read_excel_button.layout.width = '965px'\n",
    "\n",
    "#FILA 6\n",
    "\n",
    "label_assets_class = Label(value='Clasificación Tipo Activo')\n",
    "label_assets_class.layout.width = '150px'\n",
    "\n",
    "assets_class = Dropdown(options=[])\n",
    "assets_class.observe(gen_excel_type_table, names = 'value')\n",
    "assets_class.layout.width = '200px'\n",
    "\n",
    "output_number_assets_class = Text(value='', disabled = True) #Esta ventana de texto es para mostrar el número de activos que hay de cada categoría\n",
    "output_number_assets_class.layout.width = '30px'\n",
    "\n",
    "row6 = VBox([HBox([aux_first_H_label, read_excel_button]), aux_V_label, HBox([aux_first_H_label, label_assets_class, assets_class, output_number_assets_class])])\n",
    "\n",
    "#FILA 7\n",
    "\n",
    "#Se va a generar el widget para incluir la tabla vacía\n",
    "tabla_excel = VBox([])\n",
    "\n",
    "#FILA 8\n",
    "\n",
    "#Botón para aplicar las modificaciones de la tabla en la matriz de datos original\n",
    "request_button5 = Button(description = 'APLICAR MODIFICACIONES', button_style = 'danger')\n",
    "request_button5.on_click(apply_changes_excel_type_table)\n",
    "request_button5.layout.width = '965px'\n",
    "\n",
    "#FILA 9\n",
    "\n",
    "#Botón para pasar a la última fase en la que se genere el Excel\n",
    "request_button6 = Button(description = 'DATOS VALIDADOS', button_style = 'success')\n",
    "request_button6.on_click(validate_data)\n",
    "request_button6.layout.width = '965px'\n",
    "\n",
    "#FILA 10 \n",
    "\n",
    "#Botón para descargar datos para la generación del Global Reporting\n",
    "request_button7 = Button(description = 'DESCARGAR GLOBAL REPORTING', button_style = 'info')\n",
    "request_button7.on_click(Global_Reporting_Generation)\n",
    "request_button7.layout.width = '480px'\n",
    "request_button7.layout.height = '50px'\n",
    "\n",
    "#Botón para descargar datos para la generación del One Pager\n",
    "request_button8 = Button(description = 'DESCARGAR ONE PAGER', button_style = 'success')\n",
    "request_button8.on_click(One_Pager_Generation)\n",
    "request_button8.layout.width = '480px'\n",
    "request_button8.layout.height = '50px'\n",
    "\n",
    "#FILA 11\n",
    "\n",
    "#Cuadro donde se imprimirá texto que guíe al usuario, (principalemnte para indicar la tipología de los errores)\n",
    "print_message_box = Text(value='')\n",
    "print_message_box.layout.width = '965px'\n",
    "\n",
    "#####################################\n",
    "\n",
    "#Agrupación de todos los widgets\n",
    "hidden_widgets1 = VBox([row2, aux_V_label]) \n",
    "\n",
    "#Para guiar más al usuario, se ocultan estos widgets que se verán una vez se pulse el botón \"CARGAR\"\n",
    "hidden_widgets2 = VBox([row3, aux_V_label, row4, aux_V_label, row5, aux_V_label, row6, aux_V_label, tabla_excel, aux_V_label, HBox([aux_first_H_label, VBox([request_button5, request_button6])]), aux_V_label])\n",
    "hidden_widgets2.layout.visibility = 'hidden'\n",
    "\n",
    "hidden_widgets3 = HBox([aux_first_H_label, request_button7, request_button8])\n",
    "hidden_widgets3.layout.visibility = 'hidden' \n",
    "\n",
    "main = VBox([row1, aux_V_label, hidden_widgets1, hidden_widgets2, hidden_widgets3, aux_V_label, HBox([aux_first_H_label, print_message_box])])\n",
    "main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_main_data()\n",
    "# Global_Reporting_Generation()\n",
    "# def_mat_cup\n",
    "# global_mat\n",
    "# def_forward_mat_cup\n",
    "# One_Pager_Generation()\n",
    "# def_mat_div\n",
    "# validate_data()\n",
    "# apply_changes_excel_type_table (tgt = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\N360716\\AppData\\Local\\bipy\\28942540\\projects\\d79fa1e593dc4dcc8560a25536e0861a\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (sandboxed)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
