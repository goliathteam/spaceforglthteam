{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coupon_matrix(tgt = None):\n",
    "    global global_mat\n",
    "    global agg_global_data_mat\n",
    "    \n",
    "    global def_mat_cup #Aquí se genera la matriz de cupones para el reporting\n",
    "    global tot_cup\n",
    "    \n",
    "    # Cálculo matriz cupones recibidos\n",
    "\n",
    "    #Se intenta generar un DataFrame como el que devolvía la query de los dividendos recibidos por activo\n",
    "    coupons_df = pd.DataFrame(data={})\n",
    "\n",
    "    aux_coupons_df = global_mat.loc[global_mat['Clasificación'].isin(['Bonos'])][['Banco', 'security', 'Coupon_freq', 'Coupon_nxt_date', 'Cupón', 'Divisa']].drop_duplicates()\n",
    "\n",
    "    start_dt = datetime.datetime.strptime(date_st.value, '%d-%m-%Y')\n",
    "    end_dt = datetime.datetime.strptime(date_end.value, '%d-%m-%Y')\n",
    "\n",
    "    for i_idx in aux_coupons_df.index:\n",
    "        try:\n",
    "            i_sec_nxt_cup = aux_coupons_df.loc[i_idx, 'Coupon_nxt_date'].to_pydatetime()\n",
    "            i_sec_cup = aux_coupons_df.loc[i_idx, 'Cupón']\n",
    "            i_sec_cup_feq = aux_coupons_df.loc[i_idx, 'Coupon_freq']\n",
    "            i_sec_cup = i_sec_cup/i_sec_cup_feq\n",
    "            i_sec_cup_feq = 12/i_sec_cup_feq\n",
    "\n",
    "            list_cup_dates = []\n",
    "            time_count = i_sec_nxt_cup\n",
    "            while start_dt <= time_count:\n",
    "                if time_count <= end_dt:\n",
    "                    list_cup_dates += [time_count]\n",
    "\n",
    "                time_count -= datetime.timedelta(i_sec_cup_feq*365/12)\n",
    "\n",
    "            if len(list_cup_dates) > 0:\n",
    "                i_sec_coupons_df = pd.DataFrame(data={'security': aux_coupons_df.loc[i_idx, 'security'],\n",
    "                                                      'Coupon_Payment_Dt': list_cup_dates, 'Cupón': i_sec_cup,\n",
    "                                                      'Divisa': aux_coupons_df.loc[i_idx, 'Divisa'],\n",
    "                                                      'Banco': aux_coupons_df.loc[i_idx, 'Banco']})\n",
    "                coupons_df = coupons_df.append(i_sec_coupons_df, ignore_index=True)\n",
    "\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    coupons_df = coupons_df.drop_duplicates()\n",
    "\n",
    "    #Una vez generado el DataFrame de forma similar al los dividendos recibidos, el resto de los cálculos se realizan de forma análoga\n",
    "    \n",
    "    #Se genera una pivot table donde las filas son los activos y las cantidas y las columnas son los periodos temporales que se han cargado\n",
    "    n_assets = pd.DataFrame(data={})\n",
    "\n",
    "    for i_bank in global_mat['Banco'].unique():\n",
    "        aux_i_global_mat = global_mat.loc[global_mat['Banco'].isin([i_bank])]\n",
    "        n_assets = pd.concat([n_assets, aux_i_global_mat[['date', 'Banco', 'security', 'Nominal']].pivot_table(index = ['Banco', 'security'], columns = 'date', values = 'Nominal').fillna(0).reset_index()], ignore_index=True)\n",
    "\n",
    "    list_dates_concat = []\n",
    "    for i_dates_concat in n_assets.columns:\n",
    "        if i_dates_concat != 'Banco' and i_dates_concat != 'security':\n",
    "            list_dates_concat += [i_dates_concat]\n",
    "\n",
    "    n_assets = n_assets[['Banco', 'security'] + sorted(list_dates_concat)]\n",
    "    n_assets = n_assets.fillna(method='ffill', axis = 1)\n",
    "\n",
    "    list_amount_cup = []\n",
    "    for i in range(len(coupons_df)):\n",
    "        aux_mat = n_assets.loc[n_assets['security'].isin([coupons_df['security'].iloc[i]]) & n_assets['Banco'].isin([coupons_df['Banco'].iloc[i]])].drop(['Banco', 'security'], axis=1) \n",
    "\n",
    "        try:\n",
    "            date_quantity = aux_mat.loc[:,aux_mat.columns <= coupons_df['Coupon_Payment_Dt'].iloc[i]].iloc[:,-1].values[0]\n",
    "            list_amount_cup += [date_quantity * coupons_df['Cupón'].iloc[i]]        \n",
    "\n",
    "        except: #Si no hay nada comprado para el activo en el que en esa fecha se paga un dividendo\n",
    "            list_amount_cup += [0]   \n",
    "            \n",
    "    coupons_df['Total_Coupon'] = list_amount_cup        \n",
    "    coupons_df['mes'] = coupons_df['Coupon_Payment_Dt'].map(lambda x: x.month)\n",
    "\n",
    "    #En caso de que algún bono esté en otra divisa, calcular el cambio de divisa\n",
    "    list_real_amount_cup = []\n",
    "    for i_idx in coupons_df.index:\n",
    "        divisa_activo = coupons_df.loc[i_idx, 'Divisa']\n",
    "        if divisa_activo != ac_curncy.value:\n",
    "            request =  bql.Request(ac_curncy.value + divisa_activo + ' Curncy', {'FX': d.px_last(start = coupons_df.loc[i_idx, 'Coupon_Payment_Dt'].to_pydatetime(), fill = 'prev')['value']})\n",
    "            res = bq.execute(request)\n",
    "            fx_df = res[0].df()\n",
    "\n",
    "            list_real_amount_cup += [coupons_df.loc[i_idx, 'Total_Coupon'] / fx_df['FX'][0]]\n",
    "        else:\n",
    "            list_real_amount_cup += [coupons_df.loc[i_idx, 'Total_Coupon']]\n",
    "\n",
    "    coupons_df['Real_Total_Coupon'] = list_real_amount_cup \n",
    "    \n",
    "    coupons_df['año'] = coupons_df['Coupon_Payment_Dt'].map(lambda x: x.year)\n",
    "\n",
    "    #Generar la matriz de cupones del último año\n",
    "    last_year = np.sort(coupons_df['año'].unique())[-1]\n",
    "    fil_coupons_df = coupons_df.loc[coupons_df['año'].isin([last_year])]\n",
    "\n",
    "    cum_coupons_df = pd.pivot_table(fil_coupons_df, values='Real_Total_Coupon', index=['security'],columns=['mes'], aggfunc=np.sum)\n",
    "    tot_cup = cum_coupons_df.sum(axis=1,skipna=True).sum(axis=0,skipna=True)\n",
    "\n",
    "    def_mat_cup = pd.DataFrame(data={})\n",
    "    for col in cum_coupons_df.columns.tolist():\n",
    "        def_mat_cup[str(col)] = cum_coupons_df[col].tolist()\n",
    "\n",
    "    if cum_coupons_df.columns.tolist() != list(range(1,13)): #Ver si faltan meses por incluir en el año\n",
    "        for left_month in list(set(list(range(1,13))) - set(cum_coupons_df.columns.tolist())):\n",
    "            def_mat_cup[str(left_month)] = np.nan\n",
    "\n",
    "    def_mat_cup['security'] = cum_coupons_df.index.tolist() \n",
    "#     def_mat_cup = def_mat_cup[['Ticker'] + [str(i) for i in range(1,13)]] #Ordenar la matriz\n",
    "#     def_mat_cup['Total'] = def_mat_cup.sum(axis=1,skipna=True)\n",
    "#     def_mat_cup = def_mat_cup.append(def_mat_cup.sum(numeric_only=True), ignore_index=True)\n",
    "#     def_mat_cup.loc[len(def_mat_cup)-1, 'Ticker'] = 'Total'\n",
    "    \n",
    "    new_mat_cup = pd.pivot_table(coupons_df, values='Real_Total_Coupon', index=['security', 'Banco'],columns=['mes'], aggfunc=np.sum)\n",
    "\n",
    "    new_mat_cup['Intereses recibidos'] = new_mat_cup.sum(axis=1,skipna=True)\n",
    "    new_mat_cup = new_mat_cup.reset_index()\n",
    "    new_mat_cup = new_mat_cup[['security', 'Banco', 'Intereses recibidos']]\n",
    "\n",
    "    agg_global_data_mat = pd.merge(agg_global_data_mat, new_mat_cup, how='left', on=['security', 'Banco'])\n",
    "    \n",
    "def dividend_matrix(tgt = None): \n",
    "    global global_mat\n",
    "    global agg_global_data_mat\n",
    "    \n",
    "    global def_mat_div #Aquí se genera la matriz de dividendos para el reporting\n",
    "    global tot_div    \n",
    "    \n",
    "    dividends_df = pd.DataFrame(data={})\n",
    "\n",
    "    #Aplicar los cálculos unicamente sobre los tickers que contengan la palabra Equity\n",
    "    list_eq_tickers = []\n",
    "    for eq in global_mat['security'].unique():\n",
    "        if 'Equity' in eq:\n",
    "            list_eq_tickers += [eq]\n",
    "\n",
    "    for eq in list_eq_tickers:\n",
    "        i_start_date = datetime.datetime.strptime(date_st.value, '%d-%m-%Y')\n",
    "        i_end_date = datetime.datetime.strptime(date_end.value, '%d-%m-%Y')\n",
    "\n",
    "        try:\n",
    "            request = bql.Request(eq, {'Dividendos': f.dropna(d.cash_divs(dates = f.range(i_start_date, i_end_date), ca_date_type = 'PAY_DATE', currency = ac_curncy.value))})\n",
    "            res = bq.execute(request)\n",
    "            aux_res = res[0].df().reset_index()\n",
    "            aux_res['aux'] = range(len(aux_res)) #Se Asigna una variable auxiliar para identificar dónde se tienen que colocar las fechas ex-dividend\n",
    "\n",
    "            #Para buscar las fechas Ex-Dividend, se va a coger el último valor del dividendo pagado y al primero se le resta 1 año.\n",
    "            #No obstante, en vez de sacar el histórico, sacamos el número mínimo necesario de las fechas ex-dividends que necesitamos con la función last\n",
    "            #Se alinean los valores con la variable auxiliar creada al hacer un merge\n",
    "\n",
    "            if len(aux_res) > 1:\n",
    "                aux_st_dt = aux_res['DATE'].values[0]\n",
    "                aux_end_dt = aux_res['DATE'].values[-1]\n",
    "\n",
    "            else:\n",
    "                aux_st_dt = aux_res['DATE'].values[0]\n",
    "                aux_end_dt = aux_res['DATE'].values[0]\n",
    "\n",
    "            pay_st_dt = pd.to_datetime(str(aux_st_dt - np.timedelta64(8760, 'h'))).strftime('%Y-%m-%d') \n",
    "            pay_end_dt = pd.to_datetime(str(aux_end_dt)).strftime('%Y-%m-%d')\n",
    "\n",
    "            request = bql.Request(eq, {'Dividendos': f.last(f.dropna(d.cash_divs(dates = f.range(pay_st_dt, pay_end_dt), ca_date_type = 'EFFECTIVE_DATE', currency = ac_curncy.value)), n = len(aux_res))})\n",
    "            res = bq.execute(request)\n",
    "            aux_res2 = res[0].df().reset_index().rename(index=str, columns={'DATE': 'Ex-div_date'})\n",
    "            aux_res2['aux'] = range(len(aux_res2))\n",
    "\n",
    "            aux_res = pd.merge(aux_res, aux_res2[['aux', 'Ex-div_date']], how = 'left', on = ['aux'])\n",
    "\n",
    "            dividends_df = dividends_df.append(aux_res, ignore_index = True)\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    dividends_df = dividends_df.dropna(subset=['Dividendos'])     \n",
    "    \n",
    "    df_tick_banks = global_mat[['Banco', 'security']].drop_duplicates()\n",
    "    df_tick_banks = df_tick_banks.rename(index=str, columns={'security': 'ID'}) \n",
    "\n",
    "    dividends_df = pd.merge(dividends_df, df_tick_banks, how='left', on=['ID'])    \n",
    "\n",
    "    #Se genera una pivot table donde las filas son los activos y las cantidas y las columnas son los periodos temporales que se han cargado\n",
    "    n_assets = pd.DataFrame(data={})\n",
    "\n",
    "    for i_bank in global_mat['Banco'].unique():\n",
    "        aux_i_global_mat = global_mat.loc[global_mat['Banco'].isin([i_bank])]\n",
    "        n_assets = pd.concat([n_assets, aux_i_global_mat[['date', 'Banco', 'security', 'Nominal']].pivot_table(index = ['Banco', 'security'], columns = 'date', values = 'Nominal').fillna(0).reset_index()], ignore_index=True)\n",
    "\n",
    "    list_dates_concat = []\n",
    "    for i_dates_concat in n_assets.columns:\n",
    "        if i_dates_concat != 'Banco' and i_dates_concat != 'security':\n",
    "            list_dates_concat += [i_dates_concat]\n",
    "\n",
    "    n_assets = n_assets[['Banco', 'security'] + sorted(list_dates_concat)]\n",
    "    n_assets = n_assets.fillna(method='ffill', axis = 1)\n",
    "\n",
    "    list_amount_div = []\n",
    "    for i in range(len(dividends_df)):\n",
    "        aux_mat = n_assets.loc[n_assets['security'].isin([dividends_df['ID'].iloc[i]]) & n_assets['Banco'].isin([dividends_df['Banco'].iloc[i]])].drop(['Banco', 'security'], axis=1) \n",
    "\n",
    "        try:\n",
    "            if aux_mat.loc[:,aux_mat.columns <= dividends_df['Ex-div_date'].iloc[i]].iloc[:,-1].values[0] != 0: #Si no se ha comprado el valor antes de la fecha ex-dividend, entonces no se podrá computar el dividendo recibido en la fecha de su pago            \n",
    "                date_quantity = aux_mat.loc[:,aux_mat.columns <= dividends_df['DATE'].iloc[i]].iloc[:,-1].values[0]\n",
    "                list_amount_div += [date_quantity * dividends_df['Dividendos'].iloc[i]]\n",
    "\n",
    "            else:\n",
    "                list_amount_div += [0]\n",
    "\n",
    "        except: #Si no hay nada comprado para el activo en el que en esa fecha se paga un dividendo\n",
    "            list_amount_div += [0]\n",
    "\n",
    "    dividends_df['Total_Div'] = list_amount_div        \n",
    "    dividends_df['mes'] = dividends_df['DATE'].map(lambda x: x.month)\n",
    "    dividends_df['año'] = dividends_df['DATE'].map(lambda x: x.year)\n",
    "\n",
    "    #Generar la matriz de dividendos del último año\n",
    "    last_year = np.sort(dividends_df['año'].unique())[-1]\n",
    "    fil_dividends_df = dividends_df.loc[dividends_df['año'].isin([last_year])]\n",
    "\n",
    "    cum_dividends_df = pd.pivot_table(fil_dividends_df, values='Total_Div', index=['ID'],columns=['mes'], aggfunc=np.sum)\n",
    "    tot_div = cum_dividends_df.sum(axis=1,skipna=True).sum(axis=0,skipna=True)\n",
    "\n",
    "    def_mat_div = pd.DataFrame(data={})\n",
    "    for col in cum_dividends_df.columns.tolist():\n",
    "        def_mat_div[str(col)] = cum_dividends_df[col].tolist()\n",
    "\n",
    "    if cum_dividends_df.columns.tolist() != list(range(1,13)): #Ver si faltan meses por incluir en el año\n",
    "        for left_month in list(set(list(range(1,13))) - set(cum_dividends_df.columns.tolist())):\n",
    "            def_mat_div[str(left_month)] = np.nan\n",
    "\n",
    "    def_mat_div['security'] = cum_dividends_df.index.tolist() \n",
    "    \n",
    "#     def_mat_div = def_mat_div[['Ticker'] + [str(i) for i in range(1,13)]] #Ordenar la matriz\n",
    "#     def_mat_div['Total'] = def_mat_div.sum(axis=1,skipna=True)\n",
    "#     def_mat_div = def_mat_div.append(def_mat_div.sum(numeric_only=True), ignore_index=True)\n",
    "#     def_mat_div.loc[len(def_mat_div)-1, 'Ticker'] = 'Total'\n",
    "#     def_mat_div = def_mat_div.loc[def_mat_div['Total'] != 0]\n",
    "\n",
    "    #Una vez calucalda la matriz de dividendos que servirá para el Global Reporting, generar el df para concatenar la cantidad de dividendos recibidos por ticker y banco\n",
    "    new_mat_div = pd.pivot_table(dividends_df, values='Total_Div', index=['ID', 'Banco'],columns=['mes'], aggfunc=np.sum)\n",
    "\n",
    "    new_mat_div['Dividendos recibidos'] = new_mat_div.sum(axis=1,skipna=True)\n",
    "    new_mat_div = new_mat_div.reset_index()\n",
    "    new_mat_div = new_mat_div.rename(index=str, columns={'ID': 'security'})\n",
    "    new_mat_div = new_mat_div[['security', 'Banco', 'Dividendos recibidos']]\n",
    "\n",
    "    agg_global_data_mat = pd.merge(agg_global_data_mat, new_mat_div, how='left', on=['security', 'Banco'])  \n",
    "    \n",
    "def coup_freq_pref(security,Coupon_nxt_date,date):\n",
    "    start_pref = dt_str_to_datetime(str(date).split()[0]) - datetime.timedelta(365)\n",
    "    end_pref = dt_str_to_datetime(str(date).split()[0])\n",
    "    prev_payment_date_coupon = f.last(f.dropna(d.cash_divs(CA_ADJ='RAW',dates=f.range(start_pref, end_pref))))['DATE']\n",
    "    prev_payment_date_coupon = bq.execute(bql.Request(security,prev_payment_date_coupon))[0].df().iloc[0,0]\n",
    "    coupon_frequency = 12/round((Coupon_nxt_date-prev_payment_date_coupon).days/31)\n",
    "    return coupon_frequency\n",
    "\n",
    "#RYO\n",
    "get(dropna(cash_divs(CA_ADJ=RAW,dates = range(\"-5y\", \"-0d\")))) for(\"EP043821 pfd\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
